{"mappings":"A,C,K,S,uB,C,E,O,G,E,U,C,E,O,C,C,C,I,e,A,a,O,W,W,A,a,O,K,K,A,a,O,O,O,A,a,O,O,O,C,E,gB,C,E,c,C,E,c,e,iB,A,O,gB,A,C,c,S,C,E,G,K,gB,O,e,C,E,C,O,C,G,K,c,C,I,E,a,C,E,A,Q,a,C,E,C,I,E,C,G,E,Q,C,C,E,O,e,C,E,C,E,E,I,C,E,O,C,E,E,O,E,E,O,A,C,I,E,A,M,uB,E,I,O,E,I,C,mB,C,C,E,Q,C,S,C,C,C,E,a,C,E,C,C,E,e,iB,C,e,c,Q,C,Q,S,M,C,O,E,O,O,C,S,C,EECA,IAAA,EAAA,CAAA,EAGA,SAAA,EAAA,CAAA,EAGA,GAAA,CAAA,CAAA,EAAA,CACA,OAAA,CAAA,CAAA,EAAA,CAAA,OADA,CAIA,IAAA,EAAA,CAAA,CAAA,EAAA,CAAA,CACA,EAAA,EACA,EAAA,CAAA,EACA,QAAA,CAAA,CACA,EASA,OANA,CAAA,CAAA,EAAA,CAAA,IAAA,CAAA,EAAA,OAAA,CAAA,EAAA,EAAA,OAAA,CAAA,GAGA,EAAA,CAAA,CAAA,CAAA,EAGA,EAAA,OAAA,AACA,CA0CA,OAtCA,EAAA,CAAA,CAAA,EAGA,EAAA,CAAA,CAAA,EAGA,EAAA,CAAA,CAAA,SAAA,CAAA,CAAA,CAAA,CAAA,CAAA,EACA,EAAA,CAAA,CAAA,EAAA,IACA,OAAA,cAAA,CAAA,EAAA,EAAA,CACA,aAAA,CAAA,EACA,WAAA,CAAA,EACA,IAAA,CACA,EAEA,EAGA,EAAA,CAAA,CAAA,SAAA,CAAA,EACA,OAAA,cAAA,CAAA,EAAA,aAAA,CAAiD,MAAA,CAAA,CAAA,EACjD,EAGA,EAAA,CAAA,CAAA,SAAA,CAAA,EACA,IAAA,EAAA,GAAA,EAAA,UAAA,CACA,WAA2B,OAAA,EAAA,OAAA,AAA0B,EACrD,WAAiC,OAAA,CAAjC,EAEA,OADA,EAAA,CAAA,CAAA,EAAA,IAAA,GACA,CACA,EAGA,EAAA,CAAA,CAAA,SAAA,CAAA,CAAA,CAAA,EAAsD,OAAA,OAAA,SAAA,CAAA,cAAA,CAAA,IAAA,CAAA,EAAA,EAAtD,EAGA,EAAA,CAAA,CAAA,GAIA,EAAA,EAAA,CAAA,CAAA,a,E,C,a,S,M,C,O,C,mB,E,K,4xH,C,E,G,I,O,c,S,0B,C,GI3DE,AAAA,SAAU,CAAM,CAAE,CAAO,EAGpB,AAAiB,YAAjB,OAAO,QAAwB,OAAO,GAAA,CAEzC,OAAQ,GAC+B,0BAEvC,0BAAiB,IAGjB,EAAO,SAAA,CAAY,GAGvB,EAAG,AAAiB,aAAjB,OAAO,OAAwB,OAAS,0BAAM,WAIjD,SAAS,IAAa,CAEtB,IAAI,EAAQ,EAAU,SAAtB,CAiFA,OA/EA,EAAM,EAAA,CAAK,SAAU,CAAS,CAAE,CAAQ,EACtC,GAAK,AAAC,GAAc,GAIpB,IAAI,EAAS,IAAI,CAAC,OAAA,CAAU,IAAI,CAAC,OAAA,EAAW,CAAC,EAEzC,EAAY,CAAM,CAAE,EAAW,CAAG,CAAM,CAAE,EAAW,EAAI,EAAE,CAM/D,OAJsC,IAAjC,EAAU,OAAA,CAAS,IACtB,EAAU,IAAA,CAAM,GAGX,IAAI,CACb,EAEA,EAAM,IAAA,CAAO,SAAU,CAAS,CAAE,CAAQ,EACxC,GAAK,AAAC,GAAc,GAIpB,IAAI,CAAC,EAAA,CAAI,EAAW,GAGpB,IAAI,EAAa,IAAI,CAAC,WAAA,CAAc,IAAI,CAAC,WAAA,EAAe,CAAC,EAErD,EAAgB,CAAU,CAAE,EAAW,CAAG,CAAU,CAAE,EAAW,EAAI,CAAC,EAI1E,OAFA,CAAa,CAAE,EAAU,CAAG,CAAA,EAErB,IAAI,CACb,EAEA,EAAM,GAAA,CAAM,SAAU,CAAS,CAAE,CAAQ,EACvC,IAAI,EAAY,IAAI,CAAC,OAAA,EAAW,IAAI,CAAC,OAAO,CAAE,EAAW,CACzD,GAAK,AAAC,GAAc,EAAU,MAAA,EAG9B,IAAI,EAAQ,EAAU,OAAA,CAAS,GAK/B,OAJc,IAAT,GACH,EAAU,MAAA,CAAQ,EAAO,GAGpB,IAAI,CACb,EAEA,EAAM,SAAA,CAAY,SAAU,CAAS,CAAE,CAAI,EACzC,IAAI,EAAY,IAAI,CAAC,OAAA,EAAW,IAAI,CAAC,OAAO,CAAE,EAAW,CACzD,GAAK,AAAC,GAAc,EAAU,MAAA,EAI9B,EAAY,EAAU,KAAA,CAAM,GAC5B,EAAO,GAAQ,EAAE,CAIjB,IAAM,IAFF,EAAgB,IAAI,CAAC,WAAA,EAAe,IAAI,CAAC,WAAW,CAAE,EAAW,CAE3D,EAAE,EAAG,EAAI,EAAU,MAAA,CAAQ,IAAM,CACzC,IAAI,EAAW,CAAS,CAAC,EAAE,CACd,GAAiB,CAAa,CAAE,EAAU,GAIrD,IAAI,CAAC,GAAA,CAAK,EAAW,GAErB,OAAO,CAAa,CAAE,EAAU,EAGlC,EAAS,KAAA,CAAO,IAAI,CAAE,EACxB,CAEA,OAAO,IAAI,CACb,EAEA,EAAM,MAAA,CAAS,WACb,OAAO,IAAI,CAAC,OAAZ,CACA,OAAO,IAAI,CAAC,WAAZ,AACF,EAEO,CAEP,ED9Ee,OAAA,iDAAoB,uBAAA,2BACjC,YAAY,CAAE,CAAE,CAAI,CAAE,CAGpB,KAAK,GAGL,IAAI,CAAC,OAAA,CAAU,OAAO,MAAA,CACpB,CAAC,EACD,CACE,gBAAiB,IACjB,cAAe,GACf,kBAAmB,gBACnB,QAAS,IACX,EACA,GAGE,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAc,MAA/B,GAEM,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAc,OAAA,CAAQ,KAAO,GAG5C,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAgB,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAc,KAAA,CAAM,KAAK,MAAA,CAAO,AAAA,GAAK,EAAE,MAAjF,EAIA,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAgB,CAAC,IAAI,CAAC,OAAA,CAAQ,aAAb,CAA2B,EAI7D,IAAI,CAAC,EAAA,CAAK,EACV,IAAI,CAAC,EAAA,CAAG,SAAA,CAAU,GAAA,CAAI,WACtB,IAAI,CAAC,MAAA,CAAS,CAAA,EACd,IAAI,CAAC,UAAA,CAAa,CAAA,EAClB,IAAI,CAAC,SAAA,CAAY,IAAI,CAAC,EAAA,CAAG,aAAA,CAAc,kBACvC,IAAI,CAAC,eAAA,CAAkB,IAAI,CAAC,EAAA,CAAG,aAAA,CAAc,IAAM,IAAI,CAAC,OAAA,CAAQ,iBAAA,GAAsB,IAAI,CAAC,SAA3F,CACA,IAAI,CAAC,QAAA,CAAW,IAAI,CAAC,EAAA,CAAG,gBAAA,CAAiB,sBAGrC,IAAI,CAAC,EAAA,CAAG,EAAA,EACV,IAAI,CAAC,SAAA,CAAY,SAAS,gBAAA,CAAiB,CAAC,aAAa,EAAE,IAAI,CAAC,EAAA,CAAG,EAAA,CAAG,EAAE,CAAC,EACzE,IAAI,CAAC,UAAA,CAAa,CAAC,CAAC,IAAI,CAAC,SAAA,CAAU,MAAnC,EAIA,IAAI,CAAC,EAAA,CAAG,EAAA,CAAK,KAAK,MAAA,GAAS,QAAA,CAAS,IAAI,MAAA,CAAO,EAAG,GAIpD,IAAI,CAAC,aAAA,CAAgB,KAGrB,IAAI,CAAC,YAAA,CAAe,IAAI,CAAC,eAAzB,GAGI,IAAI,CAAC,YAAA,CAAa,MAAA,GACpB,IAAI,CAAC,gBAAA,CAAmB,IAAI,CAAC,YAAY,CAAC,EAAE,CAC5C,IAAI,CAAC,eAAA,CAAkB,IAAI,CAAC,YAAY,CAAC,IAAI,CAAC,YAAA,CAAa,MAAA,CAAS,EAAE,EAInE,IAAI,CAAC,EAAA,CAAG,YAAA,CAAa,eAAkB,IAAI,CAAC,EAAA,CAAG,YAAA,CAAa,oBAC/D,QAAQ,IAAA,CAAK,sFAAuF,IAAI,CAAC,EAD3G,EAKA,IAAI,CAAC,IAAL,EACF,CAEA,MAAO,CAEL,IAAI,CAAC,EAAA,CAAG,YAAA,CAAa,cAAe,QACpC,IAAI,CAAC,EAAA,CAAG,YAAA,CAAa,OAAQ,UAGzB,IAAI,CAAC,UAAA,EACP,IAAI,CAAC,SAAA,CAAU,OAAA,CAAQ,AAAA,IAGrB,EAAS,YAAA,CAAa,gBAAiB,IAAI,CAAC,EAAA,CAAG,EAA/C,EACA,EAAS,YAAA,CAAa,gBAAiB,SACvC,EAAS,YAAA,CAAa,OAAQ,SAChC,GAIE,IAAI,CAAC,QAAA,CAAS,MAAA,EAChB,IAAI,CAAC,QAAA,CAAS,OAAA,CAAQ,AAAA,IACpB,EAAQ,YAAA,CAAa,OAAQ,SAC/B,GAIF,IAAI,CAAC,UAAL,GAGoC,YAAhC,OAAO,IAAI,CAAC,OAAA,CAAQ,OAAA,EACtB,IAAI,CAAC,OAAA,CAAQ,OADf,EAYF,CAEA,SAAU,CAER,IAAI,CAAC,EAAA,CAAG,eAAA,CAAgB,eACxB,IAAI,CAAC,EAAA,CAAG,eAAA,CAAgB,QACxB,IAAI,CAAC,EAAA,CAAG,eAAA,CAAgB,YAGpB,IAAI,CAAC,UAAA,EACP,IAAI,CAAC,SAAA,CAAU,OAAA,CAAQ,AAAA,IACrB,EAAS,eAAA,CAAgB,iBACzB,EAAS,eAAA,CAAgB,iBACzB,EAAS,eAAA,CAAgB,OAC3B,GAIE,IAAI,CAAC,QAAA,CAAS,MAAA,EAChB,IAAI,CAAC,QAAA,CAAS,OAAA,CAAQ,AAAA,IACpB,EAAQ,eAAA,CAAgB,cACxB,EAAQ,eAAA,CAAgB,OAC1B,GAIF,IAAI,CAAC,YAAL,GAGA,IAAI,CAAC,SAAA,CAAU,UACjB,CAIA,iBAAkB,CAMhB,MAAO,IALY,IAAI,CAAC,EAAA,CAAG,gBAAA,CACzB,wIAIsB,AAC1B,CAKA,cAAe,QACb,AACE,SAAS,QAAA,IACT,SAAS,aAAA,GAAkB,SAAS,IAAA,EACpC,SAAS,aAAA,GAAkB,SAAS,eAAA,CAE7B,SAAS,aALlB,CAQO,IACT,CAEA,WAAW,CAAE,CAAE,CAMb,OAAO,UAAA,CAAW,IAAM,EAAG,KAAA,GAAS,IAAI,CAAC,OAAA,CAAQ,eAAjD,CACF,CAEA,mBAAmB,CAAG,CAAE,CAEtB,IAAI,EAAW,MAAM,SAAA,CAAU,OAAA,CAAQ,IAAA,CAAK,IAAI,CAAC,SAAA,CAAW,EAAI,MAAA,CAAO,OAAA,CAAQ,iBAAmB,GAG9F,EAAiB,SAAS,IAAA,CAAK,QAAA,CAAS,EAAI,MAAhD,EAIA,GAAI,CAAC,IAAI,CAAC,MAAA,EAAU,GAAY,CAAC,EAC/B,OAIF,IAAI,EAAsB,IAAI,CAAC,eAAA,EAAmB,IAAI,CAAC,eAAA,CAAgB,QAAA,CAAS,EAAI,MAApF,EAGI,EAAkB,IAAI,CAAC,eAAA,CAAgB,UAAA,CAAW,EAAI,MAA1D,EAWM,GAAuB,GAC3B,IAAI,CAAC,KAAA,CAAM,EAEf,CAEA,eAAe,CAAG,CAAE,CAElB,GAAI,CAAC,IAAI,CAAC,MAAA,CACR,MAAO,CAAA,EAST,GALkB,KAAd,EAAI,KAAA,EACN,IAAI,CAAC,KAAA,CAAM,GAIT,AAAc,IAAd,EAAI,KAAA,CAAa,CAEnB,GAAI,CAAC,IAAI,CAAC,YAAA,CAAa,MAAA,CAErB,OADA,IAAI,CAAC,KAAA,CAAM,GACJ,CAAA,EAIT,IAAI,EAAY,IAAI,CAAC,YAArB,EAGI,AAAC,CAAA,EAAI,QAAA,EAAY,GAAa,IAAI,CAAC,eAAA,CAI5B,EAAI,QAAA,EAAa,CAAA,GAAa,IAAI,CAAC,gBAAA,EAAoB,GAAa,IAAI,CAAC,SAAQ,AAAR,IAElF,EAAI,cAAJ,GACA,IAAI,CAAC,eAAA,CAAgB,KAArB,KALA,EAAI,cAAJ,GACA,IAAI,CAAC,gBAAA,CAAiB,KAAtB,GAMJ,CACF,CAEA,YAAa,CAEP,IAAI,CAAC,UAAA,GAGP,IAAI,CAAC,WAAA,CAAc,IAAI,CAAC,MAAA,CAAO,IAAA,CAAK,IAAI,EAExC,IAAI,CAAC,SAAA,CAAU,OAAA,CAAQ,AAAA,IACrB,EAAS,gBAAA,CAAiB,QAAS,IAAI,CAAC,WAAxC,CACF,IAIE,IAAI,CAAC,QAAA,CAAS,MAAA,GAEhB,IAAI,CAAC,UAAA,CAAa,IAAI,CAAC,KAAA,CAAM,IAAA,CAAK,IAAI,EAEtC,IAAI,CAAC,QAAA,CAAS,OAAA,CAAQ,AAAA,IACpB,EAAQ,gBAAA,CAAiB,QAAS,IAAI,CAAC,UAAvC,CACF,IAIF,IAAI,CAAC,WAAA,CAAc,IAAI,CAAC,kBAAA,CAAmB,IAAA,CAAK,IAAI,EACpD,OAAO,gBAAA,CAAiB,QAAS,IAAI,CAAC,WAAtC,EAGA,IAAI,CAAC,OAAA,CAAU,IAAI,CAAC,cAAA,CAAe,IAAA,CAAK,IAAI,EAC5C,OAAO,gBAAA,CAAiB,UAAW,IAAI,CAAC,OAAxC,CACF,CAEA,cAAe,CAET,IAAI,CAAC,UAAA,EACP,IAAI,CAAC,SAAA,CAAU,OAAA,CAAQ,AAAA,IACrB,EAAS,mBAAA,CAAoB,QAAS,IAAI,CAAC,WAA3C,CACF,GAIE,IAAI,CAAC,QAAA,CAAS,MAAA,EAChB,IAAI,CAAC,QAAA,CAAS,OAAA,CAAQ,AAAA,IACpB,EAAQ,mBAAA,CAAoB,QAAS,IAAI,CAAC,UAA1C,CACF,GAIF,OAAO,mBAAA,CAAoB,QAAS,IAAI,CAAC,WAAzC,EACA,OAAO,mBAAA,CAAoB,UAAW,IAAI,CAAC,OAA3C,CACF,CAGA,KAAK,CAAG,CAAE,CACR,EAAI,cAAJ,GAGA,IAAI,CAAC,aAAA,CAAgB,IAAI,CAAC,YAA1B,GAGA,AAAA,uBAAA,QAAO,MAAP,GAII,IAAI,CAAC,SAAA,EACP,CAAA,IAAI,CAAC,SAAA,CAAU,SAAA,CAAY,CAAA,EAI7B,IAAI,CAAC,EAAA,CAAG,YAAA,CAAa,cAAe,SAGhC,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAc,MAAA,EAC7B,IAAI,CAAC,EAAA,CAAG,SAAA,CAAU,GAAA,IAAO,IAAI,CAAC,OAAA,CAAQ,aADxC,EAKI,IAAI,CAAC,UAAA,EACP,IAAI,CAAC,SAAA,CAAU,OAAA,CAAQ,AAAA,IACrB,EAAS,YAAA,CAAa,gBAAiB,QAGnC,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAc,MAAA,EAC7B,EAAS,SAAA,CAAU,GAAA,IAAO,IAAI,CAAC,OAAA,CAAQ,aADzC,CAGF,GAIE,IAAI,CAAC,SAAA,EACP,IAAI,CAAC,SAAA,CAAU,YAAA,CAAa,WAAY,MACxC,IAAI,CAAC,UAAA,CAAW,IAAI,CAAC,SAArB,IAEA,IAAI,CAAC,EAAA,CAAG,YAAA,CAAa,WAAY,MACjC,IAAI,CAAC,UAAA,CAAW,IAAI,CAAC,EAArB,GAYF,IAAI,CAAC,MAAA,CAAS,CAAA,EAGd,IAAI,CAAC,SAAA,CAAU,OACjB,CAGA,MAAM,CAAG,CAAE,CACT,EAAI,cAAJ,GAQA,IAAI,CAAC,EAAA,CAAG,YAAA,CAAa,cAAe,QAGhC,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAc,MAAA,EAC7B,IAAI,CAAC,EAAA,CAAG,SAAA,CAAU,MAAA,IAAU,IAAI,CAAC,OAAA,CAAQ,aAD3C,EAKI,IAAI,CAAC,UAAA,EACP,IAAI,CAAC,SAAA,CAAU,OAAA,CAAQ,AAAA,IACrB,EAAS,YAAA,CAAa,gBAAiB,SAGnC,IAAI,CAAC,OAAA,CAAQ,aAAA,CAAc,MAAA,EAC7B,EAAS,SAAA,CAAU,MAAA,IAAU,IAAI,CAAC,OAAA,CAAQ,aAD5C,CAGF,GAIF,AAAA,uBAAA,QAAO,QAAP,GAGI,IAAI,CAAC,aAAA,CACP,IAAI,CAAC,UAAA,CAAW,IAAI,CAAC,aADvB,EAEW,IAAI,CAAC,UAAA,EAEd,IAAI,CAAC,UAAA,CAAW,IAAI,CAAC,SAAS,CAAC,EAAE,EAInC,IAAI,CAAC,MAAA,CAAS,CAAA,EAGd,IAAI,CAAC,SAAA,CAAU,QACjB,CAGA,OAAO,CAAG,CAAE,CACN,IAAI,CAAC,MAAA,CACP,IAAI,CAAC,KAAA,CAAM,GAEX,IAAI,CAAC,IAAA,CAAK,EAEd,CACF,CDzbA,IAAM,gCAAY,SAAS,cAAA,CAAe,QAEtC,iCACF,IAAI,yCAAM,iC,I,0B,C,GICV,AAAA,WAiCF,IAAI,EAAO,SAAU,CAAM,EACzB,IAAI,EAAU,IAAI,EAAK,OAAvB,CAaA,OAXA,EAAQ,QAAA,CAAS,GAAA,CACf,EAAK,OAAA,CACL,EAAK,cAAA,CACL,EAAK,OAHP,EAMA,EAAQ,cAAA,CAAe,GAAA,CACrB,EAAK,OADP,EAIA,EAAO,IAAA,CAAK,EAAS,GACd,EAAQ,KAAf,EACF,CAEA,CAAA,EAAK,OAAA,CAAU,QAUf,EAAK,KAAA,CAAQ,CAAC,EASd,EAAK,KAAA,CAAM,IAAA,CAAO,SAAW,CAAM,EAEjC,OAAO,SAAU,CAAO,EAClB,EAAO,OAAA,EAAW,QAAQ,IAAA,EAC5B,QAAQ,IAAA,CAAK,EAEjB,CAEF,EAAG,IAAI,EAaP,EAAK,KAAA,CAAM,QAAA,CAAW,SAAU,CAAG,SACjC,AAAI,MAAA,EACK,GAEA,EAAI,QAAX,EAEJ,EAkBA,EAAK,KAAA,CAAM,KAAA,CAAQ,SAAU,CAAG,EAC9B,GAAI,MAAA,EACF,OAAO,EAMT,IAAK,IAHD,EAAQ,OAAO,MAAA,CAAO,MACtB,EAAO,OAAO,IAAA,CAAK,GAEd,EAAI,EAAG,EAAI,EAAK,MAAA,CAAQ,IAAK,CACpC,IAAI,EAAM,CAAI,CAAC,EAAE,CACb,EAAM,CAAG,CAAC,EAAI,CAElB,GAAI,MAAM,OAAA,CAAQ,GAAM,CACtB,CAAK,CAAC,EAAI,CAAG,EAAI,KAAjB,GACA,QACF,CAEA,GAAI,AAAe,UAAf,OAAO,GACP,AAAe,UAAf,OAAO,GACP,AAAe,WAAf,OAAO,EAAmB,CAC5B,CAAK,CAAC,EAAI,CAAG,EACb,QACF,CAEA,MAAM,AAAI,UAAU,wDACtB,CAEA,OAAO,CACT,EACA,EAAK,QAAA,CAAW,SAAU,CAAM,CAAE,CAAS,CAAE,CAAW,EACtD,IAAI,CAAC,MAAA,CAAS,EACd,IAAI,CAAC,SAAA,CAAY,EACjB,IAAI,CAAC,YAAA,CAAe,CACtB,EAEA,EAAK,QAAA,CAAS,MAAA,CAAS,IAEvB,EAAK,QAAA,CAAS,UAAA,CAAa,SAAU,CAAC,EACpC,IAAI,EAAI,EAAE,OAAA,CAAQ,EAAK,QAAA,CAAS,MAAhC,EAEA,GAAI,AAAM,KAAN,EACF,KAAM,6BAGR,IAAI,EAAW,EAAE,KAAA,CAAM,EAAG,GACtB,EAAS,EAAE,KAAA,CAAM,EAAI,GAEzB,OAAO,IAAI,EAAK,QAAA,CAAU,EAAQ,EAAU,EAC9C,EAEA,EAAK,QAAA,CAAS,SAAA,CAAU,QAAA,CAAW,WAKjC,OAJyB,KAAA,GAArB,IAAI,CAAC,YAAA,EACP,CAAA,IAAI,CAAC,YAAA,CAAe,IAAI,CAAC,SAAA,CAAY,EAAK,QAAA,CAAS,MAAA,CAAS,IAAI,CAAC,MADnE,AAAA,EAIO,IAAI,CAAC,YAAZ,AACF,EAWA,EAAK,GAAA,CAAM,SAAU,CAAQ,EAG3B,GAFA,IAAI,CAAC,QAAA,CAAW,OAAO,MAAA,CAAO,MAE1B,EAAU,CACZ,IAAI,CAAC,MAAA,CAAS,EAAS,MAAvB,CAEA,IAAK,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,MAAA,CAAQ,IAC/B,IAAI,CAAC,QAAQ,CAAC,CAAQ,CAAC,EAAE,CAAC,CAAG,CAAA,CAEjC,MACE,IAAI,CAAC,MAAA,CAAS,CAElB,EASA,EAAK,GAAA,CAAI,QAAA,CAAW,CAClB,UAAW,SAAU,CAAK,EACxB,OAAO,CACT,EAEA,MAAO,WACL,OAAO,IAAI,AACb,EAEA,SAAU,WACR,MAAO,CAAA,CACT,CACF,EASA,EAAK,GAAA,CAAI,KAAA,CAAQ,CACf,UAAW,WACT,OAAO,IAAI,AACb,EAEA,MAAO,SAAU,CAAK,EACpB,OAAO,CACT,EAEA,SAAU,WACR,MAAO,CAAA,CACT,CACF,EAQA,EAAK,GAAA,CAAI,SAAA,CAAU,QAAA,CAAW,SAAU,CAAM,EAC5C,MAAO,CAAC,CAAC,IAAI,CAAC,QAAQ,CAAC,EAAO,AAChC,EAUA,EAAK,GAAA,CAAI,SAAA,CAAU,SAAA,CAAY,SAAU,CAAK,EAC5C,IAAI,EAAG,EAAG,EAAU,EAAe,EAAE,CAErC,GAAI,IAAU,EAAK,GAAA,CAAI,QAAA,CACrB,OAAO,IAAI,CAGb,GAAI,IAAU,EAAK,GAAA,CAAI,KAAA,CACrB,OAAO,CAGL,CAAA,IAAI,CAAC,MAAA,CAAS,EAAM,MAAA,EACtB,EAAI,IAAI,CACR,EAAI,IAEJ,EAAI,EACJ,EAAI,IAAI,EAGV,EAAW,OAAO,IAAA,CAAK,EAAE,QAAzB,EAEA,IAAK,IAAI,EAAI,EAAG,EAAI,EAAS,MAAA,CAAQ,IAAK,CACxC,IAAI,EAAU,CAAQ,CAAC,EAAE,CACrB,KAAW,EAAE,QAAA,EACf,EAAa,IAAA,CAAK,EAEtB,CAEA,OAAO,IAAI,EAAK,GAAA,CAAK,EACvB,EASA,EAAK,GAAA,CAAI,SAAA,CAAU,KAAA,CAAQ,SAAU,CAAK,SACxC,AAAI,IAAU,EAAK,GAAA,CAAI,QAAA,CACd,EAAK,GAAA,CAAI,QADlB,CAII,IAAU,EAAK,GAAA,CAAI,KAAA,CACd,IAAI,CAGN,IAAI,EAAK,GAAA,CAAI,OAAO,IAAA,CAAK,IAAI,CAAC,QAAA,EAAU,MAAA,CAAO,OAAO,IAAA,CAAK,EAAM,QAAxE,GACF,EASA,EAAK,GAAA,CAAM,SAAU,CAAO,CAAE,CAAa,EACzC,IAAI,EAAoB,EAExB,IAAK,IAAI,KAAa,EACH,UAAb,GACJ,CAAA,GAAqB,OAAO,IAAA,CAAK,CAAO,CAAC,EAAU,EAAE,MAArD,AAAA,EAKF,OAAO,KAAK,GAAA,CAAI,EAAI,KAAK,GAAA,CAFhB,AAAA,CAAA,EAAgB,EAAoB,EAAA,EAAQ,CAAA,EAAoB,EAAA,GAG3E,EAUA,EAAK,KAAA,CAAQ,SAAU,CAAG,CAAE,CAAQ,EAClC,IAAI,CAAC,GAAA,CAAM,GAAO,GAClB,IAAI,CAAC,QAAA,CAAW,GAAY,CAAC,CAC/B,EAOA,EAAK,KAAA,CAAM,SAAA,CAAU,QAAA,CAAW,WAC9B,OAAO,IAAI,CAAC,GAAZ,AACF,EAsBA,EAAK,KAAA,CAAM,SAAA,CAAU,MAAA,CAAS,SAAU,CAAE,EAExC,OADA,IAAI,CAAC,GAAA,CAAM,EAAG,IAAI,CAAC,GAAA,CAAK,IAAI,CAAC,QAA7B,EACO,IAAI,AACb,EASA,EAAK,KAAA,CAAM,SAAA,CAAU,KAAA,CAAQ,SAAU,CAAE,EAEvC,OADA,EAAK,GAAM,SAAU,CAAC,EAAI,OAAO,CAAE,EAC5B,IAAI,EAAK,KAAA,CAAO,EAAG,IAAI,CAAC,GAAA,CAAK,IAAI,CAAC,QAAA,EAAW,IAAI,CAAC,QAAzD,CACF,EAwBA,EAAK,SAAA,CAAY,SAAU,CAAG,CAAE,CAAQ,EACtC,GAAI,AAAO,MAAP,GAAe,AAAO,KAAA,GAAP,EACjB,MAAO,EAAE,CAGX,GAAI,MAAM,OAAA,CAAQ,GAChB,OAAO,EAAI,GAAA,CAAI,SAAU,CAAC,EACxB,OAAO,IAAI,EAAK,KAAA,CACd,EAAK,KAAA,CAAM,QAAA,CAAS,GAAG,WAAA,GACvB,EAAK,KAAA,CAAM,KAAA,CAAM,GAErB,GAOF,IAAK,IAJD,EAAM,EAAI,QAAA,GAAW,WAAA,GACrB,EAAM,EAAI,MAAA,CACV,EAAS,EAAE,CAEN,EAAW,EAAG,EAAa,EAAG,GAAY,EAAK,IAAY,CAClE,IAAI,EAAO,EAAI,MAAA,CAAO,GAClB,EAAc,EAAW,EAE7B,GAAK,EAAK,KAAA,CAAM,EAAK,SAAA,CAAU,SAAA,GAAc,GAAY,EAAM,CAE7D,GAAI,EAAc,EAAG,CACnB,IAAI,EAAgB,EAAK,KAAA,CAAM,KAAA,CAAM,IAAa,CAAC,CACnD,CAAA,EAAc,QAAW,CAAG,CAAC,EAAY,EAAY,CACrD,EAAc,KAAQ,CAAG,EAAO,MAAhC,CAEA,EAAO,IAAA,CACL,IAAI,EAAK,KAAA,CACP,EAAI,KAAA,CAAM,EAAY,GACtB,GAGN,CAEA,EAAa,EAAW,CAC1B,CAEF,CAEA,OAAO,CACT,EASA,EAAK,SAAA,CAAU,SAAA,CAAY,UAmC3B,EAAK,QAAA,CAAW,WACd,IAAI,CAAC,MAAA,CAAS,EAAE,AAClB,EAEA,EAAK,QAAA,CAAS,mBAAA,CAAsB,OAAO,MAAA,CAAO,MAmClD,EAAK,QAAA,CAAS,gBAAA,CAAmB,SAAU,CAAE,CAAE,CAAK,EAC9C,KAAS,IAAI,CAAC,mBAAA,EAChB,EAAK,KAAA,CAAM,IAAA,CAAK,6CAA+C,GAGjE,EAAG,KAAA,CAAQ,EACX,EAAK,QAAA,CAAS,mBAAmB,CAAC,EAAG,KAAA,CAAM,CAAG,CAChD,EAQA,EAAK,QAAA,CAAS,2BAAA,CAA8B,SAAU,CAAE,EACnC,EAAG,KAAA,EAAU,EAAG,KAAA,IAAS,IAAI,CAAC,mBAAjD,EAGE,EAAK,KAAA,CAAM,IAAA,CAAK,kGAAmG,EAEvH,EAYA,EAAK,QAAA,CAAS,IAAA,CAAO,SAAU,CAAU,EACvC,IAAI,EAAW,IAAI,EAAK,QAAxB,CAYA,OAVA,EAAW,OAAA,CAAQ,SAAU,CAAM,EACjC,IAAI,EAAK,EAAK,QAAA,CAAS,mBAAmB,CAAC,EAAO,CAElD,GAAI,EACF,EAAS,GAAA,CAAI,QAEb,MAAM,AAAI,MAAM,sCAAwC,EAE5D,GAEO,CACT,EASA,EAAK,QAAA,CAAS,SAAA,CAAU,GAAA,CAAM,WAC5B,IAAI,EAAM,MAAM,SAAA,CAAU,KAAA,CAAM,IAAA,CAAK,WAErC,EAAI,OAAA,CAAQ,SAAU,CAAE,EACtB,EAAK,QAAA,CAAS,2BAAA,CAA4B,GAC1C,IAAI,CAAC,MAAA,CAAO,IAAA,CAAK,EACnB,EAAG,IAAI,CACT,EAWA,EAAK,QAAA,CAAS,SAAA,CAAU,KAAA,CAAQ,SAAU,CAAU,CAAE,CAAK,EACzD,EAAK,QAAA,CAAS,2BAAA,CAA4B,GAE1C,IAAI,EAAM,IAAI,CAAC,MAAA,CAAO,OAAA,CAAQ,GAC9B,GAAI,AAAO,IAAP,EACF,MAAM,AAAI,MAAM,0BAGlB,GAAY,EACZ,IAAI,CAAC,MAAA,CAAO,MAAA,CAAO,EAAK,EAAG,EAC7B,EAWA,EAAK,QAAA,CAAS,SAAA,CAAU,MAAA,CAAS,SAAU,CAAU,CAAE,CAAK,EAC1D,EAAK,QAAA,CAAS,2BAAA,CAA4B,GAE1C,IAAI,EAAM,IAAI,CAAC,MAAA,CAAO,OAAA,CAAQ,GAC9B,GAAI,AAAO,IAAP,EACF,MAAM,AAAI,MAAM,0BAGlB,IAAI,CAAC,MAAA,CAAO,MAAA,CAAO,EAAK,EAAG,EAC7B,EAOA,EAAK,QAAA,CAAS,SAAA,CAAU,MAAA,CAAS,SAAU,CAAE,EAC3C,IAAI,EAAM,IAAI,CAAC,MAAA,CAAO,OAAA,CAAQ,EACnB,CAAA,IAAP,GAIJ,IAAI,CAAC,MAAA,CAAO,MAAA,CAAO,EAAK,EAC1B,EASA,EAAK,QAAA,CAAS,SAAA,CAAU,GAAA,CAAM,SAAU,CAAM,EAG5C,IAAK,IAFD,EAAc,IAAI,CAAC,MAAA,CAAO,MAA9B,CAES,EAAI,EAAG,EAAI,EAAa,IAAK,CAIpC,IAAK,IAHD,EAAK,IAAI,CAAC,MAAM,CAAC,EAAE,CACnB,EAAO,EAAE,CAEJ,EAAI,EAAG,EAAI,EAAO,MAAA,CAAQ,IAAK,CACtC,IAAI,EAAS,EAAG,CAAM,CAAC,EAAE,CAAE,EAAG,GAE9B,GAAI,MAAA,GAAwC,AAAW,KAAX,GAE5C,GAAI,MAAM,OAAA,CAAQ,GAChB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAA,CAAQ,IACjC,EAAK,IAAA,CAAK,CAAM,CAAC,EAAE,OAGrB,EAAK,IAAA,CAAK,GAEd,CAEA,EAAS,CACX,CAEA,OAAO,CACT,EAYA,EAAK,QAAA,CAAS,SAAA,CAAU,SAAA,CAAY,SAAU,CAAG,CAAE,CAAQ,EACzD,IAAI,EAAQ,IAAI,EAAK,KAAA,CAAO,EAAK,GAEjC,OAAO,IAAI,CAAC,GAAA,CAAI,CAAC,EAAM,EAAE,GAAA,CAAI,SAAU,CAAC,EACtC,OAAO,EAAE,QAAT,EACF,EACF,EAMA,EAAK,QAAA,CAAS,SAAA,CAAU,KAAA,CAAQ,WAC9B,IAAI,CAAC,MAAA,CAAS,EAAE,AAClB,EASA,EAAK,QAAA,CAAS,SAAA,CAAU,MAAA,CAAS,WAC/B,OAAO,IAAI,CAAC,MAAA,CAAO,GAAA,CAAI,SAAU,CAAE,EAGjC,OAFA,EAAK,QAAA,CAAS,2BAAA,CAA4B,GAEnC,EAAG,KAAV,AACF,EACF,EAsBA,EAAK,MAAA,CAAS,SAAU,CAAQ,EAC9B,IAAI,CAAC,UAAA,CAAa,EAClB,IAAI,CAAC,QAAA,CAAW,GAAY,EAAE,AAChC,EAaA,EAAK,MAAA,CAAO,SAAA,CAAU,gBAAA,CAAmB,SAAU,CAAK,EAEtD,GAAI,AAAwB,GAAxB,IAAI,CAAC,QAAA,CAAS,MAAA,CAChB,OAAO,EAST,IANA,IAAI,EAAQ,EACR,EAAM,IAAI,CAAC,QAAA,CAAS,MAAA,CAAS,EAC7B,EAAc,EAAM,EACpB,EAAa,KAAK,KAAA,CAAM,EAAc,GACtC,EAAa,IAAI,CAAC,QAAQ,CAAC,AAAa,EAAb,EAAe,CAW5C,AATK,EAAc,IACf,EAAa,GACf,CAAA,EAAQ,CADV,EAII,EAAa,GACf,CAAA,EAAM,CADR,EAII,GAAc,IAIlB,EAAc,EAAM,EACpB,EAAa,EAAQ,KAAK,KAAA,CAAM,EAAc,GAC9C,EAAa,IAAI,CAAC,QAAQ,CAAC,AAAa,EAAb,EAAe,QAG5C,AAAI,GAAc,GAId,EAAa,EAHR,AAAa,EAAb,EAOL,EAAa,EACP,AAAA,CAAA,EAAa,CAAA,EAAK,QAE9B,EAWA,EAAK,MAAA,CAAO,SAAA,CAAU,MAAA,CAAS,SAAU,CAAS,CAAE,CAAG,EACrD,IAAI,CAAC,MAAA,CAAO,EAAW,EAAK,WAC1B,KAAM,iBACR,EACF,EAUA,EAAK,MAAA,CAAO,SAAA,CAAU,MAAA,CAAS,SAAU,CAAS,CAAE,CAAG,CAAE,CAAE,EACzD,IAAI,CAAC,UAAA,CAAa,EAClB,IAAI,EAAW,IAAI,CAAC,gBAAA,CAAiB,EAEjC,CAAA,IAAI,CAAC,QAAQ,CAAC,EAAS,EAAI,EAC7B,IAAI,CAAC,QAAQ,CAAC,EAAW,EAAE,CAAG,EAAG,IAAI,CAAC,QAAQ,CAAC,EAAW,EAAE,CAAE,GAE9D,IAAI,CAAC,QAAA,CAAS,MAAA,CAAO,EAAU,EAAG,EAAW,EAEjD,EAOA,EAAK,MAAA,CAAO,SAAA,CAAU,SAAA,CAAY,WAChC,GAAI,IAAI,CAAC,UAAA,CAAY,OAAO,IAAI,CAAC,UAAjC,CAKA,IAAK,IAHD,EAAe,EACf,EAAiB,IAAI,CAAC,QAAA,CAAS,MADnC,CAGS,EAAI,EAAG,EAAI,EAAgB,GAAK,EAAG,CAC1C,IAAI,EAAM,IAAI,CAAC,QAAQ,CAAC,EAAE,CAC1B,GAAgB,EAAM,CACxB,CAEA,OAAO,IAAI,CAAC,UAAA,CAAa,KAAK,IAAA,CAAK,EACrC,EAQA,EAAK,MAAA,CAAO,SAAA,CAAU,GAAA,CAAM,SAAU,CAAW,EAO/C,IANA,IAAI,EAAa,EACb,EAAI,IAAI,CAAC,QAAA,CAAU,EAAI,EAAY,QAAA,CACnC,EAAO,EAAE,MAAA,CAAQ,EAAO,EAAE,MAAA,CAC1B,EAAO,EAAG,EAAO,EACjB,EAAI,EAAG,EAAI,EAER,EAAI,GAAQ,EAAI,GAEjB,AADJ,CAAA,EAAO,CAAC,CAAC,EAAE,AAAF,EAAI,CAAA,EAAO,CAAC,CAAC,EAAE,AAAF,EAEpB,GAAK,EACI,EAAO,EAChB,GAAK,EACI,GAAQ,IACjB,GAAc,CAAC,CAAC,EAAI,EAAE,CAAG,CAAC,CAAC,EAAI,EAAE,CACjC,GAAK,EACL,GAAK,GAIT,OAAO,CACT,EASA,EAAK,MAAA,CAAO,SAAA,CAAU,UAAA,CAAa,SAAU,CAAW,EACtD,OAAO,IAAI,CAAC,GAAA,CAAI,GAAe,IAAI,CAAC,SAAA,IAAe,CACrD,EAOA,EAAK,MAAA,CAAO,SAAA,CAAU,OAAA,CAAU,WAG9B,IAAK,IAFD,EAAS,AAAI,MAAO,IAAI,CAAC,QAAA,CAAS,MAAA,CAAS,GAEtC,EAAI,EAAG,EAAI,EAAG,EAAI,IAAI,CAAC,QAAA,CAAS,MAAA,CAAQ,GAAK,EAAG,IACvD,CAAM,CAAC,EAAE,CAAG,IAAI,CAAC,QAAQ,CAAC,EAAE,CAG9B,OAAO,CACT,EAOA,EAAK,MAAA,CAAO,SAAA,CAAU,MAAA,CAAS,WAC7B,OAAO,IAAI,CAAC,QAAZ,AACF,EAmBA,EAAK,OAAA,CAAW,WACd,IAAI,EAAY,CACZ,QAAY,MACZ,OAAW,OACX,KAAS,OACT,KAAS,OACT,KAAS,MACT,IAAQ,MACR,KAAS,KACT,MAAU,MACV,IAAQ,IACR,MAAU,MACV,QAAY,MACZ,MAAU,MACV,KAAS,MACT,MAAU,KACV,QAAY,MACZ,QAAY,MACZ,QAAY,MACZ,MAAU,KACV,MAAU,MACV,OAAW,MACX,KAAS,KACX,EAEA,EAAY,CACV,MAAU,KACV,MAAU,GACV,MAAU,KACV,MAAU,KACV,KAAS,KACT,IAAQ,GACR,KAAS,EACX,EAGA,EAAI,WACJ,EAAI,qBACJ,EAAI,EAAI,WAER,EAAO,KAAO,EAAI,KAAO,EAAI,EAC7B,EAAO,KAAO,EAAI,KAAO,EAAI,EAAI,IAAM,EAAI,MAC3C,EAAO,KAAO,EAAI,KAAO,EAAI,EAAI,EAAI,EACrC,EAAM,KAAO,EAAI,KAAO,EAEtB,EAAU,IAAI,OAAO,GACrB,EAAU,IAAI,OAAO,GACrB,EAAU,IAAI,OAAO,GACrB,EAAS,IAAI,OAAO,GAEpB,EAAQ,kBACR,EAAS,iBACT,EAAQ,aACR,EAAS,kBACT,EAAU,KACV,EAAW,cACX,EAAW,AAAI,OAAO,sBACtB,EAAW,AAAI,OAAO,IAAM,EAAI,EAAI,gBAEpC,EAAQ,mBACR,EAAO,2IAEP,EAAO,iDAEP,EAAO,sFACP,EAAQ,oBAER,EAAO,WACP,EAAS,MACT,EAAQ,AAAI,OAAO,IAAM,EAAI,EAAI,gBAEjC,EAAgB,SAAuB,CAAC,EAC1C,IAAI,EACF,EACA,EACA,EACA,EACA,EACA,EAEF,GAAI,EAAE,MAAA,CAAS,EAAK,OAAO,EAiB3B,GAde,KADf,CAAA,EAAU,EAAE,MAAA,CAAO,EAAE,EAArB,GAEE,CAAA,EAAI,EAAQ,WAAA,GAAgB,EAAE,MAAA,CAAO,EADvC,EAKA,EAAK,EACL,EAAM,EAEF,EAAG,IAAA,CAAK,GAAM,EAAI,EAAE,OAAA,CAAQ,EAAG,QAC1B,EAAI,IAAA,CAAK,IAAM,CAAA,EAAI,EAAE,OAAA,CAAQ,EAAI,OAArC,EAGL,EAAK,EACL,EAAM,EACF,EAAG,IAAA,CAAK,GAAI,CACd,IAAI,EAAK,EAAG,IAAA,CAAK,GAEb,AADJ,CAAA,EAAK,CAAL,EACO,IAAA,CAAK,CAAE,CAAC,EAAE,IACf,EAAK,EACL,EAAI,EAAE,OAAA,CAAQ,EAAG,IAErB,MAAO,GAAI,EAAI,IAAA,CAAK,GAAI,CACtB,IAAI,EAAK,EAAI,IAAA,CAAK,GAClB,EAAO,CAAE,CAAC,EAAE,CAER,AADJ,CAAA,EAAM,CAAN,EACQ,IAAA,CAAK,KACX,EAAI,EACJ,EAAM,EACN,EAAM,EACN,EAAM,EACF,EAAI,IAAA,CAAK,GAAM,GAAQ,IAClB,EAAI,IAAA,CAAK,IAAM,EAAK,EAAS,EAAI,EAAE,OAAA,CAAQ,EAAG,KAC9C,EAAI,IAAA,CAAK,IAAM,CAAA,GAAQ,GAD4B,EAGhE,CAIA,GAAI,AADJ,CAAA,EAAK,CAAL,EACO,IAAA,CAAK,GAAI,CACd,IAAI,EAAK,EAAG,IAAA,CAAK,GAEjB,EAAI,AADJ,CAAA,EAAO,CAAE,CAAC,EAAE,AAAF,EACC,GACb,CAIA,GAAI,AADJ,CAAA,EAAK,CAAL,EACO,IAAA,CAAK,GAAI,CACd,IAAI,EAAK,EAAG,IAAA,CAAK,GACjB,EAAO,CAAE,CAAC,EAAE,CACZ,EAAS,CAAE,CAAC,EAAE,CAEV,AADJ,CAAA,EAAK,CAAL,EACO,IAAA,CAAK,IACV,CAAA,EAAI,EAAO,CAAS,CAAC,EAAO,AAAP,CAEzB,CAIA,GAAI,AADJ,CAAA,EAAK,CAAL,EACO,IAAA,CAAK,GAAI,CACd,IAAI,EAAK,EAAG,IAAA,CAAK,GACjB,EAAO,CAAE,CAAC,EAAE,CACZ,EAAS,CAAE,CAAC,EAAE,CAEV,AADJ,CAAA,EAAK,CAAL,EACO,IAAA,CAAK,IACV,CAAA,EAAI,EAAO,CAAS,CAAC,EAAO,AAAP,CAEzB,CAKA,GAFA,EAAK,EACL,EAAM,EACF,EAAG,IAAA,CAAK,GAAI,CACd,IAAI,EAAK,EAAG,IAAA,CAAK,GACjB,EAAO,CAAE,CAAC,EAAE,CAER,AADJ,CAAA,EAAK,CAAL,EACO,IAAA,CAAK,IACV,CAAA,EAAI,CADN,CAGF,MAAO,GAAI,EAAI,IAAA,CAAK,GAAI,CACtB,IAAI,EAAK,EAAI,IAAA,CAAK,GAClB,EAAO,CAAE,CAAC,EAAE,CAAG,CAAE,CAAC,EAAE,CAEhB,AADJ,CAAA,EAAM,CAAN,EACQ,IAAA,CAAK,IACX,CAAA,EAAI,CADN,CAGF,CAIA,GAAI,AADJ,CAAA,EAAK,CAAL,EACO,IAAA,CAAK,GAAI,CACd,IAAI,EAAK,EAAG,IAAA,CAAK,GACjB,EAAO,CAAE,CAAC,EAAE,CACZ,EAAK,EACL,EAAM,EACN,EAAM,EACF,CAAA,EAAG,IAAA,CAAK,IAAU,EAAI,IAAA,CAAK,IAAS,CAAE,EAAI,IAAA,CAAK,EAAA,GACjD,CAAA,EAAI,CADN,CAGF,CAeA,OAbA,EAAK,EACL,EAAM,EACF,EAAG,IAAA,CAAK,IAAM,EAAI,IAAA,CAAK,KACzB,EAAK,EACL,EAAI,EAAE,OAAA,CAAQ,EAAG,KAKJ,KAAX,GACF,CAAA,EAAI,EAAQ,WAAA,GAAgB,EAAE,MAAA,CAAO,EADvC,EAIO,CACT,EAEA,OAAO,SAAU,CAAK,EACpB,OAAO,EAAM,MAAA,CAAO,EACtB,CACF,IAEA,EAAK,QAAA,CAAS,gBAAA,CAAiB,EAAK,OAAA,CAAS,WAmB7C,EAAK,sBAAA,CAAyB,SAAU,CAAS,EAC/C,IAAI,EAAQ,EAAU,MAAA,CAAO,SAAU,CAAI,CAAE,CAAQ,EAEnD,OADA,CAAI,CAAC,EAAS,CAAG,EACV,CACT,EAAG,CAAC,GAEJ,OAAO,SAAU,CAAK,EACpB,GAAI,GAAS,CAAK,CAAC,EAAM,QAAA,GAAW,GAAK,EAAM,QAAA,GAAY,OAAO,CACpE,CACF,EAeA,EAAK,cAAA,CAAiB,EAAK,sBAAA,CAAuB,CAChD,IACA,OACA,QACA,SACA,QACA,MACA,SACA,OACA,KACA,QACA,KACA,MACA,MACA,MACA,KACA,KACA,KACA,UACA,OACA,MACA,KACA,MACA,SACA,QACA,OACA,MACA,KACA,OACA,SACA,OACA,OACA,QACA,MACA,OACA,MACA,MACA,MACA,MACA,OACA,KACA,MACA,OACA,MACA,MACA,MACA,UACA,IACA,KACA,KACA,OACA,KACA,KACA,MACA,OACA,QACA,MACA,OACA,SACA,MACA,KACA,QACA,OACA,OACA,KACA,UACA,KACA,MACA,MACA,KACA,MACA,QACA,KACA,OACA,KACA,QACA,MACA,MACA,SACA,OACA,MACA,OACA,MACA,SACA,QACA,KACA,OACA,OACA,OACA,MACA,QACA,OACA,OACA,QACA,QACA,OACA,OACA,MACA,KACA,MACA,OACA,KACA,QACA,MACA,KACA,OACA,OACA,OACA,QACA,QACA,QACA,MACA,OACA,MACA,OACA,OACA,QACA,MACA,MACA,OACD,EAED,EAAK,QAAA,CAAS,gBAAA,CAAiB,EAAK,cAAA,CAAgB,kBAqBpD,EAAK,OAAA,CAAU,SAAU,CAAK,EAC5B,OAAO,EAAM,MAAA,CAAO,SAAU,CAAC,EAC7B,OAAO,EAAE,OAAA,CAAQ,OAAQ,IAAI,OAAA,CAAQ,OAAQ,GAC/C,EACF,EAEA,EAAK,QAAA,CAAS,gBAAA,CAAiB,EAAK,OAAA,CAAS,WA2B7C,EAAK,QAAA,CAAW,WACd,IAAI,CAAC,KAAA,CAAQ,CAAA,EACb,IAAI,CAAC,KAAA,CAAQ,CAAC,EACd,IAAI,CAAC,EAAA,CAAK,EAAK,QAAA,CAAS,OAAxB,CACA,EAAK,QAAA,CAAS,OAAA,EAAW,CAC3B,EAUA,EAAK,QAAA,CAAS,OAAA,CAAU,EASxB,EAAK,QAAA,CAAS,SAAA,CAAY,SAAU,CAAG,EAGrC,IAAK,IAFD,EAAU,IAAI,EAAK,QAAA,CAAS,OAAhC,CAES,EAAI,EAAG,EAAM,EAAI,MAAA,CAAQ,EAAI,EAAK,IACzC,EAAQ,MAAA,CAAO,CAAG,CAAC,EAAE,EAIvB,OADA,EAAQ,MAAR,GACO,EAAQ,IAAf,AACF,EAWA,EAAK,QAAA,CAAS,UAAA,CAAa,SAAU,CAAM,QACzC,AAAI,iBAAkB,EACb,EAAK,QAAA,CAAS,eAAA,CAAgB,EAAO,IAAA,CAAM,EAAO,YAD3D,EAGS,EAAK,QAAA,CAAS,UAAA,CAAW,EAAO,IAAvC,CAEJ,EAiBA,EAAK,QAAA,CAAS,eAAA,CAAkB,SAAU,CAAG,CAAE,CAAY,EASzD,IARA,IAAI,EAAO,IAAI,EAAK,QAApB,CAEI,EAAQ,CAAC,CACX,KAAM,EACN,eAAgB,EAChB,IAAK,CACP,EAAE,CAEK,EAAM,MAAA,EAAQ,CACnB,IAAI,EAAQ,EAAM,GAAlB,GAGA,GAAI,EAAM,GAAA,CAAI,MAAA,CAAS,EAAG,CACxB,IACI,EADA,EAAO,EAAM,GAAA,CAAI,MAAA,CAAO,EAGxB,CAAA,KAAQ,EAAM,IAAA,CAAK,KAAA,CACrB,EAAa,EAAM,IAAA,CAAK,KAAK,CAAC,EAAK,EAEnC,EAAa,IAAI,EAAK,QAAtB,CACA,EAAM,IAAA,CAAK,KAAK,CAAC,EAAK,CAAG,GAGH,GAApB,EAAM,GAAA,CAAI,MAAA,EACZ,CAAA,EAAW,KAAA,CAAQ,CAAA,CADrB,EAIA,EAAM,IAAA,CAAK,CACT,KAAM,EACN,eAAgB,EAAM,cAAtB,CACA,IAAK,EAAM,GAAA,CAAI,KAAA,CAAM,EACvB,EACF,CAEA,GAAI,AAAwB,GAAxB,EAAM,cAAA,EAKV,GAAI,MAAO,EAAM,IAAA,CAAK,KAAA,CACpB,IAAI,EAAgB,EAAM,IAAA,CAAK,KAAK,CAAC,IAAI,KACpC,CACL,IAAI,EAAgB,IAAI,EAAK,QAA7B,AACA,CAAA,EAAM,IAAA,CAAK,KAAK,CAAC,IAAI,CAAG,CAC1B,CAgCA,GA9BwB,GAApB,EAAM,GAAA,CAAI,MAAA,EACZ,CAAA,EAAc,KAAA,CAAQ,CAAA,CADxB,EAIA,EAAM,IAAA,CAAK,CACT,KAAM,EACN,eAAgB,EAAM,cAAA,CAAiB,EACvC,IAAK,EAAM,GAAX,AACF,GAKI,EAAM,GAAA,CAAI,MAAA,CAAS,GACrB,EAAM,IAAA,CAAK,CACT,KAAM,EAAM,IAAZ,CACA,eAAgB,EAAM,cAAA,CAAiB,EACvC,IAAK,EAAM,GAAA,CAAI,KAAA,CAAM,EACvB,GAKsB,GAApB,EAAM,GAAA,CAAI,MAAA,EACZ,CAAA,EAAM,IAAA,CAAK,KAAA,CAAQ,CAAA,CADrB,EAOI,EAAM,GAAA,CAAI,MAAA,EAAU,EAAG,CACzB,GAAI,MAAO,EAAM,IAAA,CAAK,KAAA,CACpB,IAAI,EAAmB,EAAM,IAAA,CAAK,KAAK,CAAC,IAAI,KACvC,CACL,IAAI,EAAmB,IAAI,EAAK,QAAhC,AACA,CAAA,EAAM,IAAA,CAAK,KAAK,CAAC,IAAI,CAAG,CAC1B,CAEwB,GAApB,EAAM,GAAA,CAAI,MAAA,EACZ,CAAA,EAAiB,KAAA,CAAQ,CAAA,CAD3B,EAIA,EAAM,IAAA,CAAK,CACT,KAAM,EACN,eAAgB,EAAM,cAAA,CAAiB,EACvC,IAAK,EAAM,GAAA,CAAI,KAAA,CAAM,EACvB,EACF,CAKA,GAAI,EAAM,GAAA,CAAI,MAAA,CAAS,EAAG,CACxB,IAEI,EAFA,EAAQ,EAAM,GAAA,CAAI,MAAA,CAAO,GACzB,EAAQ,EAAM,GAAA,CAAI,MAAA,CAAO,EAGzB,CAAA,KAAS,EAAM,IAAA,CAAK,KAAA,CACtB,EAAgB,EAAM,IAAA,CAAK,KAAK,CAAC,EAAM,EAEvC,EAAgB,IAAI,EAAK,QAAzB,CACA,EAAM,IAAA,CAAK,KAAK,CAAC,EAAM,CAAG,GAGJ,GAApB,EAAM,GAAA,CAAI,MAAA,EACZ,CAAA,EAAc,KAAA,CAAQ,CAAA,CADxB,EAIA,EAAM,IAAA,CAAK,CACT,KAAM,EACN,eAAgB,EAAM,cAAA,CAAiB,EACvC,IAAK,EAAQ,EAAM,GAAA,CAAI,KAAA,CAAM,EAC/B,EACF,EACF,CAEA,OAAO,CACT,EAYA,EAAK,QAAA,CAAS,UAAA,CAAa,SAAU,CAAG,EAYtC,IAAK,IAXD,EAAO,IAAI,EAAK,QAAA,CAChB,EAAO,EAUF,EAAI,EAAG,EAAM,EAAI,MAAA,CAAQ,EAAI,EAAK,IAAK,CAC9C,IAAI,EAAO,CAAG,CAAC,EAAE,CACb,EAAS,GAAK,EAAM,EAExB,GAAI,AAAQ,KAAR,EACF,EAAK,KAAK,CAAC,EAAK,CAAG,EACnB,EAAK,KAAA,CAAQ,MAER,CACL,IAAI,EAAO,IAAI,EAAK,QAApB,AACA,CAAA,EAAK,KAAA,CAAQ,EAEb,EAAK,KAAK,CAAC,EAAK,CAAG,EACnB,EAAO,CACT,CACF,CAEA,OAAO,CACT,EAYA,EAAK,QAAA,CAAS,SAAA,CAAU,OAAA,CAAU,WAQhC,IAPA,IAAI,EAAQ,EAAE,CAEV,EAAQ,CAAC,CACX,OAAQ,GACR,KAAM,IAAI,AACZ,EAAE,CAEK,EAAM,MAAA,EAAQ,CACnB,IAAI,EAAQ,EAAM,GAAA,GACd,EAAQ,OAAO,IAAA,CAAK,EAAM,IAAA,CAAK,KAAA,EAC/B,EAAM,EAAM,MAFhB,AAII,CAAA,EAAM,IAAA,CAAK,KAAA,GAKb,EAAM,MAAA,CAAO,MAAA,CAAO,GACpB,EAAM,IAAA,CAAK,EAAM,MAAjB,GAGF,IAAK,IAAI,EAAI,EAAG,EAAI,EAAK,IAAK,CAC5B,IAAI,EAAO,CAAK,CAAC,EAAE,CAEnB,EAAM,IAAA,CAAK,CACT,OAAQ,EAAM,MAAA,CAAO,MAAA,CAAO,GAC5B,KAAM,EAAM,IAAA,CAAK,KAAK,CAAC,EAAK,AAC9B,EACF,CACF,CAEA,OAAO,CACT,EAYA,EAAK,QAAA,CAAS,SAAA,CAAU,QAAA,CAAW,WASjC,GAAI,IAAI,CAAC,IAAA,CACP,OAAO,IAAI,CAAC,IADd,CAQA,IAAK,IAJD,EAAM,IAAI,CAAC,KAAA,CAAQ,IAAM,IACzB,EAAS,OAAO,IAAA,CAAK,IAAI,CAAC,KAAA,EAAO,IAAA,GACjC,EAAM,EAAO,MAFjB,CAIS,EAAI,EAAG,EAAI,EAAK,IAAK,CAC5B,IAAI,EAAQ,CAAM,CAAC,EAAE,CACjB,EAAO,IAAI,CAAC,KAAK,CAAC,EAAM,CAE5B,EAAM,EAAM,EAAQ,EAAK,EAAzB,AACF,CAEA,OAAO,CACT,EAYA,EAAK,QAAA,CAAS,SAAA,CAAU,SAAA,CAAY,SAAU,CAAC,EAU7C,IATA,IAAI,EAAS,IAAI,EAAK,QAAA,CAClB,EAAQ,KAAA,EAER,EAAQ,CAAC,CACX,MAAO,EACP,OAAQ,EACR,KAAM,IAAI,AACZ,EAAE,CAEK,EAAM,MAAA,EAYX,IAAK,IALD,EAAS,OAAO,IAAA,CAAK,AANzB,CAAA,EAAQ,EAAM,GAAd,EAAA,EAM+B,KAAA,CAAM,KAAA,EACjC,EAAO,EAAO,MAAA,CACd,EAAS,OAAO,IAAA,CAAK,EAAM,IAAA,CAAK,KAAA,EAChC,EAAO,EAAO,MAHlB,CAKS,EAAI,EAAG,EAAI,EAAM,IAGxB,IAAK,IAFD,EAAQ,CAAM,CAAC,EAAE,CAEZ,EAAI,EAAG,EAAI,EAAM,IAAK,CAC7B,IAAI,EAAQ,CAAM,CAAC,EAAE,CAErB,GAAI,GAAS,GAAS,AAAS,KAAT,EAAc,CAClC,IAAI,EAAO,EAAM,IAAA,CAAK,KAAK,CAAC,EAAM,CAC9B,EAAQ,EAAM,KAAA,CAAM,KAAK,CAAC,EAAM,CAChC,EAAQ,EAAK,KAAA,EAAS,EAAM,KAAA,CAC5B,EAAO,KAAA,CAEP,CAAA,KAAS,EAAM,MAAA,CAAO,KAAA,CAKxB,AADA,CAAA,EAAO,EAAM,MAAA,CAAO,KAAK,CAAC,EAAM,AAAN,EACrB,KAAA,CAAQ,EAAK,KAAA,EAAS,GAO3B,AADA,CAAA,EAAO,IAAI,EAAK,QAAhB,AAAA,EACK,KAAA,CAAQ,EACb,EAAM,MAAA,CAAO,KAAK,CAAC,EAAM,CAAG,GAG9B,EAAM,IAAA,CAAK,CACT,MAAO,EACP,OAAQ,EACR,KAAM,CACR,EACF,CACF,CAIJ,OAAO,CACT,EACA,EAAK,QAAA,CAAS,OAAA,CAAU,WACtB,IAAI,CAAC,YAAA,CAAe,GACpB,IAAI,CAAC,IAAA,CAAO,IAAI,EAAK,QAArB,CACA,IAAI,CAAC,cAAA,CAAiB,EAAE,CACxB,IAAI,CAAC,cAAA,CAAiB,CAAC,CACzB,EAEA,EAAK,QAAA,CAAS,OAAA,CAAQ,SAAA,CAAU,MAAA,CAAS,SAAU,CAAI,EACrD,IAAI,EACA,EAAe,EAEnB,GAAI,EAAO,IAAI,CAAC,YAAA,CACd,MAAM,AAAI,MAAO,+BAGnB,IAAK,IAAI,EAAI,EACX,AADc,EAAI,EAAK,MAAA,EAAU,EAAI,IAAI,CAAC,YAAA,CAAa,MAAA,EACnD,CAAI,CAAC,EAAE,EAAI,IAAI,CAAC,YAAY,CAAC,EAAE,CAD4B,IAE/D,IAGF,IAAI,CAAC,QAAA,CAAS,GAGZ,EADE,AAA8B,GAA9B,IAAI,CAAC,cAAA,CAAe,MAAA,CACf,IAAI,CAAC,IADd,CAGS,IAAI,CAAC,cAAc,CAAC,IAAI,CAAC,cAAA,CAAe,MAAA,CAAS,EAAE,CAAC,KAA3D,CAGF,IAAK,IAAI,EAAI,EAAc,EAAI,EAAK,MAAA,CAAQ,IAAK,CAC/C,IAAI,EAAW,IAAI,EAAK,QAAA,CACpB,EAAO,CAAI,CAAC,EAAE,AAElB,CAAA,EAAK,KAAK,CAAC,EAAK,CAAG,EAEnB,IAAI,CAAC,cAAA,CAAe,IAAA,CAAK,CACvB,OAAQ,EACR,KAAM,EACN,MAAO,CACT,GAEA,EAAO,CACT,CAEA,EAAK,KAAA,CAAQ,CAAA,EACb,IAAI,CAAC,YAAA,CAAe,CACtB,EAEA,EAAK,QAAA,CAAS,OAAA,CAAQ,SAAA,CAAU,MAAA,CAAS,WACvC,IAAI,CAAC,QAAA,CAAS,EAChB,EAEA,EAAK,QAAA,CAAS,OAAA,CAAQ,SAAA,CAAU,QAAA,CAAW,SAAU,CAAM,EACzD,IAAK,IAAI,EAAI,IAAI,CAAC,cAAA,CAAe,MAAA,CAAS,EAAG,GAAK,EAAQ,IAAK,CAC7D,IAAI,EAAO,IAAI,CAAC,cAAc,CAAC,EAAE,CAC7B,EAAW,EAAK,KAAA,CAAM,QAD1B,EAGI,CAAA,KAAY,IAAI,CAAC,cAAA,CACnB,EAAK,MAAA,CAAO,KAAK,CAAC,EAAK,IAAA,CAAK,CAAG,IAAI,CAAC,cAAc,CAAC,EAAS,EAI5D,EAAK,KAAA,CAAM,IAAA,CAAO,EAElB,IAAI,CAAC,cAAc,CAAC,EAAS,CAAG,EAAK,KAArC,EAGF,IAAI,CAAC,cAAA,CAAe,GAApB,EACF,CACF,EAsBA,EAAK,KAAA,CAAQ,SAAU,CAAK,EAC1B,IAAI,CAAC,aAAA,CAAgB,EAAM,aAA3B,CACA,IAAI,CAAC,YAAA,CAAe,EAAM,YAA1B,CACA,IAAI,CAAC,QAAA,CAAW,EAAM,QAAtB,CACA,IAAI,CAAC,MAAA,CAAS,EAAM,MAApB,CACA,IAAI,CAAC,QAAA,CAAW,EAAM,QAAtB,AACF,EAyEA,EAAK,KAAA,CAAM,SAAA,CAAU,MAAA,CAAS,SAAU,CAAW,EACjD,OAAO,IAAI,CAAC,KAAA,CAAM,SAAU,CAAK,EAE/B,AADa,IAAI,EAAK,WAAA,CAAY,EAAa,GACxC,KAAP,EACF,EACF,EA2BA,EAAK,KAAA,CAAM,SAAA,CAAU,KAAA,CAAQ,SAAU,CAAE,EAoBvC,IAAK,IAZD,EAAQ,IAAI,EAAK,KAAA,CAAM,IAAI,CAAC,MAAA,EAC5B,EAAiB,OAAO,MAAA,CAAO,MAC/B,EAAe,OAAO,MAAA,CAAO,MAC7B,EAAiB,OAAO,MAAA,CAAO,MAC/B,EAAkB,OAAO,MAAA,CAAO,MAChC,EAAoB,OAAO,MAAA,CAAO,MAO7B,EAAI,EAAG,EAAI,IAAI,CAAC,MAAA,CAAO,MAAA,CAAQ,IACtC,CAAY,CAAC,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,CAAG,IAAI,EAAK,MAFzC,CAKD,EAAG,IAAA,CAAK,EAAO,GAEf,IAAK,IAAI,EAAI,EAAG,EAAI,EAAM,OAAA,CAAQ,MAAA,CAAQ,IAAK,CAS7C,IAAI,EAAS,EAAM,OAAO,CAAC,EAAE,CACzB,EAAQ,KACR,EAAgB,EAAK,GAAA,CAAI,KAH5B,CAMC,EADE,EAAO,WAAA,CACD,IAAI,CAAC,QAAA,CAAS,SAAA,CAAU,EAAO,IAAA,CAAM,CAC3C,OAAQ,EAAO,MAAf,AACF,GAEQ,CAAC,EAAO,IAAP,CAAY,CAGvB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAM,MAAA,CAAQ,IAAK,CACrC,IAAI,EAAO,CAAK,CAAC,EAAE,AAQnB,CAAA,EAAO,IAAA,CAAO,EAOd,IAAI,EAAe,EAAK,QAAA,CAAS,UAAA,CAAW,GACxC,EAAgB,IAAI,CAAC,QAAA,CAAS,SAAA,CAAU,GAAc,OAFzD,GAUD,GAAI,AAAyB,IAAzB,EAAc,MAAA,EAAgB,EAAO,QAAA,GAAa,EAAK,KAAA,CAAM,QAAA,CAAS,QAAA,CAAU,CAClF,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAA,CAAO,MAAA,CAAQ,IAAK,CAC7C,IAAI,EAAQ,EAAO,MAAM,CAAC,EAAE,AAC5B,CAAA,CAAe,CAAC,EAAM,CAAG,EAAK,GAAA,CAAI,KAAlC,AACF,CAEA,KACF,CAEA,IAAK,IAAI,EAAI,EAAG,EAAI,EAAc,MAAA,CAAQ,IASxC,IAAK,IAJD,EAAe,CAAa,CAAC,EAAE,CAC/B,EAAU,IAAI,CAAC,aAAa,CAAC,EAAa,CAC1C,EAAY,EAAQ,MAHvB,CAKQ,EAAI,EAAG,EAAI,EAAO,MAAA,CAAO,MAAA,CAAQ,IAAK,CAS7C,IAAI,EAAQ,EAAO,MAAM,CAAC,EAAE,CACxB,EAAe,CAAO,CAAC,EAAM,CAC7B,EAAuB,OAAO,IAAA,CAAK,GACnC,EAAY,EAAe,IAAM,EACjC,EAAuB,IAAI,EAAK,GAAA,CAAI,GAoBxC,GAbI,EAAO,QAAA,EAAY,EAAK,KAAA,CAAM,QAAA,CAAS,QAAA,GACzC,EAAgB,EAAc,KAAA,CAAM,GAEL,KAAA,IAA3B,CAAe,CAAC,EAAM,EACxB,CAAA,CAAe,CAAC,EAAM,CAAG,EAAK,GAAA,CAAI,QADpC,AAAA,GAUE,EAAO,QAAA,EAAY,EAAK,KAAA,CAAM,QAAA,CAAS,UAAA,CAAY,CACpB,KAAA,IAA7B,CAAiB,CAAC,EAAM,EAC1B,CAAA,CAAiB,CAAC,EAAM,CAAG,EAAK,GAAA,CAAI,KADtC,AAAA,EAIA,CAAiB,CAAC,EAAM,CAAG,CAAiB,CAAC,EAAM,CAAC,KAAA,CAAM,GAO1D,QACF,CAeA,GANA,CAAY,CAAC,EAAM,CAAC,MAAA,CAAO,EAAW,EAAO,KAAA,CAAO,SAAU,CAAC,CAAE,CAAC,EAAI,OAAO,EAAI,CAAE,IAM/E,CAAc,CAAC,EAAU,EAI7B,IAAK,IAAI,EAAI,EAAG,EAAI,EAAqB,MAAA,CAAQ,IAAK,CAOpD,IAGI,EAHA,EAAsB,CAAoB,CAAC,EAAE,CAC7C,EAAmB,IAAI,EAAK,QAAA,CAAU,EAAqB,GAC3D,EAAW,CAAY,CAAC,EAAoB,AAG3C,AAAmD,MAAA,IAAnD,CAAA,EAAa,CAAc,CAAC,EAAgB,AAAhB,EAC/B,CAAc,CAAC,EAAiB,CAAG,IAAI,EAAK,SAAA,CAAW,EAAc,EAAO,GAE5E,EAAW,GAAA,CAAI,EAAc,EAAO,EAGxC,CAEA,CAAc,CAAC,EAAU,CAAG,CAAA,EAC9B,CAEJ,CAQA,GAAI,EAAO,QAAA,GAAa,EAAK,KAAA,CAAM,QAAA,CAAS,QAAA,CAC1C,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAA,CAAO,MAAA,CAAQ,IAAK,CAC7C,IAAI,EAAQ,EAAO,MAAM,CAAC,EAAE,AAC5B,CAAA,CAAe,CAAC,EAAM,CAAG,CAAe,CAAC,EAAM,CAAC,SAAA,CAAU,EAC5D,CAEJ,CAUA,IAAK,IAHD,EAAqB,EAAK,GAAA,CAAI,QAAA,CAC9B,EAAuB,EAAK,GAAA,CAAI,KAFnC,CAIQ,EAAI,EAAG,EAAI,IAAI,CAAC,MAAA,CAAO,MAAA,CAAQ,IAAK,CAC3C,IAAI,EAAQ,IAAI,CAAC,MAAM,CAAC,EAAE,AAEtB,CAAA,CAAe,CAAC,EAAM,EACxB,CAAA,EAAqB,EAAmB,SAAA,CAAU,CAAe,CAAC,EAAM,CAAA,EAGtE,CAAiB,CAAC,EAAM,EAC1B,CAAA,EAAuB,EAAqB,KAAA,CAAM,CAAiB,CAAC,EAAM,CAAA,CAE9E,CAbA,IAeI,EAAoB,OAAO,IAAA,CAAK,GAChC,EAAU,EAAE,CACZ,EAAU,OAAO,MAAA,CAAO,MAY5B,GAAI,EAAM,SAAA,GAAa,CACrB,EAAoB,OAAO,IAAA,CAAK,IAAI,CAAC,YAArC,EAEA,IAAK,IAAI,EAAI,EAAG,EAAI,EAAkB,MAAA,CAAQ,IAAK,CACjD,IAAI,EAAmB,CAAiB,CAAC,EAAE,CACvC,EAAW,EAAK,QAAA,CAAS,UAAA,CAAW,EACxC,CAAA,CAAc,CAAC,EAAiB,CAAG,IAAI,EAAK,SAA5C,AACF,CACF,CAEA,IAAK,IAAI,EAAI,EAAG,EAAI,EAAkB,MAAA,CAAQ,IAAK,CASjD,IAAI,EAAW,EAAK,QAAA,CAAS,UAAA,CAAW,CAAiB,CAAC,EAAE,EACxD,EAAS,EAAS,MAFrB,CAID,GAAK,EAAmB,QAAA,CAAS,KAI7B,EAAqB,QAAA,CAAS,IAIlC,IAEI,EAFA,EAAc,IAAI,CAAC,YAAY,CAAC,EAAS,CACzC,EAAQ,CAAY,CAAC,EAAS,SAAA,CAAU,CAAC,UAAA,CAAW,GAGxD,GAAK,AAAgC,KAAA,IAAhC,CAAA,EAAW,CAAO,CAAC,EAAM,AAAN,EACtB,EAAS,KAAA,EAAS,EAClB,EAAS,SAAA,CAAU,OAAA,CAAQ,CAAc,CAAC,EAAS,MAC9C,CACL,IAAI,EAAQ,CACV,IAAK,EACL,MAAO,EACP,UAAW,CAAc,CAAC,EAAS,AACrC,CACA,CAAA,CAAO,CAAC,EAAO,CAAG,EAClB,EAAQ,IAAA,CAAK,EACf,EACF,CAKA,OAAO,EAAQ,IAAA,CAAK,SAAU,CAAC,CAAE,CAAC,EAChC,OAAO,EAAE,KAAA,CAAQ,EAAE,KAAnB,AACF,EACF,EAUA,EAAK,KAAA,CAAM,SAAA,CAAU,MAAA,CAAS,WAC5B,IAAI,EAAgB,OAAO,IAAA,CAAK,IAAI,CAAC,aAAA,EAClC,IAAA,GACA,GAAA,CAAI,SAAU,CAAI,EACjB,MAAO,CAAC,EAAM,IAAI,CAAC,aAAa,CAAC,EAAK,CAAC,AACzC,EAAG,IAAI,EAEL,EAAe,OAAO,IAAA,CAAK,IAAI,CAAC,YAAA,EACjC,GAAA,CAAI,SAAU,CAAG,EAChB,MAAO,CAAC,EAAK,IAAI,CAAC,YAAY,CAAC,EAAI,CAAC,MAAvB,GAAgC,AAC/C,EAAG,IAAI,EAET,MAAO,CACL,QAAS,EAAK,OAAd,CACA,OAAQ,IAAI,CAAC,MAAb,CACA,aAAc,EACd,cAAe,EACf,SAAU,IAAI,CAAC,QAAA,CAAS,MAAxB,EACF,CACF,EAQA,EAAK,KAAA,CAAM,IAAA,CAAO,SAAU,CAAe,EACzC,IAAI,EAAQ,CAAC,EACT,EAAe,CAAC,EAChB,EAAoB,EAAgB,YAAA,CACpC,EAAgB,OAAO,MAAA,CAAO,MAC9B,EAA0B,EAAgB,aAAA,CAC1C,EAAkB,IAAI,EAAK,QAAA,CAAS,OAAA,CACpC,EAAW,EAAK,QAAA,CAAS,IAAA,CAAK,EAAgB,QANlD,CAQI,CAAA,EAAgB,OAAA,EAAW,EAAK,OAAA,EAClC,EAAK,KAAA,CAAM,IAAA,CAAK,4EAA8E,EAAK,OAAA,CAAU,sCAAwC,EAAgB,OAAA,CAAU,KAGjL,IAAK,IAAI,EAAI,EAAG,EAAI,EAAkB,MAAA,CAAQ,IAAK,CACjD,IAAI,EAAQ,CAAiB,CAAC,EAAE,CAC5B,EAAM,CAAK,CAAC,EAAE,CACd,EAAW,CAAK,CAAC,EAAE,AAEvB,CAAA,CAAY,CAAC,EAAI,CAAG,IAAI,EAAK,MAAA,CAAO,EACtC,CAEA,IAAK,IAAI,EAAI,EAAG,EAAI,EAAwB,MAAA,CAAQ,IAAK,CACvD,IAAI,EAAQ,CAAuB,CAAC,EAAE,CAClC,EAAO,CAAK,CAAC,EAAE,CACf,EAAU,CAAK,CAAC,EAAE,CAEtB,EAAgB,MAAA,CAAO,GACvB,CAAa,CAAC,EAAK,CAAG,CACxB,CAWA,OATA,EAAgB,MAAhB,GAEA,EAAM,MAAA,CAAS,EAAgB,MAA/B,CAEA,EAAM,YAAA,CAAe,EACrB,EAAM,aAAA,CAAgB,EACtB,EAAM,QAAA,CAAW,EAAgB,IAAjC,CACA,EAAM,QAAA,CAAW,EAEV,IAAI,EAAK,KAAA,CAAM,EACxB,EA8BA,EAAK,OAAA,CAAU,WACb,IAAI,CAAC,IAAA,CAAO,KACZ,IAAI,CAAC,OAAA,CAAU,OAAO,MAAA,CAAO,MAC7B,IAAI,CAAC,UAAA,CAAa,OAAO,MAAA,CAAO,MAChC,IAAI,CAAC,aAAA,CAAgB,OAAO,MAAA,CAAO,MACnC,IAAI,CAAC,oBAAA,CAAuB,CAAC,EAC7B,IAAI,CAAC,YAAA,CAAe,CAAC,EACrB,IAAI,CAAC,SAAA,CAAY,EAAK,SAAtB,CACA,IAAI,CAAC,QAAA,CAAW,IAAI,EAAK,QAAzB,CACA,IAAI,CAAC,cAAA,CAAiB,IAAI,EAAK,QAA/B,CACA,IAAI,CAAC,aAAA,CAAgB,EACrB,IAAI,CAAC,EAAA,CAAK,IACV,IAAI,CAAC,GAAA,CAAM,IACX,IAAI,CAAC,SAAA,CAAY,EACjB,IAAI,CAAC,iBAAA,CAAoB,EAAE,AAC7B,EAcA,EAAK,OAAA,CAAQ,SAAA,CAAU,GAAA,CAAM,SAAU,CAAG,EACxC,IAAI,CAAC,IAAA,CAAO,CACd,EAkCA,EAAK,OAAA,CAAQ,SAAA,CAAU,KAAA,CAAQ,SAAU,CAAS,CAAE,CAAU,EAC5D,GAAI,KAAK,IAAA,CAAK,GACZ,MAAM,AAAI,WAAY,UAAY,EAAY,mCAGhD,CAAA,IAAI,CAAC,OAAO,CAAC,EAAU,CAAG,GAAc,CAAC,CAC3C,EAUA,EAAK,OAAA,CAAQ,SAAA,CAAU,CAAA,CAAI,SAAU,CAAM,EACrC,EAAS,EACX,IAAI,CAAC,EAAA,CAAK,EACD,EAAS,EAClB,IAAI,CAAC,EAAA,CAAK,EAEV,IAAI,CAAC,EAAA,CAAK,CAEd,EASA,EAAK,OAAA,CAAQ,SAAA,CAAU,EAAA,CAAK,SAAU,CAAM,EAC1C,IAAI,CAAC,GAAA,CAAM,CACb,EAmBA,EAAK,OAAA,CAAQ,SAAA,CAAU,GAAA,CAAM,SAAU,CAAG,CAAE,CAAU,EACpD,IAAI,EAAS,CAAG,CAAC,IAAI,CAAC,IAAA,CAAK,CACvB,EAAS,OAAO,IAAA,CAAK,IAAI,CAAC,OAD9B,CAGA,CAAA,IAAI,CAAC,UAAU,CAAC,EAAO,CAAG,GAAc,CAAC,EACzC,IAAI,CAAC,aAAA,EAAiB,EAEtB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAA,CAAQ,IAAK,CACtC,IAAI,EAAY,CAAM,CAAC,EAAE,CACrB,EAAY,IAAI,CAAC,OAAO,CAAC,EAAU,CAAC,SAAA,CACpC,EAAQ,EAAY,EAAU,GAAO,CAAG,CAAC,EAAU,CACnD,EAAS,IAAI,CAAC,SAAA,CAAU,EAAO,CAC7B,OAAQ,CAAC,EAAU,AACrB,GACA,EAAQ,IAAI,CAAC,QAAA,CAAS,GAAA,CAAI,GAC1B,EAAW,IAAI,EAAK,QAAA,CAAU,EAAQ,GACtC,EAAa,OAAO,MAAA,CAAO,KAE/B,CAAA,IAAI,CAAC,oBAAoB,CAAC,EAAS,CAAG,EACtC,IAAI,CAAC,YAAY,CAAC,EAAS,CAAG,EAG9B,IAAI,CAAC,YAAY,CAAC,EAAS,EAAI,EAAM,MAArC,CAGA,IAAK,IAAI,EAAI,EAAG,EAAI,EAAM,MAAA,CAAQ,IAAK,CACrC,IAAI,EAAO,CAAK,CAAC,EAAE,CAUnB,GARwB,KAAA,GAApB,CAAU,CAAC,EAAK,EAClB,CAAA,CAAU,CAAC,EAAK,CAAG,CAAA,EAGrB,CAAU,CAAC,EAAK,EAAI,EAIhB,AAA4B,KAAA,GAA5B,IAAI,CAAC,aAAa,CAAC,EAAK,CAAe,CACzC,IAAI,EAAU,OAAO,MAAA,CAAO,KAC5B,CAAA,EAAQ,MAAS,CAAG,IAAI,CAAC,SAAzB,CACA,IAAI,CAAC,SAAA,EAAa,EAElB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAA,CAAQ,IACjC,CAAO,CAAC,CAAM,CAAC,EAAE,CAAC,CAAG,OAAO,MAAA,CAAO,KAGrC,CAAA,IAAI,CAAC,aAAa,CAAC,EAAK,CAAG,CAC7B,CAGmD,KAAA,GAA/C,IAAI,CAAC,aAAa,CAAC,EAAK,CAAC,EAAU,CAAC,EAAO,EAC7C,CAAA,IAAI,CAAC,aAAa,CAAC,EAAK,CAAC,EAAU,CAAC,EAAO,CAAG,OAAO,MAAA,CAAO,KAD9D,EAMA,IAAK,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,iBAAA,CAAkB,MAAA,CAAQ,IAAK,CACtD,IAAI,EAAc,IAAI,CAAC,iBAAiB,CAAC,EAAE,CACvC,EAAW,EAAK,QAAQ,CAAC,EAAY,AAEuB,MAAA,GAA5D,IAAI,CAAC,aAAa,CAAC,EAAK,CAAC,EAAU,CAAC,EAAO,CAAC,EAAY,EAC1D,CAAA,IAAI,CAAC,aAAa,CAAC,EAAK,CAAC,EAAU,CAAC,EAAO,CAAC,EAAY,CAAG,EAAE,AAAF,EAG7D,IAAI,CAAC,aAAa,CAAC,EAAK,CAAC,EAAU,CAAC,EAAO,CAAC,EAAY,CAAC,IAAA,CAAK,EAChE,CACF,CAEF,CACF,EAOA,EAAK,OAAA,CAAQ,SAAA,CAAU,4BAAA,CAA+B,WAOpD,IAAK,IALD,EAAY,OAAO,IAAA,CAAK,IAAI,CAAC,YAAA,EAC7B,EAAiB,EAAU,MAAA,CAC3B,EAAc,CAAC,EACf,EAAqB,CAAC,EAEjB,EAAI,EAAG,EAAI,EAAgB,IAAK,CACvC,IAAI,EAAW,EAAK,QAAA,CAAS,UAAA,CAAW,CAAS,CAAC,EAAE,EAChD,EAAQ,EAAS,SADrB,AAGA,CAAA,CAAkB,CAAC,EAAM,EAAK,CAAA,CAAkB,CAAC,EAAM,CAAG,CAAA,EAC1D,CAAkB,CAAC,EAAM,EAAI,EAE7B,CAAW,CAAC,EAAM,EAAK,CAAA,CAAW,CAAC,EAAM,CAAG,CAAA,EAC5C,CAAW,CAAC,EAAM,EAAI,IAAI,CAAC,YAAY,CAAC,EAAS,AACnD,CAIA,IAAK,IAFD,EAAS,OAAO,IAAA,CAAK,IAAI,CAAC,OAA9B,EAES,EAAI,EAAG,EAAI,EAAO,MAAA,CAAQ,IAAK,CACtC,IAAI,EAAY,CAAM,CAAC,EAAE,AACzB,CAAA,CAAW,CAAC,EAAU,CAAG,CAAW,CAAC,EAAU,CAAG,CAAkB,CAAC,EAAU,AACjF,CAEA,IAAI,CAAC,kBAAA,CAAqB,CAC5B,EAOA,EAAK,OAAA,CAAQ,SAAA,CAAU,kBAAA,CAAqB,WAM1C,IAAK,IALD,EAAe,CAAC,EAChB,EAAY,OAAO,IAAA,CAAK,IAAI,CAAC,oBAAA,EAC7B,EAAkB,EAAU,MAAA,CAC5B,EAAe,OAAO,MAAA,CAAO,MAExB,EAAI,EAAG,EAAI,EAAiB,IAAK,CAaxC,IAAK,IAZD,EAAW,EAAK,QAAA,CAAS,UAAA,CAAW,CAAS,CAAC,EAAE,EAChD,EAAY,EAAS,SAAA,CACrB,EAAc,IAAI,CAAC,YAAY,CAAC,EAAS,CACzC,EAAc,IAAI,EAAK,MAAA,CACvB,EAAkB,IAAI,CAAC,oBAAoB,CAAC,EAAS,CACrD,EAAQ,OAAO,IAAA,CAAK,GACpB,EAAc,EAAM,MANxB,CASI,EAAa,IAAI,CAAC,OAAO,CAAC,EAAU,CAAC,KAAA,EAAS,EAC9C,EAAW,IAAI,CAAC,UAAU,CAAC,EAAS,MAAA,CAAO,CAAC,KAAA,EAAS,EAEhD,EAAI,EAAG,EAAI,EAAa,IAAK,CACpC,IAGI,EAAK,EAAO,EAHZ,EAAO,CAAK,CAAC,EAAE,CACf,EAAK,CAAe,CAAC,EAAK,CAC1B,EAAY,IAAI,CAAC,aAAa,CAAC,EAAK,CAAC,MAAA,AAGrC,AAAuB,MAAA,IAAvB,CAAY,CAAC,EAAK,EACpB,EAAM,EAAK,GAAA,CAAI,IAAI,CAAC,aAAa,CAAC,EAAK,CAAE,IAAI,CAAC,aAA9C,EACA,CAAY,CAAC,EAAK,CAAG,GAErB,EAAM,CAAY,CAAC,EAAK,CAM1B,EAAqB,KAAK,KAAA,CAAM,AAAQ,IADxC,CAAA,EAFQ,EAAQ,CAAA,AAAA,CAAA,IAAI,CAAC,GAAA,CAAM,CAAA,EAAK,CAAA,EAAO,CAAA,IAAI,CAAC,GAAA,CAAO,CAAA,EAAI,IAAI,CAAC,EAAA,CAAK,IAAI,CAAC,EAAA,CAAM,CAAA,EAAc,IAAI,CAAC,kBAAkB,CAAC,EAAS,AAAT,CAAS,EAAM,CAAA,EACxH,EACA,CAAT,GACgD,IAQhD,EAAY,MAAA,CAAO,EAAW,EAChC,CAEA,CAAY,CAAC,EAAS,CAAG,CAC3B,CAEA,IAAI,CAAC,YAAA,CAAe,CACtB,EAOA,EAAK,OAAA,CAAQ,SAAA,CAAU,cAAA,CAAiB,WACtC,IAAI,CAAC,QAAA,CAAW,EAAK,QAAA,CAAS,SAAA,CAC5B,OAAO,IAAA,CAAK,IAAI,CAAC,aAAA,EAAe,IADlC,GAGF,EAUA,EAAK,OAAA,CAAQ,SAAA,CAAU,KAAA,CAAQ,WAK7B,OAJA,IAAI,CAAC,4BAAL,GACA,IAAI,CAAC,kBAAL,GACA,IAAI,CAAC,cAAL,GAEO,IAAI,EAAK,KAAA,CAAM,CACpB,cAAe,IAAI,CAAC,aAApB,CACA,aAAc,IAAI,CAAC,YAAnB,CACA,SAAU,IAAI,CAAC,QAAf,CACA,OAAQ,OAAO,IAAA,CAAK,IAAI,CAAC,OAAzB,EACA,SAAU,IAAI,CAAC,cAAf,AACF,EACF,EAgBA,EAAK,OAAA,CAAQ,SAAA,CAAU,GAAA,CAAM,SAAU,CAAE,EACvC,IAAI,EAAO,MAAM,SAAA,CAAU,KAAA,CAAM,IAAA,CAAK,UAAW,GACjD,EAAK,OAAA,CAAQ,IAAI,EACjB,EAAG,KAAA,CAAM,IAAI,CAAE,EACjB,EAaA,EAAK,SAAA,CAAY,SAAU,CAAI,CAAE,CAAK,CAAE,CAAQ,EAS9C,IAAK,IARD,EAAiB,OAAO,MAAA,CAAO,MAC/B,EAAe,OAAO,IAAA,CAAK,GAAY,CAAC,GAOnC,EAAI,EAAG,EAAI,EAAa,MAAA,CAAQ,IAAK,CAC5C,IAAI,EAAM,CAAY,CAAC,EAAE,AACzB,CAAA,CAAc,CAAC,EAAI,CAAG,CAAQ,CAAC,EAAI,CAAC,KAApC,EACF,CAEA,IAAI,CAAC,QAAA,CAAW,OAAO,MAAA,CAAO,MAEjB,KAAA,IAAT,IACF,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAG,OAAO,MAAA,CAAO,MACpC,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAG,EAEjC,EAWA,EAAK,SAAA,CAAU,SAAA,CAAU,OAAA,CAAU,SAAU,CAAc,EAGzD,IAAK,IAFD,EAAQ,OAAO,IAAA,CAAK,EAAe,QAAvC,EAES,EAAI,EAAG,EAAI,EAAM,MAAA,CAAQ,IAAK,CACrC,IAAI,EAAO,CAAK,CAAC,EAAE,CACf,EAAS,OAAO,IAAA,CAAK,EAAe,QAAQ,CAAC,EAAK,CAE3B,MAAA,GAAvB,IAAI,CAAC,QAAQ,CAAC,EAAK,EACrB,CAAA,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAG,OAAO,MAAA,CAAO,KADtC,EAIA,IAAK,IAAI,EAAI,EAAG,EAAI,EAAO,MAAA,CAAQ,IAAK,CACtC,IAAI,EAAQ,CAAM,CAAC,EAAE,CACjB,EAAO,OAAO,IAAA,CAAK,EAAe,QAAQ,CAAC,EAAK,CAAC,EAAM,CAEzB,MAAA,GAA9B,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,EAC5B,CAAA,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAG,OAAO,MAAA,CAAO,KAD7C,EAIA,IAAK,IAAI,EAAI,EAAG,EAAI,EAAK,MAAA,CAAQ,IAAK,CACpC,IAAI,EAAM,CAAI,CAAC,EAAE,AAEb,AAAmC,MAAA,GAAnC,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CACjC,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CAAG,EAAe,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CAE3E,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CAAG,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CAAC,MAAA,CAAO,EAAe,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CAGtH,CACF,CACF,CACF,EASA,EAAK,SAAA,CAAU,SAAA,CAAU,GAAA,CAAM,SAAU,CAAI,CAAE,CAAK,CAAE,CAAQ,EAC5D,GAAI,CAAE,CAAA,KAAQ,IAAI,CAAC,QAAO,AAAP,EAAW,CAC5B,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAG,OAAO,MAAA,CAAO,MACpC,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAG,EAC7B,MACF,CAEA,GAAI,CAAE,CAAA,KAAS,IAAI,CAAC,QAAQ,CAAC,EAAK,AAAL,EAAQ,CACnC,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAG,EAC7B,MACF,CAIA,IAAK,IAFD,EAAe,OAAO,IAAA,CAAK,GAEtB,EAAI,EAAG,EAAI,EAAa,MAAA,CAAQ,IAAK,CAC5C,IAAI,EAAM,CAAY,CAAC,EAAE,AAErB,CAAA,KAAO,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CACnC,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CAAG,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CAAC,MAAA,CAAO,CAAQ,CAAC,EAAI,EAEtF,IAAI,CAAC,QAAQ,CAAC,EAAK,CAAC,EAAM,CAAC,EAAI,CAAG,CAAQ,CAAC,EAAI,AAEnD,CACF,EAYA,EAAK,KAAA,CAAQ,SAAU,CAAS,EAC9B,IAAI,CAAC,OAAA,CAAU,EAAE,CACjB,IAAI,CAAC,SAAA,CAAY,CACnB,EA0BA,EAAK,KAAA,CAAM,QAAA,CAAW,IAAI,OAAQ,KAClC,EAAK,KAAA,CAAM,QAAA,CAAS,IAAA,CAAO,EAC3B,EAAK,KAAA,CAAM,QAAA,CAAS,OAAA,CAAU,EAC9B,EAAK,KAAA,CAAM,QAAA,CAAS,QAAA,CAAW,EAa/B,EAAK,KAAA,CAAM,QAAA,CAAW,CAIpB,SAAU,EAMV,SAAU,EAMV,WAAY,CACd,EAyBA,EAAK,KAAA,CAAM,SAAA,CAAU,MAAA,CAAS,SAAU,CAAM,EA+B5C,MA9BM,WAAY,GAChB,CAAA,EAAO,MAAA,CAAS,IAAI,CAAC,SADvB,AAAA,EAIM,UAAW,GACf,CAAA,EAAO,KAAA,CAAQ,CAAA,EAGX,gBAAiB,GACrB,CAAA,EAAO,WAAA,CAAc,CAAA,CADvB,EAIM,aAAc,GAClB,CAAA,EAAO,QAAA,CAAW,EAAK,KAAA,CAAM,QAAA,CAAS,IADxC,AAAA,EAIK,EAAO,QAAA,CAAW,EAAK,KAAA,CAAM,QAAA,CAAS,OAAA,EAAa,EAAO,IAAA,CAAK,MAAA,CAAO,IAAM,EAAK,KAAA,CAAM,QAAA,EAC1F,CAAA,EAAO,IAAA,CAAO,IAAM,EAAO,IAD7B,AAAA,EAIK,EAAO,QAAA,CAAW,EAAK,KAAA,CAAM,QAAA,CAAS,QAAA,EAAc,EAAO,IAAA,CAAK,KAAA,CAAM,KAAO,EAAK,KAAA,CAAM,QAAA,EAC3F,CAAA,EAAO,IAAA,CAAO,GAAK,EAAO,IAAA,CAAO,GADnC,EAIM,aAAc,GAClB,CAAA,EAAO,QAAA,CAAW,EAAK,KAAA,CAAM,QAAA,CAAS,QADxC,AAAA,EAIA,IAAI,CAAC,OAAA,CAAQ,IAAA,CAAK,GAEX,IAAI,AACb,EASA,EAAK,KAAA,CAAM,SAAA,CAAU,SAAA,CAAY,WAC/B,IAAK,IAAI,EAAI,EAAG,EAAI,IAAI,CAAC,OAAA,CAAQ,MAAA,CAAQ,IACvC,GAAI,IAAI,CAAC,OAAO,CAAC,EAAE,CAAC,QAAA,EAAY,EAAK,KAAA,CAAM,QAAA,CAAS,UAAA,CAClD,MAAO,CAAA,EAIX,MAAO,CAAA,CACT,EA4BA,EAAK,KAAA,CAAM,SAAA,CAAU,IAAA,CAAO,SAAU,CAAI,CAAE,CAAO,EACjD,GAAI,MAAM,OAAA,CAAQ,GAEhB,OADA,EAAK,OAAA,CAAQ,SAAU,CAAC,EAAI,IAAI,CAAC,IAAA,CAAK,EAAG,EAAK,KAAA,CAAM,KAAA,CAAM,GAAU,EAAG,IAAI,EACpE,IAAI,CAGb,IAAI,EAAS,GAAW,CAAC,EAKzB,OAJA,EAAO,IAAA,CAAO,EAAK,QAAnB,GAEA,IAAI,CAAC,MAAA,CAAO,GAEL,IAAI,AACb,EACA,EAAK,eAAA,CAAkB,SAAU,CAAO,CAAE,CAAK,CAAE,CAAG,EAClD,IAAI,CAAC,IAAA,CAAO,kBACZ,IAAI,CAAC,OAAA,CAAU,EACf,IAAI,CAAC,KAAA,CAAQ,EACb,IAAI,CAAC,GAAA,CAAM,CACb,EAEA,EAAK,eAAA,CAAgB,SAAA,CAAY,AAAI,QACrC,EAAK,UAAA,CAAa,SAAU,CAAG,EAC7B,IAAI,CAAC,OAAA,CAAU,EAAE,CACjB,IAAI,CAAC,GAAA,CAAM,EACX,IAAI,CAAC,MAAA,CAAS,EAAI,MAAlB,CACA,IAAI,CAAC,GAAA,CAAM,EACX,IAAI,CAAC,KAAA,CAAQ,EACb,IAAI,CAAC,mBAAA,CAAsB,EAAE,AAC/B,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,GAAA,CAAM,WAG9B,IAFA,IAAI,EAAQ,EAAK,UAAA,CAAW,OAA5B,CAEO,GACL,EAAQ,EAAM,IAAI,CAEtB,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,WAAA,CAAc,WAKtC,IAAK,IAJD,EAAY,EAAE,CACd,EAAa,IAAI,CAAC,KAAA,CAClB,EAAW,IAAI,CAAC,GAFpB,CAIS,EAAI,EAAG,EAAI,IAAI,CAAC,mBAAA,CAAoB,MAAA,CAAQ,IACnD,EAAW,IAAI,CAAC,mBAAmB,CAAC,EAAE,CACtC,EAAU,IAAA,CAAK,IAAI,CAAC,GAAA,CAAI,KAAA,CAAM,EAAY,IAC1C,EAAa,EAAW,EAM1B,OAHA,EAAU,IAAA,CAAK,IAAI,CAAC,GAAA,CAAI,KAAA,CAAM,EAAY,IAAI,CAAC,GAA/C,GACA,IAAI,CAAC,mBAAA,CAAoB,MAAA,CAAS,EAE3B,EAAU,IAAA,CAAK,GACxB,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,IAAA,CAAO,SAAU,CAAI,EAC7C,IAAI,CAAC,OAAA,CAAQ,IAAA,CAAK,CAChB,KAAM,EACN,IAAK,IAAI,CAAC,WAAV,GACA,MAAO,IAAI,CAAC,KAAZ,CACA,IAAK,IAAI,CAAC,GAAV,AACF,GAEA,IAAI,CAAC,KAAA,CAAQ,IAAI,CAAC,GAAlB,AACF,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,eAAA,CAAkB,WAC1C,IAAI,CAAC,mBAAA,CAAoB,IAAA,CAAK,IAAI,CAAC,GAAA,CAAM,GACzC,IAAI,CAAC,GAAA,EAAO,CACd,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,IAAA,CAAO,WAC/B,GAAI,IAAI,CAAC,GAAA,EAAO,IAAI,CAAC,MAAA,CACnB,OAAO,EAAK,UAAA,CAAW,GADzB,CAIA,IAAI,EAAO,IAAI,CAAC,GAAA,CAAI,MAAA,CAAO,IAAI,CAAC,GAAhC,EAEA,OADA,IAAI,CAAC,GAAA,EAAO,EACL,CACT,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,KAAA,CAAQ,WAChC,OAAO,IAAI,CAAC,GAAA,CAAM,IAAI,CAAC,KAAvB,AACF,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,MAAA,CAAS,WAC7B,IAAI,CAAC,KAAA,EAAS,IAAI,CAAC,GAAA,EACrB,CAAA,IAAI,CAAC,GAAA,EAAO,CAAA,EAGd,IAAI,CAAC,KAAA,CAAQ,IAAI,CAAC,GAAlB,AACF,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,MAAA,CAAS,WACjC,IAAI,CAAC,GAAA,EAAO,CACd,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,cAAA,CAAiB,WACzC,IAAI,EAAM,EAEV,GAEE,EAAW,AADX,CAAA,EAAO,IAAI,CAAC,IAAZ,EAAA,EACgB,UAAA,CAAW,SACpB,EAAW,IAAM,EAAW,GAAG,AAEpC,GAAQ,EAAK,UAAA,CAAW,GAAA,EAC1B,IAAI,CAAC,MADP,EAGF,EAEA,EAAK,UAAA,CAAW,SAAA,CAAU,IAAA,CAAO,WAC/B,OAAO,IAAI,CAAC,GAAA,CAAM,IAAI,CAAC,MAAvB,AACF,EAEA,EAAK,UAAA,CAAW,GAAA,CAAM,MACtB,EAAK,UAAA,CAAW,KAAA,CAAQ,QACxB,EAAK,UAAA,CAAW,IAAA,CAAO,OACvB,EAAK,UAAA,CAAW,aAAA,CAAgB,gBAChC,EAAK,UAAA,CAAW,KAAA,CAAQ,QACxB,EAAK,UAAA,CAAW,QAAA,CAAW,WAE3B,EAAK,UAAA,CAAW,QAAA,CAAW,SAAU,CAAK,EAIxC,OAHA,EAAM,MAAN,GACA,EAAM,IAAA,CAAK,EAAK,UAAA,CAAW,KAA3B,EACA,EAAM,MAAN,GACO,EAAK,UAAA,CAAW,OAAvB,AACF,EAEA,EAAK,UAAA,CAAW,OAAA,CAAU,SAAU,CAAK,EAQvC,GAPI,EAAM,KAAA,GAAU,IAClB,EAAM,MAAN,GACA,EAAM,IAAA,CAAK,EAAK,UAAA,CAAW,IAA3B,GAGF,EAAM,MAAN,GAEI,EAAM,IAAA,GACR,OAAO,EAAK,UAAA,CAAW,OADzB,AAGF,EAEA,EAAK,UAAA,CAAW,eAAA,CAAkB,SAAU,CAAK,EAI/C,OAHA,EAAM,MAAN,GACA,EAAM,cAAN,GACA,EAAM,IAAA,CAAK,EAAK,UAAA,CAAW,aAA3B,EACO,EAAK,UAAA,CAAW,OAAvB,AACF,EAEA,EAAK,UAAA,CAAW,QAAA,CAAW,SAAU,CAAK,EAIxC,OAHA,EAAM,MAAN,GACA,EAAM,cAAN,GACA,EAAM,IAAA,CAAK,EAAK,UAAA,CAAW,KAA3B,EACO,EAAK,UAAA,CAAW,OAAvB,AACF,EAEA,EAAK,UAAA,CAAW,MAAA,CAAS,SAAU,CAAK,EAClC,EAAM,KAAA,GAAU,GAClB,EAAM,IAAA,CAAK,EAAK,UAAA,CAAW,IAD7B,CAGF,EAaA,EAAK,UAAA,CAAW,aAAA,CAAgB,EAAK,SAAA,CAAU,SAA/C,CAEA,EAAK,UAAA,CAAW,OAAA,CAAU,SAAU,CAAK,EACvC,OAAa,CACX,IAAI,EAAO,EAAM,IAAjB,GAEA,GAAI,GAAQ,EAAK,UAAA,CAAW,GAAA,CAC1B,OAAO,EAAK,UAAA,CAAW,MADzB,CAKA,GAAI,AAAsB,IAAtB,EAAK,UAAA,CAAW,GAAU,CAC5B,EAAM,eAAN,GACA,QACF,CAEA,GAAI,AAAQ,KAAR,EACF,OAAO,EAAK,UAAA,CAAW,QADzB,CAIA,GAAI,AAAQ,KAAR,EAKF,OAJA,EAAM,MAAN,GACI,EAAM,KAAA,GAAU,GAClB,EAAM,IAAA,CAAK,EAAK,UAAA,CAAW,IAD7B,EAGO,EAAK,UAAA,CAAW,eAAvB,CAGF,GAAI,AAAQ,KAAR,EAKF,OAJA,EAAM,MAAN,GACI,EAAM,KAAA,GAAU,GAClB,EAAM,IAAA,CAAK,EAAK,UAAA,CAAW,IAD7B,EAGO,EAAK,UAAA,CAAW,QAAvB,CAMF,GAAY,KAAR,GAAe,AAAkB,IAAlB,EAAM,KAAA,IAQrB,AAAQ,KAAR,GAAe,AAAkB,IAAlB,EAAM,KAAA,GANvB,OADA,EAAM,IAAA,CAAK,EAAK,UAAA,CAAW,QAA3B,EACO,EAAK,UAAA,CAAW,OAAvB,CAWF,GAAI,EAAK,KAAA,CAAM,EAAK,UAAA,CAAW,aAAA,EAC7B,OAAO,EAAK,UAAA,CAAW,OADzB,AAGF,CACF,EAEA,EAAK,WAAA,CAAc,SAAU,CAAG,CAAE,CAAK,EACrC,IAAI,CAAC,KAAA,CAAQ,IAAI,EAAK,UAAA,CAAY,GAClC,IAAI,CAAC,KAAA,CAAQ,EACb,IAAI,CAAC,aAAA,CAAgB,CAAC,EACtB,IAAI,CAAC,SAAA,CAAY,CACnB,EAEA,EAAK,WAAA,CAAY,SAAA,CAAU,KAAA,CAAQ,WACjC,IAAI,CAAC,KAAA,CAAM,GAAX,GACA,IAAI,CAAC,OAAA,CAAU,IAAI,CAAC,KAAA,CAAM,OAA1B,CAIA,IAFA,IAAI,EAAQ,EAAK,WAAA,CAAY,WAA7B,CAEO,GACL,EAAQ,EAAM,IAAI,EAGpB,OAAO,IAAI,CAAC,KAAZ,AACF,EAEA,EAAK,WAAA,CAAY,SAAA,CAAU,UAAA,CAAa,WACtC,OAAO,IAAI,CAAC,OAAO,CAAC,IAAI,CAAC,SAAA,CAAU,AACrC,EAEA,EAAK,WAAA,CAAY,SAAA,CAAU,aAAA,CAAgB,WACzC,IAAI,EAAS,IAAI,CAAC,UAAlB,GAEA,OADA,IAAI,CAAC,SAAA,EAAa,EACX,CACT,EAEA,EAAK,WAAA,CAAY,SAAA,CAAU,UAAA,CAAa,WACtC,IAAI,EAAkB,IAAI,CAAC,aAA3B,CACA,IAAI,CAAC,KAAA,CAAM,MAAA,CAAO,GAClB,IAAI,CAAC,aAAA,CAAgB,CAAC,CACxB,EAEA,EAAK,WAAA,CAAY,WAAA,CAAc,SAAU,CAAM,EAC7C,IAAI,EAAS,EAAO,UAApB,GAEA,GAAI,AAAU,KAAA,GAAV,EAIJ,OAAQ,EAAO,IAAf,EACE,KAAK,EAAK,UAAA,CAAW,QAArB,CACE,OAAO,EAAK,WAAA,CAAY,aAAxB,AACF,MAAK,EAAK,UAAA,CAAW,KAArB,CACE,OAAO,EAAK,WAAA,CAAY,UAAxB,AACF,MAAK,EAAK,UAAA,CAAW,IAArB,CACE,OAAO,EAAK,WAAA,CAAY,SAAxB,AACF,SACE,IAAI,EAAe,4CAA8C,EAAO,IAAxE,AAMA,OAJI,EAAO,GAAA,CAAI,MAAA,EAAU,GACvB,CAAA,GAAgB,gBAAkB,EAAO,GAAA,CAAM,GADjD,EAIM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAO,KAAA,CAAO,EAAO,GAAnE,CACJ,CACF,EAEA,EAAK,WAAA,CAAY,aAAA,CAAgB,SAAU,CAAM,EAC/C,IAAI,EAAS,EAAO,aAApB,GAEA,GAAI,AAAU,KAAA,GAAV,GAIJ,OAAQ,EAAO,GAAf,EACE,IAAK,IACH,EAAO,aAAA,CAAc,QAAA,CAAW,EAAK,KAAA,CAAM,QAAA,CAAS,UAApD,CACA,KACF,KAAK,IACH,EAAO,aAAA,CAAc,QAAA,CAAW,EAAK,KAAA,CAAM,QAAA,CAAS,QAApD,CACA,KACF,SACE,IAAI,EAAe,kCAAoC,EAAO,GAAA,CAAM,GACpE,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAO,KAAA,CAAO,EAAO,GAAnE,CACJ,CAEA,IAAI,EAAa,EAAO,UAAxB,GAEA,GAAI,AAAc,KAAA,GAAd,EAAyB,CAC3B,IAAI,EAAe,wCACnB,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAO,KAAA,CAAO,EAAO,GAAnE,CACF,CAEA,OAAQ,EAAW,IAAnB,EACE,KAAK,EAAK,UAAA,CAAW,KAArB,CACE,OAAO,EAAK,WAAA,CAAY,UAAxB,AACF,MAAK,EAAK,UAAA,CAAW,IAArB,CACE,OAAO,EAAK,WAAA,CAAY,SAAxB,AACF,SACE,IAAI,EAAe,mCAAqC,EAAW,IAAA,CAAO,GAC1E,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAW,KAAA,CAAO,EAAW,GAA3E,CACJ,EACF,EAEA,EAAK,WAAA,CAAY,UAAA,CAAa,SAAU,CAAM,EAC5C,IAAI,EAAS,EAAO,aAApB,GAEA,GAAI,AAAU,KAAA,GAAV,GAIJ,GAAI,AAA8C,IAA9C,EAAO,KAAA,CAAM,SAAA,CAAU,OAAA,CAAQ,EAAO,GAAA,EAAY,CACpD,IAAI,EAAiB,EAAO,KAAA,CAAM,SAAA,CAAU,GAAA,CAAI,SAAU,CAAC,EAAI,MAAO,IAAM,EAAI,GAAI,GAAG,IAAA,CAAK,MACxF,EAAe,uBAAyB,EAAO,GAAA,CAAM,uBAAyB,CAElF,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAO,KAAA,CAAO,EAAO,GAAnE,CACF,CAEA,EAAO,aAAA,CAAc,MAAA,CAAS,CAAC,EAAO,GAAP,CAAW,CAE1C,IAAI,EAAa,EAAO,UAAxB,GAEA,GAAI,AAAc,KAAA,GAAd,EAAyB,CAC3B,IAAI,EAAe,+BACnB,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAO,KAAA,CAAO,EAAO,GAAnE,CACF,CAEA,GAAQ,EAAW,IAAnB,GACO,EAAK,UAAA,CAAW,IAArB,CACE,OAAO,EAAK,WAAA,CAAY,SAAxB,CAEA,IAAI,EAAe,0BAA4B,EAAW,IAAA,CAAO,GACjE,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAW,KAAA,CAAO,EAAW,GAA3E,EAEN,EAEA,EAAK,WAAA,CAAY,SAAA,CAAY,SAAU,CAAM,EAC3C,IAAI,EAAS,EAAO,aAApB,GAEA,GAAI,AAAU,KAAA,GAAV,GAIJ,EAAO,aAAA,CAAc,IAAA,CAAO,EAAO,GAAA,CAAI,WAAvC,GAE+B,IAA3B,EAAO,GAAA,CAAI,OAAA,CAAQ,MACrB,CAAA,EAAO,aAAA,CAAc,WAAA,CAAc,CAAA,CADrC,EAIA,IAAI,EAAa,EAAO,UAAxB,GAEA,GAAI,AAAc,KAAA,GAAd,EAAyB,CAC3B,EAAO,UAAP,GACA,MACF,CAEA,OAAQ,EAAW,IAAnB,EACE,KAAK,EAAK,UAAA,CAAW,IAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,SAAxB,AACF,MAAK,EAAK,UAAA,CAAW,KAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,UAAxB,AACF,MAAK,EAAK,UAAA,CAAW,aAArB,CACE,OAAO,EAAK,WAAA,CAAY,iBAAxB,AACF,MAAK,EAAK,UAAA,CAAW,KAArB,CACE,OAAO,EAAK,WAAA,CAAY,UAAxB,AACF,MAAK,EAAK,UAAA,CAAW,QAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,aAAxB,AACF,SACE,IAAI,EAAe,2BAA6B,EAAW,IAAA,CAAO,GAClE,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAW,KAAA,CAAO,EAAW,GAA3E,CACJ,EACF,EAEA,EAAK,WAAA,CAAY,iBAAA,CAAoB,SAAU,CAAM,EACnD,IAAI,EAAS,EAAO,aAApB,GAEA,GAAI,AAAU,KAAA,GAAV,GAIJ,IAAI,EAAe,SAAS,EAAO,GAAA,CAAK,IAExC,GAAI,MAAM,GAAe,CACvB,IAAI,EAAe,+BACnB,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAO,KAAA,CAAO,EAAO,GAAnE,CACF,CAEA,EAAO,aAAA,CAAc,YAAA,CAAe,EAEpC,IAAI,EAAa,EAAO,UAAxB,GAEA,GAAI,AAAc,KAAA,GAAd,EAAyB,CAC3B,EAAO,UAAP,GACA,MACF,CAEA,OAAQ,EAAW,IAAnB,EACE,KAAK,EAAK,UAAA,CAAW,IAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,SAAxB,AACF,MAAK,EAAK,UAAA,CAAW,KAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,UAAxB,AACF,MAAK,EAAK,UAAA,CAAW,aAArB,CACE,OAAO,EAAK,WAAA,CAAY,iBAAxB,AACF,MAAK,EAAK,UAAA,CAAW,KAArB,CACE,OAAO,EAAK,WAAA,CAAY,UAAxB,AACF,MAAK,EAAK,UAAA,CAAW,QAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,aAAxB,AACF,SACE,IAAI,EAAe,2BAA6B,EAAW,IAAA,CAAO,GAClE,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAW,KAAA,CAAO,EAAW,GAA3E,CACJ,EACF,EAEA,EAAK,WAAA,CAAY,UAAA,CAAa,SAAU,CAAM,EAC5C,IAAI,EAAS,EAAO,aAApB,GAEA,GAAI,AAAU,KAAA,GAAV,GAIJ,IAAI,EAAQ,SAAS,EAAO,GAAA,CAAK,IAEjC,GAAI,MAAM,GAAQ,CAChB,IAAI,EAAe,uBACnB,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAO,KAAA,CAAO,EAAO,GAAnE,CACF,CAEA,EAAO,aAAA,CAAc,KAAA,CAAQ,EAE7B,IAAI,EAAa,EAAO,UAAxB,GAEA,GAAI,AAAc,KAAA,GAAd,EAAyB,CAC3B,EAAO,UAAP,GACA,MACF,CAEA,OAAQ,EAAW,IAAnB,EACE,KAAK,EAAK,UAAA,CAAW,IAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,SAAxB,AACF,MAAK,EAAK,UAAA,CAAW,KAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,UAAxB,AACF,MAAK,EAAK,UAAA,CAAW,aAArB,CACE,OAAO,EAAK,WAAA,CAAY,iBAAxB,AACF,MAAK,EAAK,UAAA,CAAW,KAArB,CACE,OAAO,EAAK,WAAA,CAAY,UAAxB,AACF,MAAK,EAAK,UAAA,CAAW,QAArB,CAEE,OADA,EAAO,UAAP,GACO,EAAK,WAAA,CAAY,aAAxB,AACF,SACE,IAAI,EAAe,2BAA6B,EAAW,IAAA,CAAO,GAClE,OAAM,IAAI,EAAK,eAAA,CAAiB,EAAc,EAAW,KAAA,CAAO,EAAW,GAA3E,CACJ,EACF,EAMI,AAAA,SAAU,CAAI,CAAE,CAAO,EACnB,AAAkB,YAAlB,OAAO,QAAyB,OAAO,GAAA,CAEzC,OAAO,GAOP,0BAAiB,GAKrB,EAAE,EAAM,WAMN,OAAO,CACT,EACF,ID/4GA,IAAM,qCAAiB,SAAS,sBAAA,CAAuB,WACjD,gCAAY,IAAI,qCAAe,CAC/B,gCAAY,SAAS,cAAA,CAAe,UACpC,6BAAS,SAAS,cAAA,CAAe,UACjC,qCAAiB,SAAS,cAAA,CAAe,SACzC,gCAAY,SAAS,cAAA,CAAe,cACpC,kCAAc,SAAS,cAAA,CAAe,iBACtC,iCAAa,SAAS,cAAA,CAAe,aACvC,8BAAU,GAIR,4BAAQ,gCAAU,GAAA,CAAI,AAAA,GAC1B,CAAA,CACE,GAAI,EAAK,EAAT,CACA,QAAS,EAAK,SAAA,CAAU,OAAA,CAAQ,MAAO,KACvC,SAAU,EAAK,OAAA,CAAQ,QAAvB,CACA,KAAM,EAAK,OAAA,CAAQ,IAAA,CAAK,KAAA,CAAM,EAAE,IAChC,QAAS,EAAK,OAAA,CAAQ,OAAtB,CACA,SAAU,EAAK,OAAA,CAAQ,QAAvB,CACA,SAAU,EAAK,OAAA,CAAQ,QAAvB,AACF,CAAA,GAGF,IAAI,6BAAS,SAAU,CAAO,EAE5B,IAAI,EAAmB,SAAU,CAAK,CAAE,CAAK,CAAE,CAAM,EACnD,EAAM,MAAA,CAAO,SAAS,CAAG,CAAE,CAAQ,EACjC,OAAO,EAAM,IAAM,EAAS,YAA5B,AACF,EACF,EAGA,AAAA,uBAAA,2BAAK,QAAA,CAAS,gBAAA,CAAiB,EAAkB,UAIjD,EAAQ,QAAA,CAAS,MAAA,CAAO,AAAA,uBAAA,2BAAK,OAAA,CAAS,GACtC,EAAQ,cAAA,CAAe,MAAA,CAAO,AAAA,uBAAA,2BAAK,OAAA,CAAS,EAC9C,EAGI,qCAAiB,SAAU,CAAO,EAEpC,IAAI,EAAmB,SAAU,CAAK,CAAE,CAAK,CAAE,CAAM,EAMnD,OALI,CAAM,CAAC,EAAQ,EAAE,CACnB,EAAM,QAAQ,CAAC,YAAe,CAAG,CAAM,CAAC,EAAQ,EAAE,CAAC,GADrD,CAGE,EAAM,QAAQ,CAAC,YAAe,CAAG,GAE5B,EAAM,MAAA,CAAO,SAAS,CAAG,CAAE,CAAQ,EACxC,OAAO,EAAM,IAAM,EAAS,YAA5B,AACF,EACF,EAGA,AAAA,uBAAA,2BAAK,QAAA,CAAS,gBAAA,CAAiB,EAAkB,kBAGjD,EAAQ,QAAA,CAAS,MAAA,CAAO,AAAA,uBAAA,2BAAK,OAAA,CAAS,GAGtC,EAAQ,iBAAA,CAAkB,IAAA,CAAK,eACjC,EAGA,IAAI,0BAAM,AAAA,uBAAA,2BAAK,WACb,IAAI,CAAC,GAAA,CAAI,MACT,IAAI,CAAC,KAAA,CAAM,UAAW,CAAC,MAAO,EAAE,GAChC,IAAI,CAAC,KAAA,CAAM,WAAY,CAAC,MAAO,CAAC,GAChC,IAAI,CAAC,KAAA,CAAM,OAAQ,CAAC,MAAO,CAAC,GAC5B,IAAI,CAAC,KAAA,CAAM,UAAW,CAAC,MAAO,CAAC,GAC/B,IAAI,CAAC,KAAA,CAAM,WAAY,CAAE,MAAO,CAAE,GAClC,IAAI,CAAC,KAAA,CAAM,WAAY,CAAE,MAAO,CAAE,GAGlC,IAAI,CAAC,QAAA,CAAS,KAAd,GACA,IAAI,CAAC,cAAA,CAAe,KAApB,GAGA,IAAI,CAAC,EAAA,CAAG,IACR,IAAI,CAAC,CAAA,CAAE,GAKP,4BAAM,OAAA,CAAQ,SAAU,CAAG,EACzB,IAAI,CAAC,GAAA,CAAI,EACX,EAAG,IAAI,CACT,GAGM,iCAAa,AAAC,IACnB,EAAI,GAAK,MAEF,AADO,YAAY,IAAA,CAAM,AAAA,CAAA,EAAE,MAAA,EAAU,EAAE,UAAS,AAAT,EAAY,OAA1D,GACmB,AAA6C,KAA7C,CAAA,EAAE,OAAA,EAAW,EAAE,KAAA,EAAS,EAAE,QAAA,EAAY,CAAA,EAG1D,CAAA,gCAAU,UAAA,CAAa,iCAEvB,gCAAU,gBAAA,CAAiB,QAAS,AAAA,IAClC,EAAM,cAAN,GACA,iCAAW,SAAA,CAAU,GAAA,CAAI,UAEzB,0BAAI,KAAA,CAAM,SAAU,CAAC,EAEnB,EAAE,IAAA,CAAK,CAAC,CAAC,EAAE,EAAM,MAAA,CAAO,KAAA,CAAM,CAAC,CAAE,CAAE,YAAa,CAAA,EAAM,MAAO,GAAI,GAGjE,EAAE,IAAA,CAAK,CAAC,EAAE,EAAM,MAAA,CAAO,KAAA,CAAM,CAAC,CAAC,CAAE,CAAE,YAAa,CAAA,EAAO,MAAO,CAAE,GAGhE,EAAE,IAAA,CAAK,EAAM,MAAA,CAAO,KAAA,CAAO,CAAE,YAAa,CAAA,EAAO,aAAc,EAAG,MAAO,CAAE,EAC7E,GAEA,IAAI,EAAU,0BAAI,MAAA,CAAO,CAAC,EAAE,EAAM,MAAA,CAAO,KAAA,CAAM,KAAK,EAAE,EAAM,MAAA,CAAO,KAAA,CAAM,KAAK,EAAE,EAAM,MAAA,CAAO,KAAA,CAAM,EAAE,CAAC,CAElG,CAAA,EAAM,MAAA,CAAO,KAAA,EAAS,EAAQ,MAAA,EAChC,gCAAU,SAAA,CAAU,GAAA,CAAI,UACxB,qCAAe,SAAA,CAAU,MAAA,CAAO,UAChC,gCAAU,MAAA,CAAO,AAAA,IACf,EAAK,SAAA,CAAU,GAAA,CAAI,UACnB,EAAQ,IAAA,CAAK,AAAA,IACP,EAAO,GAAA,GAAQ,EAAK,EAAA,EACtB,EAAK,SAAA,CAAU,MAAA,CAAO,SAE1B,EACF,IACS,EAAM,MAAA,CAAO,KAAA,EACtB,gCAAU,SAAA,CAAU,MAAA,CAAO,UAC3B,qCAAe,SAAA,CAAU,GAAA,CAAI,YAE7B,gCAAU,SAAA,CAAU,GAAA,CAAI,UACxB,qCAAe,SAAA,CAAU,MAAA,CAAO,UAChC,gCAAU,GAAA,CAAI,AAAA,IACZ,EAAK,SAAA,CAAU,MAAA,CAAO,SACxB,GAEJ,GAGA,6BAAO,gBAAA,CAAiB,SAAU,AAAA,IAChC,EAAM,cAAN,GACA,iCAAW,SAAA,CAAU,GAAA,CAAI,UACzB,IAAI,EAAW,IAAI,SAAS,8BACxB,EAAU,EAAE,CAChB,IAAK,IAAI,KAAQ,EAAS,OAAA,GACxB,EAAU,IAAI,KAAY,EAAK,CAGjC,EAAU,EACP,MAAA,CAAO,AAAA,GAAW,AAAW,OAAX,GAAmB,AAAU,YAAV,GAAwB,EAAO,MAAA,EACpE,GAAA,CAAI,AAAA,IACH,IAAM,EAAa,CAAC,CAAC,EAAE,EAAO,CAAC,CAC/B,OAAO,EAAW,OAAA,CAAQ,MAAO,KACnC,GACC,IAAA,CAAK,KAGR,0BAAI,KAAA,CAAM,SAAU,CAAC,EAEnB,EAAE,IAAA,CAAK,EAAS,CAAE,YAAa,CAAA,EAAM,MAAO,GAAI,EAClD,GAEA,IAAI,EAAU,0BAAI,MAAA,CAAO,EAErB,CAAA,EAAQ,MAAA,EAAU,EAAQ,MAAA,EAC5B,gCAAU,SAAA,CAAU,GAAA,CAAI,UACxB,qCAAe,SAAA,CAAU,MAAA,CAAO,UAChC,gCAAU,MAAA,CAAO,AAAA,IACf,EAAK,SAAA,CAAU,GAAA,CAAI,UACnB,EAAQ,IAAA,CAAK,AAAA,IACP,EAAO,GAAA,GAAQ,EAAK,EAAA,EACtB,EAAK,SAAA,CAAU,MAAA,CAAO,SAE1B,EACF,IACS,EAAQ,MAAA,EACjB,gCAAU,SAAA,CAAU,MAAA,CAAO,UAC3B,qCAAe,SAAA,CAAU,GAAA,CAAI,YAE7B,gCAAU,SAAA,CAAU,GAAA,CAAI,UACxB,qCAAe,SAAA,CAAU,MAAA,CAAO,UAChC,gCAAU,GAAA,CAAI,AAAA,IACZ,EAAK,SAAA,CAAU,MAAA,CAAO,SACxB,GAEJ,GAGA,kCAAY,gBAAA,CAAiB,QAAS,AAAA,IACpC,6BAAO,KAAP,GACA,iCAAW,SAAA,CAAU,MAAA,CAAO,UAC5B,8BAAU,GACV,gCAAU,GAAA,CAAI,CAAC,EAAM,KACf,EAAQ,+BACV,EAAK,SAAA,CAAU,MAAA,CAAO,SAE1B,GACA,qCAAe,SAAA,CAAU,MAAA,CAAO,SAClC,GAGI,gCAAU,MAAA,EACZ,gCAAU,GAAA,CAAI,CAAC,EAAM,KACf,GAAS,IACX,EAAK,SAAA,CAAU,GAAA,CAAI,UACnB,iCAAW,SAAA,CAAU,MAAA,CAAO,YAE5B,EAAK,SAAA,CAAU,MAAA,CAAO,UACtB,iCAAW,SAAA,CAAU,GAAA,CAAI,UAE7B,GAIF,iCAAW,gBAAA,CAAiB,QAAS,AAAA,IAC/B,8BAAU,gCAAU,MAAA,EACtB,+BAAW,GACX,gCAAU,GAAA,CAAI,CAAC,EAAM,KACf,+BAAW,GAAS,gCAAU,MAAA,CAChC,EAAK,SAAA,CAAU,MAAA,CAAO,UAEtB,EAAK,SAAA,CAAU,GAAA,CAAI,SAEvB,IAEA,iCAAW,SAAA,CAAU,GAAA,CAAI,SAE7B,E,C","sources":["<anon>","node_modules/@threespot/freeze-scroll/dist/freeze-scroll.m.js","node_modules/@threespot/freeze-scroll/dist/webpack:/webpack/bootstrap","static/js/custom.js","static/js/modal.js","static/js/modals.js","node_modules/ev-emitter/ev-emitter.js","static/js/search.js","node_modules/lunr/lunr.js"],"sourcesContent":["(() => {\nfunction $parcel$interopDefault(a) {\n  return a && a.__esModule ? a.default : a;\n}\nvar $parcel$global =\ntypeof globalThis !== 'undefined'\n  ? globalThis\n  : typeof self !== 'undefined'\n  ? self\n  : typeof window !== 'undefined'\n  ? window\n  : typeof global !== 'undefined'\n  ? global\n  : {};\nvar $parcel$modules = {};\nvar $parcel$inits = {};\n\nvar parcelRequire = $parcel$global[\"parcelRequire7bfb\"];\nif (parcelRequire == null) {\n  parcelRequire = function(id) {\n    if (id in $parcel$modules) {\n      return $parcel$modules[id].exports;\n    }\n    if (id in $parcel$inits) {\n      var init = $parcel$inits[id];\n      delete $parcel$inits[id];\n      var module = {id: id, exports: {}};\n      $parcel$modules[id] = module;\n      init.call(module.exports, module, module.exports);\n      return module.exports;\n    }\n    var err = new Error(\"Cannot find module '\" + id + \"'\");\n    err.code = 'MODULE_NOT_FOUND';\n    throw err;\n  };\n\n  parcelRequire.register = function register(id, init) {\n    $parcel$inits[id] = init;\n  };\n\n  $parcel$global[\"parcelRequire7bfb\"] = parcelRequire;\n}\nparcelRequire.register(\"ee2Qt\", function(module, exports) {\nmodule.exports = /******/ function(modules1) {\n    /******/ // The module cache\n    /******/ var installedModules1 = {};\n    /******/ /******/ // The require function\n    /******/ function __webpack_require__1(moduleId1) {\n        /******/ /******/ // Check if module is in cache\n        /******/ if (installedModules1[moduleId1]) /******/ return installedModules1[moduleId1].exports;\n        /******/ // Create a new module (and put it into the cache)\n        /******/ var module1 = installedModules1[moduleId1] = {\n            /******/ i: moduleId1,\n            /******/ l: false,\n            /******/ exports: {}\n        };\n        /******/ /******/ // Execute the module function\n        /******/ modules1[moduleId1].call(module1.exports, module1, module1.exports, __webpack_require__1);\n        /******/ /******/ // Flag the module as loaded\n        /******/ module1.l = true;\n        /******/ /******/ // Return the exports of the module\n        /******/ return module1.exports;\n    /******/ }\n    /******/ /******/ /******/ // expose the modules object (__webpack_modules__)\n    /******/ __webpack_require__1.m = modules1;\n    /******/ /******/ // expose the module cache\n    /******/ __webpack_require__1.c = installedModules1;\n    /******/ /******/ // define getter function for harmony exports\n    /******/ __webpack_require__1.d = function(exports1, name1, getter1) {\n        /******/ if (!__webpack_require__1.o(exports1, name1)) /******/ Object.defineProperty(exports1, name1, {\n            /******/ configurable: false,\n            /******/ enumerable: true,\n            /******/ get: getter1\n        });\n    /******/ };\n    /******/ /******/ // define __esModule on exports\n    /******/ __webpack_require__1.r = function(exports1) {\n        /******/ Object.defineProperty(exports1, \"__esModule\", {\n            value: true\n        });\n    /******/ };\n    /******/ /******/ // getDefaultExport function for compatibility with non-harmony modules\n    /******/ __webpack_require__1.n = function(module1) {\n        /******/ var getter1 = module1 && module1.__esModule ? /******/ function getDefault1() {\n            return module1[\"default\"];\n        } : /******/ function getModuleExports1() {\n            return module1;\n        };\n        /******/ __webpack_require__1.d(getter1, \"a\", getter1);\n        /******/ return getter1;\n    /******/ };\n    /******/ /******/ // Object.prototype.hasOwnProperty.call\n    /******/ __webpack_require__1.o = function(object1, property1) {\n        return Object.prototype.hasOwnProperty.call(object1, property1);\n    };\n    /******/ /******/ // __webpack_public_path__\n    /******/ __webpack_require__1.p = \"\";\n    /******/ /******/ /******/ // Load entry module and return exports\n    /******/ return __webpack_require__1(__webpack_require__1.s = \"./index.js\");\n/******/ }({\n    /***/ \"./index.js\": /*!******************!*\\\n  !*** ./index.js ***!\n  \\******************/ /*! no static exports found */ /***/ function(module, exports, __webpack_require__) {\n        \"use strict\";\n        eval('//------------------------------------------------------------------------\\n// Disable scrolling (e.g. when modal window is open)\\n//\\n// Inspired by https://benfrain.com/preventing-body-scroll-for-modals-in-ios/\\n//\\n// Note: Once Safari and iOS Safari support the “touch-action” CSS property,\\n//       we can simply toggle a class that adds the following:\\n//\\n//       html,\\n//       body {\\n//         overflow: hidden !important;\\n//         touch-action: none !important;\\n//       }\\n//\\n//       /* Add class to elements like modal windows that still need to scroll */\\n//       .allow-scroll { touch-action: auto !important; }\\n//\\n// https://caniuse.com/#feat=css-touch-action\\n//------------------------------------------------------------------------\\n\\n\\nmodule.exports = {\\n  // Save current scroll position when scrolling is disabled so we can reset it when enabled\\n  _scrollPos: 0,\\n\\n  // Track whether or not we have injected CSS the already\\n  _hasCSS: false,\\n\\n  // Inject <style> tag with CSS rules (simpler than toggling a lot of inline styles)\\n  _injectCSS: function _injectCSS() {\\n\\n    // Don’t add styles more than once\\n    if (!this._hasCSS) {\\n      var css = \\'\\\\n        html.js-no-scroll { height: 100% !important; }\\\\n        .js-no-scroll body {\\\\n          height: 100%;\\\\n          overflow: hidden !important;\\\\n          position: fixed !important;\\\\n          width: 100% !important;\\\\n        }\\';\\n\\n      // Note: Setting “position: fixed” on the body prevents iOS from scrolling.\\n      //       However, this will cause the browser to scroll to the top, so we must\\n      //       add inline “height” and “top” styles to the body to address this.\\n\\n      // Create <style> tag and add to <head>\\n      // https://stackoverflow.com/a/524721/673457\\n      var styleEl = document.createElement(\\'style\\');\\n      styleEl.type = \\'text/css\\';\\n      styleEl.appendChild(document.createTextNode(css));\\n      document.head.appendChild(styleEl);\\n\\n      // Update var so we can avoid loading the CSS multiple times\\n      this._hasCSS = true;\\n    }\\n  },\\n\\n  _saveScrollPos: function _saveScrollPos() {\\n    this._scrollPos = window.pageYOffset || document.documentElement.scrollTop;\\n  },\\n\\n  /**\\n   * Disable scrolling\\n   */\\n  freeze: function freeze() {\\n    // Add required inline CSS (only runs first time)\\n    this._injectCSS();\\n\\n    this._saveScrollPos();\\n\\n    // Add class to prevent page scrolling (sets fixed position on body)\\n    document.documentElement.classList.add(\"js-no-scroll\");\\n\\n    // Add inline styles if not already at top of page\\n    if (this._scrollPos > 0) {\\n      document.body.style.height = \"calc(100% + \" + this._scrollPos + \"px)\";\\n      document.body.style.top = -this._scrollPos + \"px\";\\n    }\\n  },\\n\\n  /**\\n   * Enable scrolling\\n   */\\n  unfreeze: function unfreeze() {\\n    // Remove js-no-scroll class\\n    document.documentElement.classList.remove(\"js-no-scroll\");\\n\\n    if (this._scrollPos > 0) {\\n      // Remove inline styles on body, which causes the page to jump to the top.\\n      document.body.style.height = \"\";\\n      document.body.style.top = \"\";\\n\\n      // Disable native smooth scrolling before resetting the scroll position.\\n      // Otherwise, there would be an annoying jump after scrolling is enabled.\\n      if (document.documentElement.style.hasOwnProperty(\\'scrollBehavior\\')) {\\n        document.documentElement.style.scrollBehavior = \"auto\";\\n      }\\n\\n      // Reset scroll position to what it was before scrolling was disabled.\\n      window.scrollTo(0, this._scrollPos);\\n\\n      // Re-enable native smooth scrolling\\n      if (document.documentElement.style.hasOwnProperty(\\'scrollBehavior\\')) {\\n        document.documentElement.style.scrollBehavior = \"\";\\n      }\\n    }\\n  }\\n};\\n\\n//# sourceURL=webpack://%5Bname%5DLink/./index.js?');\n    /***/ }\n});\n\n});\n\n// by Threespot https://github.com/Threespot/modal\n// adding as a local module because Parcel is having\n// trouble with the npm installed module\n//------------------------------------------------------------------------\n// Modal windows\n//\n// - Progressively enhanced, works with pure CSS thanks to the `:target` pseudo selector\n// - Supports multiple toggles and multiple close buttons\n//\n// References:\n// - https://www.w3.org/TR/2017/NOTE-wai-aria-practices-1.1-20171214/examples/dialog-modal/dialog.html\n// - https://www.smashingmagazine.com/2014/09/making-modal-windows-better-for-everyone/\n// - https://www.smashingmagazine.com/2016/09/building-social-a-case-study-on-progressive-enhancement/\n// - https://bitsofco.de/accessible-modal-dialog/\n// - https://haltersweb.github.io/Accessibility/dialog.html\n// - https://yoast.com/dev-blog/the-a11y-monthly-making-modals-accessible/\n//\n// Note: Avoid aria-modal=\"true\" until support is beter\n//       https://labs.levelaccess.com/index.php/ARIA_Dialog_Role_with_modal_true\n//------------------------------------------------------------------------\n\nvar $ee2Qt = parcelRequire(\"ee2Qt\");\nvar $ba1d3eb1170b398e$exports = {};\n/**\n * EvEmitter v1.1.0\n * Lil' event emitter\n * MIT License\n */ /* jshint unused: true, undef: true, strict: true */ (function(global, factory) {\n    // universal module definition\n    /* jshint strict: false */ /* globals define, module, window */ if (typeof define == \"function\" && define.amd) // AMD - RequireJS\n    define(factory);\n    else if (0, $ba1d3eb1170b398e$exports) // CommonJS - Browserify, Webpack\n    $ba1d3eb1170b398e$exports = factory();\n    else // Browser globals\n    global.EvEmitter = factory();\n})(typeof window != \"undefined\" ? window : $ba1d3eb1170b398e$exports, function() {\n    \"use strict\";\n    function EvEmitter() {}\n    var proto = EvEmitter.prototype;\n    proto.on = function(eventName, listener) {\n        if (!eventName || !listener) return;\n        // set events hash\n        var events = this._events = this._events || {};\n        // set listeners array\n        var listeners = events[eventName] = events[eventName] || [];\n        // only add once\n        if (listeners.indexOf(listener) == -1) listeners.push(listener);\n        return this;\n    };\n    proto.once = function(eventName, listener) {\n        if (!eventName || !listener) return;\n        // add event\n        this.on(eventName, listener);\n        // set once flag\n        // set onceEvents hash\n        var onceEvents = this._onceEvents = this._onceEvents || {};\n        // set onceListeners object\n        var onceListeners = onceEvents[eventName] = onceEvents[eventName] || {};\n        // set flag\n        onceListeners[listener] = true;\n        return this;\n    };\n    proto.off = function(eventName, listener) {\n        var listeners = this._events && this._events[eventName];\n        if (!listeners || !listeners.length) return;\n        var index = listeners.indexOf(listener);\n        if (index != -1) listeners.splice(index, 1);\n        return this;\n    };\n    proto.emitEvent = function(eventName, args) {\n        var listeners = this._events && this._events[eventName];\n        if (!listeners || !listeners.length) return;\n        // copy over to avoid interference if .off() in listener\n        listeners = listeners.slice(0);\n        args = args || [];\n        // once stuff\n        var onceListeners = this._onceEvents && this._onceEvents[eventName];\n        for(var i = 0; i < listeners.length; i++){\n            var listener = listeners[i];\n            var isOnce = onceListeners && onceListeners[listener];\n            if (isOnce) {\n                // remove listener\n                // remove before trigger to prevent recursion\n                this.off(eventName, listener);\n                // unset once flag\n                delete onceListeners[listener];\n            }\n            // trigger listener\n            listener.apply(this, args);\n        }\n        return this;\n    };\n    proto.allOff = function() {\n        delete this._events;\n        delete this._onceEvents;\n    };\n    return EvEmitter;\n});\n\n\n\"use strict\";\nclass $c83f175452bd0a3c$export$2e2bcd8739ae039 extends (0, (/*@__PURE__*/$parcel$interopDefault($ba1d3eb1170b398e$exports))) {\n    constructor(el, opts){\n        // Have to call super() first before referencing “this” since we’re extending EventEmitter\n        // https://stackoverflow.com/a/43591507/673457\n        super();\n        // Use Object.assign() to merge “opts” object with default values in this.options\n        this.options = Object.assign({}, {\n            transitionSpeed: 100,\n            activeClasses: \"\",\n            modalContentClass: \"Modal-content\",\n            onReady: null\n        }, opts);\n        if (this.options.activeClasses.length) {\n            // Check if active class string contains multiple classes\n            if (this.options.activeClasses.indexOf(\" \") > -1) // Convert to array and remove any empty string values\n            // caused by having multiple spaces in a row.\n            this.options.activeClasses = this.options.activeClasses.split(\" \").filter((n)=>n.length);\n            else // We still need to convert a single active class to an array\n            // so we can use the spread syntax later in classList.add()\n            this.options.activeClasses = [\n                this.options.activeClasses\n            ];\n        }\n        this.el = el;\n        this.el.classList.add(\"js-init\");\n        this.isOpen = false;\n        this.hasToggles = false;\n        this.contentEl = this.el.querySelector(\".Modal-content\");\n        this.customContentEl = this.el.querySelector(\".\" + this.options.modalContentClass) || this.contentEl;\n        this.closeEls = this.el.querySelectorAll(\"[data-modal-close]\");\n        // If modal has an ID, check for matching toggle elements with “data-modal” attribute\n        if (this.el.id) {\n            this.toggleEls = document.querySelectorAll(`[data-modal=\"${this.el.id}\"]`);\n            this.hasToggles = !!this.toggleEls.length;\n        } else // If modal doesn’t have an id, add a random one for “aria-controls”\n        // https://gist.github.com/gordonbrander/2230317\n        this.el.id = Math.random().toString(36).substr(2, 4);\n        // Store currently focused element when modal opens so we can restore focus when it closes\n        this.prevFocusedEl = null;\n        // Find focusable elements inside of modal window (used to prevent tabbing outside of modal)\n        this.focusableEls = this.getFocusableEls();\n        // Save first and last focusable elements\n        if (this.focusableEls.length) {\n            this.firstFocusableEl = this.focusableEls[0];\n            this.lastFocusableEl = this.focusableEls[this.focusableEls.length - 1];\n        }\n        // Check for aria-label/aria-labelledby on modal (a11y best practice)\n        if (!this.el.getAttribute(\"aria-label\") && !this.el.getAttribute(\"aria-labelledby\")) console.warn(\"A11y Issue: Modal window should have an “aria-label” or “aria-labelledby” attribute\", this.el);\n        // Init modal window\n        this.init();\n    }\n    init() {\n        // Add aria attributes to modal window\n        this.el.setAttribute(\"aria-hidden\", \"true\");\n        this.el.setAttribute(\"role\", \"dialog\");\n        // Add aria attributes to toggle buttons\n        if (this.hasToggles) this.toggleEls.forEach((toggleEl)=>{\n            // Add “aria-controls” but be aware only JAWS supports it\n            // https://inclusive-components.design/menus-menu-buttons/#ariacontrols\n            toggleEl.setAttribute(\"aria-controls\", this.el.id);\n            toggleEl.setAttribute(\"aria-expanded\", \"false\");\n            toggleEl.setAttribute(\"role\", \"button\");\n        });\n        // Add aria attributes to close buttons\n        if (this.closeEls.length) this.closeEls.forEach((closeEl)=>{\n            closeEl.setAttribute(\"role\", \"button\");\n        });\n        // Add event listeners\n        this.bindEvents();\n        // Check for ready callback\n        if (typeof this.options.onReady === \"function\") this.options.onReady();\n    // Check URL hash to determine if modal should start open\n    // if (\n    //   this.el.id &&\n    //   window.location.hash &&\n    //   window.location.hash.substring(1) == this.el.id\n    // ) {\n    //   this.open();\n    // }\n    }\n    destroy() {\n        // Remove aria attributes on modal window\n        this.el.removeAttribute(\"aria-hidden\");\n        this.el.removeAttribute(\"role\");\n        this.el.removeAttribute(\"tabindex\");\n        // Remove aria attributes on toggle buttons\n        if (this.hasToggles) this.toggleEls.forEach((toggleEl)=>{\n            toggleEl.removeAttribute(\"aria-controls\");\n            toggleEl.removeAttribute(\"aria-expanded\");\n            toggleEl.removeAttribute(\"role\");\n        });\n        // Remove aria attributes on close buttons\n        if (this.closeEls.length) this.closeEls.forEach((closeEl)=>{\n            closeEl.removeAttribute(\"aria-label\");\n            closeEl.removeAttribute(\"role\");\n        });\n        // Remove event listeners\n        this.unbindEvents();\n        // Trigger destroy event\n        this.emitEvent(\"destroy\");\n    }\n    // Find focusable elements inside of modal window (used to prevent tabbing outside of modal)\n    // https://bitsofco.de/accessible-modal-dialog/\n    getFocusableEls() {\n        let focusableEls = this.el.querySelectorAll('a[href], area[href], input:not([disabled]), select:not([disabled]), textarea:not([disabled]), button:not([disabled]), [tabindex=\"0\"]');\n        // Convert NodeList to Array\n        return [\n            ...focusableEls\n        ];\n    }\n    // Get currently focused element\n    // https://stackoverflow.com/a/40873560/673457\n    // Could also use document.querySelector(\":focus\") but that’s likely less performant\n    getFocusedEl() {\n        if (document.hasFocus() && document.activeElement !== document.body && document.activeElement !== document.documentElement) return document.activeElement;\n        return null;\n    }\n    focusDelay(el) {\n        var self = this;\n        // Use setTimeout() to ensure element is focused\n        // https://stackoverflow.com/questions/33955650/what-is-settimeout-doing-when-set-to-0-milliseconds/33955673\n        // https://stackoverflow.com/questions/779379/why-is-settimeoutfn-0-sometimes-useful\n        // https://blog.sessionstack.com/how-javascript-works-event-loop-and-the-rise-of-async-programming-5-ways-to-better-coding-with-2f077c4438b5\n        window.setTimeout(()=>el.focus(), this.options.transitionSpeed);\n    }\n    windowClickHandler(evt) {\n        // Ignore click on the toggle button, which already has an event handler\n        let isToggle = Array.prototype.indexOf.call(this.toggleEls, evt.target.closest(\"[data-modal]\")) > -1;\n        // Don’t close if target el has been removed from the DOM by the time this callback runs\n        let targetElExists = document.body.contains(evt.target);\n        // Do nothing if modal is closed, a toggle was clicked,\n        // or target element no longer exists.\n        if (!this.isOpen || isToggle || !targetElExists) return;\n        // Don’t close if target is a child of the modal wrapper\n        let targetInsideWrapper = this.customContentEl && this.customContentEl.contains(evt.target);\n        // Don’t close if target is the modal wrapper itself\n        let targetIsWrapper = this.customContentEl.isSameNode(evt.target);\n        // For single-page apps or site using pjax (e.g. Turbolinks, Swup),\n        // we need to manually close the modal when a link is clicked,\n        // but ignore links that have been set to role=\"button\".\n        // let targetIsLink = evt.target.closest('a:not([role=\"button\"])');\n        //\n        // Then add this additional condition below:\n        // || (targetInsideWrapper && targetIsLink)\n        // Close when click target is outside of the modal window,\n        if (!(targetInsideWrapper || targetIsWrapper)) this.close(evt);\n    }\n    keydownHandler(evt) {\n        // Do nothing if modal is closed\n        if (!this.isOpen) return false;\n        // Close with escape key\n        if (evt.which === 27) this.close(evt);\n        // Prevent tabbing outside of modal\n        if (evt.which === 9) {\n            // If no focusable items, close the modal\n            if (!this.focusableEls.length) {\n                this.close(evt);\n                return false;\n            }\n            // Find currently focused element\n            let focusedEl = this.getFocusedEl();\n            // If tabbing forward and the last item is focued, focus the first item\n            if (!evt.shiftKey && focusedEl == this.lastFocusableEl) {\n                // Prevent default since we're manually focusing the first element\n                evt.preventDefault();\n                this.firstFocusableEl.focus();\n            } else if (evt.shiftKey && (focusedEl == this.firstFocusableEl || focusedEl == this.contentEl)) {\n                // If tabbing backwards and the first item is focused, focus the last item\n                evt.preventDefault();\n                this.lastFocusableEl.focus();\n            }\n        }\n    }\n    bindEvents() {\n        // Toggle buttons\n        if (this.hasToggles) {\n            // Note: Event callbacks need to be assigned to a var so they can be removed\n            // https://stackoverflow.com/a/22870717/673457\n            this.toggleClick = this.toggle.bind(this);\n            this.toggleEls.forEach((toggleEl)=>{\n                toggleEl.addEventListener(\"click\", this.toggleClick);\n            });\n        }\n        // Close buttons\n        if (this.closeEls.length) {\n            // Event callback\n            this.closeClick = this.close.bind(this);\n            this.closeEls.forEach((closeEl)=>{\n                closeEl.addEventListener(\"click\", this.closeClick);\n            });\n        }\n        // Close if click outside of modal content\n        this.windowClick = this.windowClickHandler.bind(this);\n        window.addEventListener(\"click\", this.windowClick);\n        // Keyboard events\n        this.keydown = this.keydownHandler.bind(this);\n        window.addEventListener(\"keydown\", this.keydown);\n    }\n    unbindEvents() {\n        // Toggle buttons\n        if (this.hasToggles) this.toggleEls.forEach((toggleEl)=>{\n            toggleEl.removeEventListener(\"click\", this.toggleClick);\n        });\n        // Close buttons\n        if (this.closeEls.length) this.closeEls.forEach((closeEl)=>{\n            closeEl.removeEventListener(\"click\", this.closeClick);\n        });\n        // Window events\n        window.removeEventListener(\"click\", this.windowClick);\n        window.removeEventListener(\"keydown\", this.keydown);\n    }\n    // Expand expandable\n    open(evt) {\n        evt.preventDefault();\n        // Save currently focused element to focus on close\n        this.prevFocusedEl = this.getFocusedEl();\n        // Disable scrolling\n        (0, (/*@__PURE__*/$parcel$interopDefault($ee2Qt))).freeze();\n        // Scroll modal content to top\n        // (without this, content will be vertically centered)\n        if (this.contentEl) this.contentEl.scrollTop = 0;\n        // Update modal aria attributes\n        this.el.setAttribute(\"aria-hidden\", \"false\");\n        // Add custom classes\n        if (this.options.activeClasses.length) this.el.classList.add(...this.options.activeClasses);\n        // Update toggle aria attributes\n        if (this.hasToggles) this.toggleEls.forEach((toggleEl)=>{\n            toggleEl.setAttribute(\"aria-expanded\", \"true\");\n            // Add custom classes\n            if (this.options.activeClasses.length) toggleEl.classList.add(...this.options.activeClasses);\n        });\n        // Focus modal on open\n        if (this.contentEl) {\n            this.contentEl.setAttribute(\"tabindex\", \"-1\");\n            this.focusDelay(this.contentEl);\n        } else {\n            this.el.setAttribute(\"tabindex\", \"-1\");\n            this.focusDelay(this.el);\n        }\n        // Update URL hash so users can link directly to the modal window content\n        // Use history.replaceState() to prevent adding a new history entry\n        // Note: If replaceState isn’t supported, modal-toggles.js won’t prevent the\n        // default click event, causing the hash to update and creating a new history entry.\n        // if (history.replaceState) {\n        //   history.replaceState(null, \"\", \"#\" + this.el.id);\n        // }\n        // Update state\n        this.isOpen = true;\n        // Trigger open event\n        this.emitEvent(\"open\");\n    }\n    // Collapse expandable\n    close(evt) {\n        evt.preventDefault();\n        // Clear hash using replaceState() to prevent adding a new history entry\n        // if (history.replaceState) {\n        //   history.replaceState(null, \"\", window.location.pathname);\n        // }\n        // Update modal aria attributes\n        this.el.setAttribute(\"aria-hidden\", \"true\");\n        // Remove custom classes\n        if (this.options.activeClasses.length) this.el.classList.remove(...this.options.activeClasses);\n        // Update toggle aria attributes\n        if (this.hasToggles) this.toggleEls.forEach((toggleEl)=>{\n            toggleEl.setAttribute(\"aria-expanded\", \"false\");\n            // Remove custom classes\n            if (this.options.activeClasses.length) toggleEl.classList.remove(...this.options.activeClasses);\n        });\n        // Enable scrolling\n        (0, (/*@__PURE__*/$parcel$interopDefault($ee2Qt))).unfreeze();\n        // Shift focus to previously focused element\n        if (this.prevFocusedEl) this.focusDelay(this.prevFocusedEl);\n        else if (this.hasToggles) // Focus the first toggle if nothing was previously focused\n        this.focusDelay(this.toggleEls[0]);\n        // Update state\n        this.isOpen = false;\n        // Trigger close event\n        this.emitEvent(\"close\");\n    }\n    // Toggle expandable\n    toggle(evt) {\n        if (this.isOpen) this.close(evt);\n        else this.open(evt);\n    }\n}\n\n\nconst $7baa24001ba46d98$var$container = document.getElementById(\"info\");\nif ($7baa24001ba46d98$var$container) new (0, $c83f175452bd0a3c$export$2e2bcd8739ae039)($7baa24001ba46d98$var$container);\n // If you have more than one modal on the page\n // const containers = document.querySelectorAll(\".Modal\");\n // containers.forEach(container => new Modal(container));\n\n\nvar $9bd5008c96f03152$exports = {};\n(function() {\n    /**\n * A convenience function for configuring and constructing\n * a new lunr Index.\n *\n * A lunr.Builder instance is created and the pipeline setup\n * with a trimmer, stop word filter and stemmer.\n *\n * This builder object is yielded to the configuration function\n * that is passed as a parameter, allowing the list of fields\n * and other builder parameters to be customised.\n *\n * All documents _must_ be added within the passed config function.\n *\n * @example\n * var idx = lunr(function () {\n *   this.field('title')\n *   this.field('body')\n *   this.ref('id')\n *\n *   documents.forEach(function (doc) {\n *     this.add(doc)\n *   }, this)\n * })\n *\n * @see {@link lunr.Builder}\n * @see {@link lunr.Pipeline}\n * @see {@link lunr.trimmer}\n * @see {@link lunr.stopWordFilter}\n * @see {@link lunr.stemmer}\n * @namespace {function} lunr\n */ var lunr = function(config) {\n        var builder = new lunr.Builder;\n        builder.pipeline.add(lunr.trimmer, lunr.stopWordFilter, lunr.stemmer);\n        builder.searchPipeline.add(lunr.stemmer);\n        config.call(builder, builder);\n        return builder.build();\n    };\n    lunr.version = \"2.3.9\";\n    /*!\n * lunr.utils\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * A namespace containing utils for the rest of the lunr library\n * @namespace lunr.utils\n */ lunr.utils = {};\n    /**\n * Print a warning message to the console.\n *\n * @param {String} message The message to be printed.\n * @memberOf lunr.utils\n * @function\n */ lunr.utils.warn = function(global) {\n        /* eslint-disable no-console */ return function(message) {\n            if (global.console && console.warn) console.warn(message);\n        };\n    /* eslint-enable no-console */ }(this);\n    /**\n * Convert an object to a string.\n *\n * In the case of `null` and `undefined` the function returns\n * the empty string, in all other cases the result of calling\n * `toString` on the passed object is returned.\n *\n * @param {Any} obj The object to convert to a string.\n * @return {String} string representation of the passed object.\n * @memberOf lunr.utils\n */ lunr.utils.asString = function(obj) {\n        if (obj === void 0 || obj === null) return \"\";\n        else return obj.toString();\n    };\n    /**\n * Clones an object.\n *\n * Will create a copy of an existing object such that any mutations\n * on the copy cannot affect the original.\n *\n * Only shallow objects are supported, passing a nested object to this\n * function will cause a TypeError.\n *\n * Objects with primitives, and arrays of primitives are supported.\n *\n * @param {Object} obj The object to clone.\n * @return {Object} a clone of the passed object.\n * @throws {TypeError} when a nested object is passed.\n * @memberOf Utils\n */ lunr.utils.clone = function(obj) {\n        if (obj === null || obj === undefined) return obj;\n        var clone = Object.create(null), keys = Object.keys(obj);\n        for(var i = 0; i < keys.length; i++){\n            var key = keys[i], val = obj[key];\n            if (Array.isArray(val)) {\n                clone[key] = val.slice();\n                continue;\n            }\n            if (typeof val === \"string\" || typeof val === \"number\" || typeof val === \"boolean\") {\n                clone[key] = val;\n                continue;\n            }\n            throw new TypeError(\"clone is not deep and does not support nested objects\");\n        }\n        return clone;\n    };\n    lunr.FieldRef = function(docRef, fieldName, stringValue) {\n        this.docRef = docRef;\n        this.fieldName = fieldName;\n        this._stringValue = stringValue;\n    };\n    lunr.FieldRef.joiner = \"/\";\n    lunr.FieldRef.fromString = function(s) {\n        var n = s.indexOf(lunr.FieldRef.joiner);\n        if (n === -1) throw \"malformed field ref string\";\n        var fieldRef = s.slice(0, n), docRef = s.slice(n + 1);\n        return new lunr.FieldRef(docRef, fieldRef, s);\n    };\n    lunr.FieldRef.prototype.toString = function() {\n        if (this._stringValue == undefined) this._stringValue = this.fieldName + lunr.FieldRef.joiner + this.docRef;\n        return this._stringValue;\n    };\n    /*!\n * lunr.Set\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * A lunr set.\n *\n * @constructor\n */ lunr.Set = function(elements) {\n        this.elements = Object.create(null);\n        if (elements) {\n            this.length = elements.length;\n            for(var i = 0; i < this.length; i++)this.elements[elements[i]] = true;\n        } else this.length = 0;\n    };\n    /**\n * A complete set that contains all elements.\n *\n * @static\n * @readonly\n * @type {lunr.Set}\n */ lunr.Set.complete = {\n        intersect: function(other) {\n            return other;\n        },\n        union: function() {\n            return this;\n        },\n        contains: function() {\n            return true;\n        }\n    };\n    /**\n * An empty set that contains no elements.\n *\n * @static\n * @readonly\n * @type {lunr.Set}\n */ lunr.Set.empty = {\n        intersect: function() {\n            return this;\n        },\n        union: function(other) {\n            return other;\n        },\n        contains: function() {\n            return false;\n        }\n    };\n    /**\n * Returns true if this set contains the specified object.\n *\n * @param {object} object - Object whose presence in this set is to be tested.\n * @returns {boolean} - True if this set contains the specified object.\n */ lunr.Set.prototype.contains = function(object) {\n        return !!this.elements[object];\n    };\n    /**\n * Returns a new set containing only the elements that are present in both\n * this set and the specified set.\n *\n * @param {lunr.Set} other - set to intersect with this set.\n * @returns {lunr.Set} a new set that is the intersection of this and the specified set.\n */ lunr.Set.prototype.intersect = function(other) {\n        var a, b, elements, intersection = [];\n        if (other === lunr.Set.complete) return this;\n        if (other === lunr.Set.empty) return other;\n        if (this.length < other.length) {\n            a = this;\n            b = other;\n        } else {\n            a = other;\n            b = this;\n        }\n        elements = Object.keys(a.elements);\n        for(var i = 0; i < elements.length; i++){\n            var element = elements[i];\n            if (element in b.elements) intersection.push(element);\n        }\n        return new lunr.Set(intersection);\n    };\n    /**\n * Returns a new set combining the elements of this and the specified set.\n *\n * @param {lunr.Set} other - set to union with this set.\n * @return {lunr.Set} a new set that is the union of this and the specified set.\n */ lunr.Set.prototype.union = function(other) {\n        if (other === lunr.Set.complete) return lunr.Set.complete;\n        if (other === lunr.Set.empty) return this;\n        return new lunr.Set(Object.keys(this.elements).concat(Object.keys(other.elements)));\n    };\n    /**\n * A function to calculate the inverse document frequency for\n * a posting. This is shared between the builder and the index\n *\n * @private\n * @param {object} posting - The posting for a given term\n * @param {number} documentCount - The total number of documents.\n */ lunr.idf = function(posting, documentCount) {\n        var documentsWithTerm = 0;\n        for(var fieldName in posting){\n            if (fieldName == \"_index\") continue; // Ignore the term index, its not a field\n            documentsWithTerm += Object.keys(posting[fieldName]).length;\n        }\n        var x = (documentCount - documentsWithTerm + 0.5) / (documentsWithTerm + 0.5);\n        return Math.log(1 + Math.abs(x));\n    };\n    /**\n * A token wraps a string representation of a token\n * as it is passed through the text processing pipeline.\n *\n * @constructor\n * @param {string} [str=''] - The string token being wrapped.\n * @param {object} [metadata={}] - Metadata associated with this token.\n */ lunr.Token = function(str, metadata) {\n        this.str = str || \"\";\n        this.metadata = metadata || {};\n    };\n    /**\n * Returns the token string that is being wrapped by this object.\n *\n * @returns {string}\n */ lunr.Token.prototype.toString = function() {\n        return this.str;\n    };\n    /**\n * A token update function is used when updating or optionally\n * when cloning a token.\n *\n * @callback lunr.Token~updateFunction\n * @param {string} str - The string representation of the token.\n * @param {Object} metadata - All metadata associated with this token.\n */ /**\n * Applies the given function to the wrapped string token.\n *\n * @example\n * token.update(function (str, metadata) {\n *   return str.toUpperCase()\n * })\n *\n * @param {lunr.Token~updateFunction} fn - A function to apply to the token string.\n * @returns {lunr.Token}\n */ lunr.Token.prototype.update = function(fn) {\n        this.str = fn(this.str, this.metadata);\n        return this;\n    };\n    /**\n * Creates a clone of this token. Optionally a function can be\n * applied to the cloned token.\n *\n * @param {lunr.Token~updateFunction} [fn] - An optional function to apply to the cloned token.\n * @returns {lunr.Token}\n */ lunr.Token.prototype.clone = function(fn) {\n        fn = fn || function(s) {\n            return s;\n        };\n        return new lunr.Token(fn(this.str, this.metadata), this.metadata);\n    };\n    /*!\n * lunr.tokenizer\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * A function for splitting a string into tokens ready to be inserted into\n * the search index. Uses `lunr.tokenizer.separator` to split strings, change\n * the value of this property to change how strings are split into tokens.\n *\n * This tokenizer will convert its parameter to a string by calling `toString` and\n * then will split this string on the character in `lunr.tokenizer.separator`.\n * Arrays will have their elements converted to strings and wrapped in a lunr.Token.\n *\n * Optional metadata can be passed to the tokenizer, this metadata will be cloned and\n * added as metadata to every token that is created from the object to be tokenized.\n *\n * @static\n * @param {?(string|object|object[])} obj - The object to convert into tokens\n * @param {?object} metadata - Optional metadata to associate with every token\n * @returns {lunr.Token[]}\n * @see {@link lunr.Pipeline}\n */ lunr.tokenizer = function(obj, metadata) {\n        if (obj == null || obj == undefined) return [];\n        if (Array.isArray(obj)) return obj.map(function(t) {\n            return new lunr.Token(lunr.utils.asString(t).toLowerCase(), lunr.utils.clone(metadata));\n        });\n        var str = obj.toString().toLowerCase(), len = str.length, tokens = [];\n        for(var sliceEnd = 0, sliceStart = 0; sliceEnd <= len; sliceEnd++){\n            var char = str.charAt(sliceEnd), sliceLength = sliceEnd - sliceStart;\n            if (char.match(lunr.tokenizer.separator) || sliceEnd == len) {\n                if (sliceLength > 0) {\n                    var tokenMetadata = lunr.utils.clone(metadata) || {};\n                    tokenMetadata[\"position\"] = [\n                        sliceStart,\n                        sliceLength\n                    ];\n                    tokenMetadata[\"index\"] = tokens.length;\n                    tokens.push(new lunr.Token(str.slice(sliceStart, sliceEnd), tokenMetadata));\n                }\n                sliceStart = sliceEnd + 1;\n            }\n        }\n        return tokens;\n    };\n    /**\n * The separator used to split a string into tokens. Override this property to change the behaviour of\n * `lunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\n *\n * @static\n * @see lunr.tokenizer\n */ lunr.tokenizer.separator = /[\\s\\-]+/;\n    /*!\n * lunr.Pipeline\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * lunr.Pipelines maintain an ordered list of functions to be applied to all\n * tokens in documents entering the search index and queries being ran against\n * the index.\n *\n * An instance of lunr.Index created with the lunr shortcut will contain a\n * pipeline with a stop word filter and an English language stemmer. Extra\n * functions can be added before or after either of these functions or these\n * default functions can be removed.\n *\n * When run the pipeline will call each function in turn, passing a token, the\n * index of that token in the original list of all tokens and finally a list of\n * all the original tokens.\n *\n * The output of functions in the pipeline will be passed to the next function\n * in the pipeline. To exclude a token from entering the index the function\n * should return undefined, the rest of the pipeline will not be called with\n * this token.\n *\n * For serialisation of pipelines to work, all functions used in an instance of\n * a pipeline should be registered with lunr.Pipeline. Registered functions can\n * then be loaded. If trying to load a serialised pipeline that uses functions\n * that are not registered an error will be thrown.\n *\n * If not planning on serialising the pipeline then registering pipeline functions\n * is not necessary.\n *\n * @constructor\n */ lunr.Pipeline = function() {\n        this._stack = [];\n    };\n    lunr.Pipeline.registeredFunctions = Object.create(null);\n    /**\n * A pipeline function maps lunr.Token to lunr.Token. A lunr.Token contains the token\n * string as well as all known metadata. A pipeline function can mutate the token string\n * or mutate (or add) metadata for a given token.\n *\n * A pipeline function can indicate that the passed token should be discarded by returning\n * null, undefined or an empty string. This token will not be passed to any downstream pipeline\n * functions and will not be added to the index.\n *\n * Multiple tokens can be returned by returning an array of tokens. Each token will be passed\n * to any downstream pipeline functions and all will returned tokens will be added to the index.\n *\n * Any number of pipeline functions may be chained together using a lunr.Pipeline.\n *\n * @interface lunr.PipelineFunction\n * @param {lunr.Token} token - A token from the document being processed.\n * @param {number} i - The index of this token in the complete list of tokens for this document/field.\n * @param {lunr.Token[]} tokens - All tokens for this document/field.\n * @returns {(?lunr.Token|lunr.Token[])}\n */ /**\n * Register a function with the pipeline.\n *\n * Functions that are used in the pipeline should be registered if the pipeline\n * needs to be serialised, or a serialised pipeline needs to be loaded.\n *\n * Registering a function does not add it to a pipeline, functions must still be\n * added to instances of the pipeline for them to be used when running a pipeline.\n *\n * @param {lunr.PipelineFunction} fn - The function to check for.\n * @param {String} label - The label to register this function with\n */ lunr.Pipeline.registerFunction = function(fn, label) {\n        if (label in this.registeredFunctions) lunr.utils.warn(\"Overwriting existing registered function: \" + label);\n        fn.label = label;\n        lunr.Pipeline.registeredFunctions[fn.label] = fn;\n    };\n    /**\n * Warns if the function is not registered as a Pipeline function.\n *\n * @param {lunr.PipelineFunction} fn - The function to check for.\n * @private\n */ lunr.Pipeline.warnIfFunctionNotRegistered = function(fn) {\n        var isRegistered = fn.label && fn.label in this.registeredFunctions;\n        if (!isRegistered) lunr.utils.warn(\"Function is not registered with pipeline. This may cause problems when serialising the index.\\n\", fn);\n    };\n    /**\n * Loads a previously serialised pipeline.\n *\n * All functions to be loaded must already be registered with lunr.Pipeline.\n * If any function from the serialised data has not been registered then an\n * error will be thrown.\n *\n * @param {Object} serialised - The serialised pipeline to load.\n * @returns {lunr.Pipeline}\n */ lunr.Pipeline.load = function(serialised) {\n        var pipeline = new lunr.Pipeline;\n        serialised.forEach(function(fnName) {\n            var fn = lunr.Pipeline.registeredFunctions[fnName];\n            if (fn) pipeline.add(fn);\n            else throw new Error(\"Cannot load unregistered function: \" + fnName);\n        });\n        return pipeline;\n    };\n    /**\n * Adds new functions to the end of the pipeline.\n *\n * Logs a warning if the function has not been registered.\n *\n * @param {lunr.PipelineFunction[]} functions - Any number of functions to add to the pipeline.\n */ lunr.Pipeline.prototype.add = function() {\n        var fns = Array.prototype.slice.call(arguments);\n        fns.forEach(function(fn) {\n            lunr.Pipeline.warnIfFunctionNotRegistered(fn);\n            this._stack.push(fn);\n        }, this);\n    };\n    /**\n * Adds a single function after a function that already exists in the\n * pipeline.\n *\n * Logs a warning if the function has not been registered.\n *\n * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n */ lunr.Pipeline.prototype.after = function(existingFn, newFn) {\n        lunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n        var pos = this._stack.indexOf(existingFn);\n        if (pos == -1) throw new Error(\"Cannot find existingFn\");\n        pos = pos + 1;\n        this._stack.splice(pos, 0, newFn);\n    };\n    /**\n * Adds a single function before a function that already exists in the\n * pipeline.\n *\n * Logs a warning if the function has not been registered.\n *\n * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n */ lunr.Pipeline.prototype.before = function(existingFn, newFn) {\n        lunr.Pipeline.warnIfFunctionNotRegistered(newFn);\n        var pos = this._stack.indexOf(existingFn);\n        if (pos == -1) throw new Error(\"Cannot find existingFn\");\n        this._stack.splice(pos, 0, newFn);\n    };\n    /**\n * Removes a function from the pipeline.\n *\n * @param {lunr.PipelineFunction} fn The function to remove from the pipeline.\n */ lunr.Pipeline.prototype.remove = function(fn) {\n        var pos = this._stack.indexOf(fn);\n        if (pos == -1) return;\n        this._stack.splice(pos, 1);\n    };\n    /**\n * Runs the current list of functions that make up the pipeline against the\n * passed tokens.\n *\n * @param {Array} tokens The tokens to run through the pipeline.\n * @returns {Array}\n */ lunr.Pipeline.prototype.run = function(tokens) {\n        var stackLength = this._stack.length;\n        for(var i = 0; i < stackLength; i++){\n            var fn = this._stack[i];\n            var memo = [];\n            for(var j = 0; j < tokens.length; j++){\n                var result = fn(tokens[j], j, tokens);\n                if (result === null || result === void 0 || result === \"\") continue;\n                if (Array.isArray(result)) for(var k = 0; k < result.length; k++)memo.push(result[k]);\n                else memo.push(result);\n            }\n            tokens = memo;\n        }\n        return tokens;\n    };\n    /**\n * Convenience method for passing a string through a pipeline and getting\n * strings out. This method takes care of wrapping the passed string in a\n * token and mapping the resulting tokens back to strings.\n *\n * @param {string} str - The string to pass through the pipeline.\n * @param {?object} metadata - Optional metadata to associate with the token\n * passed to the pipeline.\n * @returns {string[]}\n */ lunr.Pipeline.prototype.runString = function(str, metadata) {\n        var token = new lunr.Token(str, metadata);\n        return this.run([\n            token\n        ]).map(function(t) {\n            return t.toString();\n        });\n    };\n    /**\n * Resets the pipeline by removing any existing processors.\n *\n */ lunr.Pipeline.prototype.reset = function() {\n        this._stack = [];\n    };\n    /**\n * Returns a representation of the pipeline ready for serialisation.\n *\n * Logs a warning if the function has not been registered.\n *\n * @returns {Array}\n */ lunr.Pipeline.prototype.toJSON = function() {\n        return this._stack.map(function(fn) {\n            lunr.Pipeline.warnIfFunctionNotRegistered(fn);\n            return fn.label;\n        });\n    };\n    /*!\n * lunr.Vector\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * A vector is used to construct the vector space of documents and queries. These\n * vectors support operations to determine the similarity between two documents or\n * a document and a query.\n *\n * Normally no parameters are required for initializing a vector, but in the case of\n * loading a previously dumped vector the raw elements can be provided to the constructor.\n *\n * For performance reasons vectors are implemented with a flat array, where an elements\n * index is immediately followed by its value. E.g. [index, value, index, value]. This\n * allows the underlying array to be as sparse as possible and still offer decent\n * performance when being used for vector calculations.\n *\n * @constructor\n * @param {Number[]} [elements] - The flat list of element index and element value pairs.\n */ lunr.Vector = function(elements) {\n        this._magnitude = 0;\n        this.elements = elements || [];\n    };\n    /**\n * Calculates the position within the vector to insert a given index.\n *\n * This is used internally by insert and upsert. If there are duplicate indexes then\n * the position is returned as if the value for that index were to be updated, but it\n * is the callers responsibility to check whether there is a duplicate at that index\n *\n * @param {Number} insertIdx - The index at which the element should be inserted.\n * @returns {Number}\n */ lunr.Vector.prototype.positionForIndex = function(index) {\n        // For an empty vector the tuple can be inserted at the beginning\n        if (this.elements.length == 0) return 0;\n        var start = 0, end = this.elements.length / 2, sliceLength = end - start, pivotPoint = Math.floor(sliceLength / 2), pivotIndex = this.elements[pivotPoint * 2];\n        while(sliceLength > 1){\n            if (pivotIndex < index) start = pivotPoint;\n            if (pivotIndex > index) end = pivotPoint;\n            if (pivotIndex == index) break;\n            sliceLength = end - start;\n            pivotPoint = start + Math.floor(sliceLength / 2);\n            pivotIndex = this.elements[pivotPoint * 2];\n        }\n        if (pivotIndex == index) return pivotPoint * 2;\n        if (pivotIndex > index) return pivotPoint * 2;\n        if (pivotIndex < index) return (pivotPoint + 1) * 2;\n    };\n    /**\n * Inserts an element at an index within the vector.\n *\n * Does not allow duplicates, will throw an error if there is already an entry\n * for this index.\n *\n * @param {Number} insertIdx - The index at which the element should be inserted.\n * @param {Number} val - The value to be inserted into the vector.\n */ lunr.Vector.prototype.insert = function(insertIdx, val) {\n        this.upsert(insertIdx, val, function() {\n            throw \"duplicate index\";\n        });\n    };\n    /**\n * Inserts or updates an existing index within the vector.\n *\n * @param {Number} insertIdx - The index at which the element should be inserted.\n * @param {Number} val - The value to be inserted into the vector.\n * @param {function} fn - A function that is called for updates, the existing value and the\n * requested value are passed as arguments\n */ lunr.Vector.prototype.upsert = function(insertIdx, val, fn) {\n        this._magnitude = 0;\n        var position = this.positionForIndex(insertIdx);\n        if (this.elements[position] == insertIdx) this.elements[position + 1] = fn(this.elements[position + 1], val);\n        else this.elements.splice(position, 0, insertIdx, val);\n    };\n    /**\n * Calculates the magnitude of this vector.\n *\n * @returns {Number}\n */ lunr.Vector.prototype.magnitude = function() {\n        if (this._magnitude) return this._magnitude;\n        var sumOfSquares = 0, elementsLength = this.elements.length;\n        for(var i = 1; i < elementsLength; i += 2){\n            var val = this.elements[i];\n            sumOfSquares += val * val;\n        }\n        return this._magnitude = Math.sqrt(sumOfSquares);\n    };\n    /**\n * Calculates the dot product of this vector and another vector.\n *\n * @param {lunr.Vector} otherVector - The vector to compute the dot product with.\n * @returns {Number}\n */ lunr.Vector.prototype.dot = function(otherVector) {\n        var dotProduct = 0, a = this.elements, b = otherVector.elements, aLen = a.length, bLen = b.length, aVal = 0, bVal = 0, i = 0, j = 0;\n        while(i < aLen && j < bLen){\n            aVal = a[i], bVal = b[j];\n            if (aVal < bVal) i += 2;\n            else if (aVal > bVal) j += 2;\n            else if (aVal == bVal) {\n                dotProduct += a[i + 1] * b[j + 1];\n                i += 2;\n                j += 2;\n            }\n        }\n        return dotProduct;\n    };\n    /**\n * Calculates the similarity between this vector and another vector.\n *\n * @param {lunr.Vector} otherVector - The other vector to calculate the\n * similarity with.\n * @returns {Number}\n */ lunr.Vector.prototype.similarity = function(otherVector) {\n        return this.dot(otherVector) / this.magnitude() || 0;\n    };\n    /**\n * Converts the vector to an array of the elements within the vector.\n *\n * @returns {Number[]}\n */ lunr.Vector.prototype.toArray = function() {\n        var output = new Array(this.elements.length / 2);\n        for(var i = 1, j = 0; i < this.elements.length; i += 2, j++)output[j] = this.elements[i];\n        return output;\n    };\n    /**\n * A JSON serializable representation of the vector.\n *\n * @returns {Number[]}\n */ lunr.Vector.prototype.toJSON = function() {\n        return this.elements;\n    };\n    /* eslint-disable */ /*!\n * lunr.stemmer\n * Copyright (C) 2020 Oliver Nightingale\n * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n */ /**\n * lunr.stemmer is an english language stemmer, this is a JavaScript\n * implementation of the PorterStemmer taken from http://tartarus.org/~martin\n *\n * @static\n * @implements {lunr.PipelineFunction}\n * @param {lunr.Token} token - The string to stem\n * @returns {lunr.Token}\n * @see {@link lunr.Pipeline}\n * @function\n */ lunr.stemmer = function() {\n        var step2list = {\n            \"ational\": \"ate\",\n            \"tional\": \"tion\",\n            \"enci\": \"ence\",\n            \"anci\": \"ance\",\n            \"izer\": \"ize\",\n            \"bli\": \"ble\",\n            \"alli\": \"al\",\n            \"entli\": \"ent\",\n            \"eli\": \"e\",\n            \"ousli\": \"ous\",\n            \"ization\": \"ize\",\n            \"ation\": \"ate\",\n            \"ator\": \"ate\",\n            \"alism\": \"al\",\n            \"iveness\": \"ive\",\n            \"fulness\": \"ful\",\n            \"ousness\": \"ous\",\n            \"aliti\": \"al\",\n            \"iviti\": \"ive\",\n            \"biliti\": \"ble\",\n            \"logi\": \"log\"\n        }, step3list = {\n            \"icate\": \"ic\",\n            \"ative\": \"\",\n            \"alize\": \"al\",\n            \"iciti\": \"ic\",\n            \"ical\": \"ic\",\n            \"ful\": \"\",\n            \"ness\": \"\"\n        }, c = \"[^aeiou]\", v = \"[aeiouy]\", C = c + \"[^aeiouy]*\", V = v + \"[aeiou]*\", mgr0 = \"^(\" + C + \")?\" + V + C, meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\", mgr1 = \"^(\" + C + \")?\" + V + C + V + C, s_v = \"^(\" + C + \")?\" + v; // vowel in stem\n        var re_mgr0 = new RegExp(mgr0);\n        var re_mgr1 = new RegExp(mgr1);\n        var re_meq1 = new RegExp(meq1);\n        var re_s_v = new RegExp(s_v);\n        var re_1a = /^(.+?)(ss|i)es$/;\n        var re2_1a = /^(.+?)([^s])s$/;\n        var re_1b = /^(.+?)eed$/;\n        var re2_1b = /^(.+?)(ed|ing)$/;\n        var re_1b_2 = /.$/;\n        var re2_1b_2 = /(at|bl|iz)$/;\n        var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n        var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n        var re_1c = /^(.+?[^aeiou])y$/;\n        var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n        var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n        var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n        var re2_4 = /^(.+?)(s|t)(ion)$/;\n        var re_5 = /^(.+?)e$/;\n        var re_5_1 = /ll$/;\n        var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n        var porterStemmer = function porterStemmer(w) {\n            var stem, suffix, firstch, re, re2, re3, re4;\n            if (w.length < 3) return w;\n            firstch = w.substr(0, 1);\n            if (firstch == \"y\") w = firstch.toUpperCase() + w.substr(1);\n            // Step 1a\n            re = re_1a;\n            re2 = re2_1a;\n            if (re.test(w)) w = w.replace(re, \"$1$2\");\n            else if (re2.test(w)) w = w.replace(re2, \"$1$2\");\n            // Step 1b\n            re = re_1b;\n            re2 = re2_1b;\n            if (re.test(w)) {\n                var fp = re.exec(w);\n                re = re_mgr0;\n                if (re.test(fp[1])) {\n                    re = re_1b_2;\n                    w = w.replace(re, \"\");\n                }\n            } else if (re2.test(w)) {\n                var fp = re2.exec(w);\n                stem = fp[1];\n                re2 = re_s_v;\n                if (re2.test(stem)) {\n                    w = stem;\n                    re2 = re2_1b_2;\n                    re3 = re3_1b_2;\n                    re4 = re4_1b_2;\n                    if (re2.test(w)) w = w + \"e\";\n                    else if (re3.test(w)) {\n                        re = re_1b_2;\n                        w = w.replace(re, \"\");\n                    } else if (re4.test(w)) w = w + \"e\";\n                }\n            }\n            // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\n            re = re_1c;\n            if (re.test(w)) {\n                var fp = re.exec(w);\n                stem = fp[1];\n                w = stem + \"i\";\n            }\n            // Step 2\n            re = re_2;\n            if (re.test(w)) {\n                var fp = re.exec(w);\n                stem = fp[1];\n                suffix = fp[2];\n                re = re_mgr0;\n                if (re.test(stem)) w = stem + step2list[suffix];\n            }\n            // Step 3\n            re = re_3;\n            if (re.test(w)) {\n                var fp = re.exec(w);\n                stem = fp[1];\n                suffix = fp[2];\n                re = re_mgr0;\n                if (re.test(stem)) w = stem + step3list[suffix];\n            }\n            // Step 4\n            re = re_4;\n            re2 = re2_4;\n            if (re.test(w)) {\n                var fp = re.exec(w);\n                stem = fp[1];\n                re = re_mgr1;\n                if (re.test(stem)) w = stem;\n            } else if (re2.test(w)) {\n                var fp = re2.exec(w);\n                stem = fp[1] + fp[2];\n                re2 = re_mgr1;\n                if (re2.test(stem)) w = stem;\n            }\n            // Step 5\n            re = re_5;\n            if (re.test(w)) {\n                var fp = re.exec(w);\n                stem = fp[1];\n                re = re_mgr1;\n                re2 = re_meq1;\n                re3 = re3_5;\n                if (re.test(stem) || re2.test(stem) && !re3.test(stem)) w = stem;\n            }\n            re = re_5_1;\n            re2 = re_mgr1;\n            if (re.test(w) && re2.test(w)) {\n                re = re_1b_2;\n                w = w.replace(re, \"\");\n            }\n            // and turn initial Y back to y\n            if (firstch == \"y\") w = firstch.toLowerCase() + w.substr(1);\n            return w;\n        };\n        return function(token) {\n            return token.update(porterStemmer);\n        };\n    }();\n    lunr.Pipeline.registerFunction(lunr.stemmer, \"stemmer\");\n    /*!\n * lunr.stopWordFilter\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * lunr.generateStopWordFilter builds a stopWordFilter function from the provided\n * list of stop words.\n *\n * The built in lunr.stopWordFilter is built using this generator and can be used\n * to generate custom stopWordFilters for applications or non English languages.\n *\n * @function\n * @param {Array} token The token to pass through the filter\n * @returns {lunr.PipelineFunction}\n * @see lunr.Pipeline\n * @see lunr.stopWordFilter\n */ lunr.generateStopWordFilter = function(stopWords) {\n        var words = stopWords.reduce(function(memo, stopWord) {\n            memo[stopWord] = stopWord;\n            return memo;\n        }, {});\n        return function(token) {\n            if (token && words[token.toString()] !== token.toString()) return token;\n        };\n    };\n    /**\n * lunr.stopWordFilter is an English language stop word list filter, any words\n * contained in the list will not be passed through the filter.\n *\n * This is intended to be used in the Pipeline. If the token does not pass the\n * filter then undefined will be returned.\n *\n * @function\n * @implements {lunr.PipelineFunction}\n * @params {lunr.Token} token - A token to check for being a stop word.\n * @returns {lunr.Token}\n * @see {@link lunr.Pipeline}\n */ lunr.stopWordFilter = lunr.generateStopWordFilter([\n        \"a\",\n        \"able\",\n        \"about\",\n        \"across\",\n        \"after\",\n        \"all\",\n        \"almost\",\n        \"also\",\n        \"am\",\n        \"among\",\n        \"an\",\n        \"and\",\n        \"any\",\n        \"are\",\n        \"as\",\n        \"at\",\n        \"be\",\n        \"because\",\n        \"been\",\n        \"but\",\n        \"by\",\n        \"can\",\n        \"cannot\",\n        \"could\",\n        \"dear\",\n        \"did\",\n        \"do\",\n        \"does\",\n        \"either\",\n        \"else\",\n        \"ever\",\n        \"every\",\n        \"for\",\n        \"from\",\n        \"get\",\n        \"got\",\n        \"had\",\n        \"has\",\n        \"have\",\n        \"he\",\n        \"her\",\n        \"hers\",\n        \"him\",\n        \"his\",\n        \"how\",\n        \"however\",\n        \"i\",\n        \"if\",\n        \"in\",\n        \"into\",\n        \"is\",\n        \"it\",\n        \"its\",\n        \"just\",\n        \"least\",\n        \"let\",\n        \"like\",\n        \"likely\",\n        \"may\",\n        \"me\",\n        \"might\",\n        \"most\",\n        \"must\",\n        \"my\",\n        \"neither\",\n        \"no\",\n        \"nor\",\n        \"not\",\n        \"of\",\n        \"off\",\n        \"often\",\n        \"on\",\n        \"only\",\n        \"or\",\n        \"other\",\n        \"our\",\n        \"own\",\n        \"rather\",\n        \"said\",\n        \"say\",\n        \"says\",\n        \"she\",\n        \"should\",\n        \"since\",\n        \"so\",\n        \"some\",\n        \"than\",\n        \"that\",\n        \"the\",\n        \"their\",\n        \"them\",\n        \"then\",\n        \"there\",\n        \"these\",\n        \"they\",\n        \"this\",\n        \"tis\",\n        \"to\",\n        \"too\",\n        \"twas\",\n        \"us\",\n        \"wants\",\n        \"was\",\n        \"we\",\n        \"were\",\n        \"what\",\n        \"when\",\n        \"where\",\n        \"which\",\n        \"while\",\n        \"who\",\n        \"whom\",\n        \"why\",\n        \"will\",\n        \"with\",\n        \"would\",\n        \"yet\",\n        \"you\",\n        \"your\"\n    ]);\n    lunr.Pipeline.registerFunction(lunr.stopWordFilter, \"stopWordFilter\");\n    /*!\n * lunr.trimmer\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * lunr.trimmer is a pipeline function for trimming non word\n * characters from the beginning and end of tokens before they\n * enter the index.\n *\n * This implementation may not work correctly for non latin\n * characters and should either be removed or adapted for use\n * with languages with non-latin characters.\n *\n * @static\n * @implements {lunr.PipelineFunction}\n * @param {lunr.Token} token The token to pass through the filter\n * @returns {lunr.Token}\n * @see lunr.Pipeline\n */ lunr.trimmer = function(token) {\n        return token.update(function(s) {\n            return s.replace(/^\\W+/, \"\").replace(/\\W+$/, \"\");\n        });\n    };\n    lunr.Pipeline.registerFunction(lunr.trimmer, \"trimmer\");\n    /*!\n * lunr.TokenSet\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * A token set is used to store the unique list of all tokens\n * within an index. Token sets are also used to represent an\n * incoming query to the index, this query token set and index\n * token set are then intersected to find which tokens to look\n * up in the inverted index.\n *\n * A token set can hold multiple tokens, as in the case of the\n * index token set, or it can hold a single token as in the\n * case of a simple query token set.\n *\n * Additionally token sets are used to perform wildcard matching.\n * Leading, contained and trailing wildcards are supported, and\n * from this edit distance matching can also be provided.\n *\n * Token sets are implemented as a minimal finite state automata,\n * where both common prefixes and suffixes are shared between tokens.\n * This helps to reduce the space used for storing the token set.\n *\n * @constructor\n */ lunr.TokenSet = function() {\n        this.final = false;\n        this.edges = {};\n        this.id = lunr.TokenSet._nextId;\n        lunr.TokenSet._nextId += 1;\n    };\n    /**\n * Keeps track of the next, auto increment, identifier to assign\n * to a new tokenSet.\n *\n * TokenSets require a unique identifier to be correctly minimised.\n *\n * @private\n */ lunr.TokenSet._nextId = 1;\n    /**\n * Creates a TokenSet instance from the given sorted array of words.\n *\n * @param {String[]} arr - A sorted array of strings to create the set from.\n * @returns {lunr.TokenSet}\n * @throws Will throw an error if the input array is not sorted.\n */ lunr.TokenSet.fromArray = function(arr) {\n        var builder = new lunr.TokenSet.Builder;\n        for(var i = 0, len = arr.length; i < len; i++)builder.insert(arr[i]);\n        builder.finish();\n        return builder.root;\n    };\n    /**\n * Creates a token set from a query clause.\n *\n * @private\n * @param {Object} clause - A single clause from lunr.Query.\n * @param {string} clause.term - The query clause term.\n * @param {number} [clause.editDistance] - The optional edit distance for the term.\n * @returns {lunr.TokenSet}\n */ lunr.TokenSet.fromClause = function(clause) {\n        if (\"editDistance\" in clause) return lunr.TokenSet.fromFuzzyString(clause.term, clause.editDistance);\n        else return lunr.TokenSet.fromString(clause.term);\n    };\n    /**\n * Creates a token set representing a single string with a specified\n * edit distance.\n *\n * Insertions, deletions, substitutions and transpositions are each\n * treated as an edit distance of 1.\n *\n * Increasing the allowed edit distance will have a dramatic impact\n * on the performance of both creating and intersecting these TokenSets.\n * It is advised to keep the edit distance less than 3.\n *\n * @param {string} str - The string to create the token set from.\n * @param {number} editDistance - The allowed edit distance to match.\n * @returns {lunr.Vector}\n */ lunr.TokenSet.fromFuzzyString = function(str, editDistance) {\n        var root = new lunr.TokenSet;\n        var stack = [\n            {\n                node: root,\n                editsRemaining: editDistance,\n                str: str\n            }\n        ];\n        while(stack.length){\n            var frame = stack.pop();\n            // no edit\n            if (frame.str.length > 0) {\n                var char = frame.str.charAt(0), noEditNode;\n                if (char in frame.node.edges) noEditNode = frame.node.edges[char];\n                else {\n                    noEditNode = new lunr.TokenSet;\n                    frame.node.edges[char] = noEditNode;\n                }\n                if (frame.str.length == 1) noEditNode.final = true;\n                stack.push({\n                    node: noEditNode,\n                    editsRemaining: frame.editsRemaining,\n                    str: frame.str.slice(1)\n                });\n            }\n            if (frame.editsRemaining == 0) continue;\n            // insertion\n            if (\"*\" in frame.node.edges) var insertionNode = frame.node.edges[\"*\"];\n            else {\n                var insertionNode = new lunr.TokenSet;\n                frame.node.edges[\"*\"] = insertionNode;\n            }\n            if (frame.str.length == 0) insertionNode.final = true;\n            stack.push({\n                node: insertionNode,\n                editsRemaining: frame.editsRemaining - 1,\n                str: frame.str\n            });\n            // deletion\n            // can only do a deletion if we have enough edits remaining\n            // and if there are characters left to delete in the string\n            if (frame.str.length > 1) stack.push({\n                node: frame.node,\n                editsRemaining: frame.editsRemaining - 1,\n                str: frame.str.slice(1)\n            });\n            // deletion\n            // just removing the last character from the str\n            if (frame.str.length == 1) frame.node.final = true;\n            // substitution\n            // can only do a substitution if we have enough edits remaining\n            // and if there are characters left to substitute\n            if (frame.str.length >= 1) {\n                if (\"*\" in frame.node.edges) var substitutionNode = frame.node.edges[\"*\"];\n                else {\n                    var substitutionNode = new lunr.TokenSet;\n                    frame.node.edges[\"*\"] = substitutionNode;\n                }\n                if (frame.str.length == 1) substitutionNode.final = true;\n                stack.push({\n                    node: substitutionNode,\n                    editsRemaining: frame.editsRemaining - 1,\n                    str: frame.str.slice(1)\n                });\n            }\n            // transposition\n            // can only do a transposition if there are edits remaining\n            // and there are enough characters to transpose\n            if (frame.str.length > 1) {\n                var charA = frame.str.charAt(0), charB = frame.str.charAt(1), transposeNode;\n                if (charB in frame.node.edges) transposeNode = frame.node.edges[charB];\n                else {\n                    transposeNode = new lunr.TokenSet;\n                    frame.node.edges[charB] = transposeNode;\n                }\n                if (frame.str.length == 1) transposeNode.final = true;\n                stack.push({\n                    node: transposeNode,\n                    editsRemaining: frame.editsRemaining - 1,\n                    str: charA + frame.str.slice(2)\n                });\n            }\n        }\n        return root;\n    };\n    /**\n * Creates a TokenSet from a string.\n *\n * The string may contain one or more wildcard characters (*)\n * that will allow wildcard matching when intersecting with\n * another TokenSet.\n *\n * @param {string} str - The string to create a TokenSet from.\n * @returns {lunr.TokenSet}\n */ lunr.TokenSet.fromString = function(str) {\n        var node = new lunr.TokenSet, root = node;\n        /*\n   * Iterates through all characters within the passed string\n   * appending a node for each character.\n   *\n   * When a wildcard character is found then a self\n   * referencing edge is introduced to continually match\n   * any number of any characters.\n   */ for(var i = 0, len = str.length; i < len; i++){\n            var char = str[i], final = i == len - 1;\n            if (char == \"*\") {\n                node.edges[char] = node;\n                node.final = final;\n            } else {\n                var next = new lunr.TokenSet;\n                next.final = final;\n                node.edges[char] = next;\n                node = next;\n            }\n        }\n        return root;\n    };\n    /**\n * Converts this TokenSet into an array of strings\n * contained within the TokenSet.\n *\n * This is not intended to be used on a TokenSet that\n * contains wildcards, in these cases the results are\n * undefined and are likely to cause an infinite loop.\n *\n * @returns {string[]}\n */ lunr.TokenSet.prototype.toArray = function() {\n        var words = [];\n        var stack = [\n            {\n                prefix: \"\",\n                node: this\n            }\n        ];\n        while(stack.length){\n            var frame = stack.pop(), edges = Object.keys(frame.node.edges), len = edges.length;\n            if (frame.node.final) {\n                /* In Safari, at this point the prefix is sometimes corrupted, see:\n       * https://github.com/olivernn/lunr.js/issues/279 Calling any\n       * String.prototype method forces Safari to \"cast\" this string to what\n       * it's supposed to be, fixing the bug. */ frame.prefix.charAt(0);\n                words.push(frame.prefix);\n            }\n            for(var i = 0; i < len; i++){\n                var edge = edges[i];\n                stack.push({\n                    prefix: frame.prefix.concat(edge),\n                    node: frame.node.edges[edge]\n                });\n            }\n        }\n        return words;\n    };\n    /**\n * Generates a string representation of a TokenSet.\n *\n * This is intended to allow TokenSets to be used as keys\n * in objects, largely to aid the construction and minimisation\n * of a TokenSet. As such it is not designed to be a human\n * friendly representation of the TokenSet.\n *\n * @returns {string}\n */ lunr.TokenSet.prototype.toString = function() {\n        // NOTE: Using Object.keys here as this.edges is very likely\n        // to enter 'hash-mode' with many keys being added\n        //\n        // avoiding a for-in loop here as it leads to the function\n        // being de-optimised (at least in V8). From some simple\n        // benchmarks the performance is comparable, but allowing\n        // V8 to optimize may mean easy performance wins in the future.\n        if (this._str) return this._str;\n        var str = this.final ? \"1\" : \"0\", labels = Object.keys(this.edges).sort(), len = labels.length;\n        for(var i = 0; i < len; i++){\n            var label = labels[i], node = this.edges[label];\n            str = str + label + node.id;\n        }\n        return str;\n    };\n    /**\n * Returns a new TokenSet that is the intersection of\n * this TokenSet and the passed TokenSet.\n *\n * This intersection will take into account any wildcards\n * contained within the TokenSet.\n *\n * @param {lunr.TokenSet} b - An other TokenSet to intersect with.\n * @returns {lunr.TokenSet}\n */ lunr.TokenSet.prototype.intersect = function(b) {\n        var output = new lunr.TokenSet, frame = undefined;\n        var stack = [\n            {\n                qNode: b,\n                output: output,\n                node: this\n            }\n        ];\n        while(stack.length){\n            frame = stack.pop();\n            // NOTE: As with the #toString method, we are using\n            // Object.keys and a for loop instead of a for-in loop\n            // as both of these objects enter 'hash' mode, causing\n            // the function to be de-optimised in V8\n            var qEdges = Object.keys(frame.qNode.edges), qLen = qEdges.length, nEdges = Object.keys(frame.node.edges), nLen = nEdges.length;\n            for(var q = 0; q < qLen; q++){\n                var qEdge = qEdges[q];\n                for(var n = 0; n < nLen; n++){\n                    var nEdge = nEdges[n];\n                    if (nEdge == qEdge || qEdge == \"*\") {\n                        var node = frame.node.edges[nEdge], qNode = frame.qNode.edges[qEdge], final = node.final && qNode.final, next = undefined;\n                        if (nEdge in frame.output.edges) {\n                            // an edge already exists for this character\n                            // no need to create a new node, just set the finality\n                            // bit unless this node is already final\n                            next = frame.output.edges[nEdge];\n                            next.final = next.final || final;\n                        } else {\n                            // no edge exists yet, must create one\n                            // set the finality bit and insert it\n                            // into the output\n                            next = new lunr.TokenSet;\n                            next.final = final;\n                            frame.output.edges[nEdge] = next;\n                        }\n                        stack.push({\n                            qNode: qNode,\n                            output: next,\n                            node: node\n                        });\n                    }\n                }\n            }\n        }\n        return output;\n    };\n    lunr.TokenSet.Builder = function() {\n        this.previousWord = \"\";\n        this.root = new lunr.TokenSet;\n        this.uncheckedNodes = [];\n        this.minimizedNodes = {};\n    };\n    lunr.TokenSet.Builder.prototype.insert = function(word) {\n        var node, commonPrefix = 0;\n        if (word < this.previousWord) throw new Error(\"Out of order word insertion\");\n        for(var i = 0; i < word.length && i < this.previousWord.length; i++){\n            if (word[i] != this.previousWord[i]) break;\n            commonPrefix++;\n        }\n        this.minimize(commonPrefix);\n        if (this.uncheckedNodes.length == 0) node = this.root;\n        else node = this.uncheckedNodes[this.uncheckedNodes.length - 1].child;\n        for(var i = commonPrefix; i < word.length; i++){\n            var nextNode = new lunr.TokenSet, char = word[i];\n            node.edges[char] = nextNode;\n            this.uncheckedNodes.push({\n                parent: node,\n                char: char,\n                child: nextNode\n            });\n            node = nextNode;\n        }\n        node.final = true;\n        this.previousWord = word;\n    };\n    lunr.TokenSet.Builder.prototype.finish = function() {\n        this.minimize(0);\n    };\n    lunr.TokenSet.Builder.prototype.minimize = function(downTo) {\n        for(var i = this.uncheckedNodes.length - 1; i >= downTo; i--){\n            var node = this.uncheckedNodes[i], childKey = node.child.toString();\n            if (childKey in this.minimizedNodes) node.parent.edges[node.char] = this.minimizedNodes[childKey];\n            else {\n                // Cache the key for this node since\n                // we know it can't change anymore\n                node.child._str = childKey;\n                this.minimizedNodes[childKey] = node.child;\n            }\n            this.uncheckedNodes.pop();\n        }\n    };\n    /*!\n * lunr.Index\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * An index contains the built index of all documents and provides a query interface\n * to the index.\n *\n * Usually instances of lunr.Index will not be created using this constructor, instead\n * lunr.Builder should be used to construct new indexes, or lunr.Index.load should be\n * used to load previously built and serialized indexes.\n *\n * @constructor\n * @param {Object} attrs - The attributes of the built search index.\n * @param {Object} attrs.invertedIndex - An index of term/field to document reference.\n * @param {Object<string, lunr.Vector>} attrs.fieldVectors - Field vectors\n * @param {lunr.TokenSet} attrs.tokenSet - An set of all corpus tokens.\n * @param {string[]} attrs.fields - The names of indexed document fields.\n * @param {lunr.Pipeline} attrs.pipeline - The pipeline to use for search terms.\n */ lunr.Index = function(attrs) {\n        this.invertedIndex = attrs.invertedIndex;\n        this.fieldVectors = attrs.fieldVectors;\n        this.tokenSet = attrs.tokenSet;\n        this.fields = attrs.fields;\n        this.pipeline = attrs.pipeline;\n    };\n    /**\n * A result contains details of a document matching a search query.\n * @typedef {Object} lunr.Index~Result\n * @property {string} ref - The reference of the document this result represents.\n * @property {number} score - A number between 0 and 1 representing how similar this document is to the query.\n * @property {lunr.MatchData} matchData - Contains metadata about this match including which term(s) caused the match.\n */ /**\n * Although lunr provides the ability to create queries using lunr.Query, it also provides a simple\n * query language which itself is parsed into an instance of lunr.Query.\n *\n * For programmatically building queries it is advised to directly use lunr.Query, the query language\n * is best used for human entered text rather than program generated text.\n *\n * At its simplest queries can just be a single term, e.g. `hello`, multiple terms are also supported\n * and will be combined with OR, e.g `hello world` will match documents that contain either 'hello'\n * or 'world', though those that contain both will rank higher in the results.\n *\n * Wildcards can be included in terms to match one or more unspecified characters, these wildcards can\n * be inserted anywhere within the term, and more than one wildcard can exist in a single term. Adding\n * wildcards will increase the number of documents that will be found but can also have a negative\n * impact on query performance, especially with wildcards at the beginning of a term.\n *\n * Terms can be restricted to specific fields, e.g. `title:hello`, only documents with the term\n * hello in the title field will match this query. Using a field not present in the index will lead\n * to an error being thrown.\n *\n * Modifiers can also be added to terms, lunr supports edit distance and boost modifiers on terms. A term\n * boost will make documents matching that term score higher, e.g. `foo^5`. Edit distance is also supported\n * to provide fuzzy matching, e.g. 'hello~2' will match documents with hello with an edit distance of 2.\n * Avoid large values for edit distance to improve query performance.\n *\n * Each term also supports a presence modifier. By default a term's presence in document is optional, however\n * this can be changed to either required or prohibited. For a term's presence to be required in a document the\n * term should be prefixed with a '+', e.g. `+foo bar` is a search for documents that must contain 'foo' and\n * optionally contain 'bar'. Conversely a leading '-' sets the terms presence to prohibited, i.e. it must not\n * appear in a document, e.g. `-foo bar` is a search for documents that do not contain 'foo' but may contain 'bar'.\n *\n * To escape special characters the backslash character '\\' can be used, this allows searches to include\n * characters that would normally be considered modifiers, e.g. `foo\\~2` will search for a term \"foo~2\" instead\n * of attempting to apply a boost of 2 to the search term \"foo\".\n *\n * @typedef {string} lunr.Index~QueryString\n * @example <caption>Simple single term query</caption>\n * hello\n * @example <caption>Multiple term query</caption>\n * hello world\n * @example <caption>term scoped to a field</caption>\n * title:hello\n * @example <caption>term with a boost of 10</caption>\n * hello^10\n * @example <caption>term with an edit distance of 2</caption>\n * hello~2\n * @example <caption>terms with presence modifiers</caption>\n * -foo +bar baz\n */ /**\n * Performs a search against the index using lunr query syntax.\n *\n * Results will be returned sorted by their score, the most relevant results\n * will be returned first.  For details on how the score is calculated, please see\n * the {@link https://lunrjs.com/guides/searching.html#scoring|guide}.\n *\n * For more programmatic querying use lunr.Index#query.\n *\n * @param {lunr.Index~QueryString} queryString - A string containing a lunr query.\n * @throws {lunr.QueryParseError} If the passed query string cannot be parsed.\n * @returns {lunr.Index~Result[]}\n */ lunr.Index.prototype.search = function(queryString) {\n        return this.query(function(query) {\n            var parser = new lunr.QueryParser(queryString, query);\n            parser.parse();\n        });\n    };\n    /**\n * A query builder callback provides a query object to be used to express\n * the query to perform on the index.\n *\n * @callback lunr.Index~queryBuilder\n * @param {lunr.Query} query - The query object to build up.\n * @this lunr.Query\n */ /**\n * Performs a query against the index using the yielded lunr.Query object.\n *\n * If performing programmatic queries against the index, this method is preferred\n * over lunr.Index#search so as to avoid the additional query parsing overhead.\n *\n * A query object is yielded to the supplied function which should be used to\n * express the query to be run against the index.\n *\n * Note that although this function takes a callback parameter it is _not_ an\n * asynchronous operation, the callback is just yielded a query object to be\n * customized.\n *\n * @param {lunr.Index~queryBuilder} fn - A function that is used to build the query.\n * @returns {lunr.Index~Result[]}\n */ lunr.Index.prototype.query = function(fn) {\n        // for each query clause\n        // * process terms\n        // * expand terms from token set\n        // * find matching documents and metadata\n        // * get document vectors\n        // * score documents\n        var query = new lunr.Query(this.fields), matchingFields = Object.create(null), queryVectors = Object.create(null), termFieldCache = Object.create(null), requiredMatches = Object.create(null), prohibitedMatches = Object.create(null);\n        /*\n   * To support field level boosts a query vector is created per\n   * field. An empty vector is eagerly created to support negated\n   * queries.\n   */ for(var i = 0; i < this.fields.length; i++)queryVectors[this.fields[i]] = new lunr.Vector;\n        fn.call(query, query);\n        for(var i = 0; i < query.clauses.length; i++){\n            /*\n     * Unless the pipeline has been disabled for this term, which is\n     * the case for terms with wildcards, we need to pass the clause\n     * term through the search pipeline. A pipeline returns an array\n     * of processed terms. Pipeline functions may expand the passed\n     * term, which means we may end up performing multiple index lookups\n     * for a single query term.\n     */ var clause = query.clauses[i], terms = null, clauseMatches = lunr.Set.empty;\n            if (clause.usePipeline) terms = this.pipeline.runString(clause.term, {\n                fields: clause.fields\n            });\n            else terms = [\n                clause.term\n            ];\n            for(var m = 0; m < terms.length; m++){\n                var term = terms[m];\n                /*\n       * Each term returned from the pipeline needs to use the same query\n       * clause object, e.g. the same boost and or edit distance. The\n       * simplest way to do this is to re-use the clause object but mutate\n       * its term property.\n       */ clause.term = term;\n                /*\n       * From the term in the clause we create a token set which will then\n       * be used to intersect the indexes token set to get a list of terms\n       * to lookup in the inverted index\n       */ var termTokenSet = lunr.TokenSet.fromClause(clause), expandedTerms = this.tokenSet.intersect(termTokenSet).toArray();\n                /*\n       * If a term marked as required does not exist in the tokenSet it is\n       * impossible for the search to return any matches. We set all the field\n       * scoped required matches set to empty and stop examining any further\n       * clauses.\n       */ if (expandedTerms.length === 0 && clause.presence === lunr.Query.presence.REQUIRED) {\n                    for(var k = 0; k < clause.fields.length; k++){\n                        var field = clause.fields[k];\n                        requiredMatches[field] = lunr.Set.empty;\n                    }\n                    break;\n                }\n                for(var j = 0; j < expandedTerms.length; j++){\n                    /*\n         * For each term get the posting and termIndex, this is required for\n         * building the query vector.\n         */ var expandedTerm = expandedTerms[j], posting = this.invertedIndex[expandedTerm], termIndex = posting._index;\n                    for(var k = 0; k < clause.fields.length; k++){\n                        /*\n           * For each field that this query term is scoped by (by default\n           * all fields are in scope) we need to get all the document refs\n           * that have this term in that field.\n           *\n           * The posting is the entry in the invertedIndex for the matching\n           * term from above.\n           */ var field = clause.fields[k], fieldPosting = posting[field], matchingDocumentRefs = Object.keys(fieldPosting), termField = expandedTerm + \"/\" + field, matchingDocumentsSet = new lunr.Set(matchingDocumentRefs);\n                        /*\n           * if the presence of this term is required ensure that the matching\n           * documents are added to the set of required matches for this clause.\n           *\n           */ if (clause.presence == lunr.Query.presence.REQUIRED) {\n                            clauseMatches = clauseMatches.union(matchingDocumentsSet);\n                            if (requiredMatches[field] === undefined) requiredMatches[field] = lunr.Set.complete;\n                        }\n                        /*\n           * if the presence of this term is prohibited ensure that the matching\n           * documents are added to the set of prohibited matches for this field,\n           * creating that set if it does not yet exist.\n           */ if (clause.presence == lunr.Query.presence.PROHIBITED) {\n                            if (prohibitedMatches[field] === undefined) prohibitedMatches[field] = lunr.Set.empty;\n                            prohibitedMatches[field] = prohibitedMatches[field].union(matchingDocumentsSet);\n                            continue;\n                        }\n                        /*\n           * The query field vector is populated using the termIndex found for\n           * the term and a unit value with the appropriate boost applied.\n           * Using upsert because there could already be an entry in the vector\n           * for the term we are working with. In that case we just add the scores\n           * together.\n           */ queryVectors[field].upsert(termIndex, clause.boost, function(a, b) {\n                            return a + b;\n                        });\n                        /**\n           * If we've already seen this term, field combo then we've already collected\n           * the matching documents and metadata, no need to go through all that again\n           */ if (termFieldCache[termField]) continue;\n                        for(var l = 0; l < matchingDocumentRefs.length; l++){\n                            /*\n             * All metadata for this term/field/document triple\n             * are then extracted and collected into an instance\n             * of lunr.MatchData ready to be returned in the query\n             * results\n             */ var matchingDocumentRef = matchingDocumentRefs[l], matchingFieldRef = new lunr.FieldRef(matchingDocumentRef, field), metadata = fieldPosting[matchingDocumentRef], fieldMatch;\n                            if ((fieldMatch = matchingFields[matchingFieldRef]) === undefined) matchingFields[matchingFieldRef] = new lunr.MatchData(expandedTerm, field, metadata);\n                            else fieldMatch.add(expandedTerm, field, metadata);\n                        }\n                        termFieldCache[termField] = true;\n                    }\n                }\n            }\n            /**\n     * If the presence was required we need to update the requiredMatches field sets.\n     * We do this after all fields for the term have collected their matches because\n     * the clause terms presence is required in _any_ of the fields not _all_ of the\n     * fields.\n     */ if (clause.presence === lunr.Query.presence.REQUIRED) for(var k = 0; k < clause.fields.length; k++){\n                var field = clause.fields[k];\n                requiredMatches[field] = requiredMatches[field].intersect(clauseMatches);\n            }\n        }\n        /**\n   * Need to combine the field scoped required and prohibited\n   * matching documents into a global set of required and prohibited\n   * matches\n   */ var allRequiredMatches = lunr.Set.complete, allProhibitedMatches = lunr.Set.empty;\n        for(var i = 0; i < this.fields.length; i++){\n            var field = this.fields[i];\n            if (requiredMatches[field]) allRequiredMatches = allRequiredMatches.intersect(requiredMatches[field]);\n            if (prohibitedMatches[field]) allProhibitedMatches = allProhibitedMatches.union(prohibitedMatches[field]);\n        }\n        var matchingFieldRefs = Object.keys(matchingFields), results = [], matches = Object.create(null);\n        /*\n   * If the query is negated (contains only prohibited terms)\n   * we need to get _all_ fieldRefs currently existing in the\n   * index. This is only done when we know that the query is\n   * entirely prohibited terms to avoid any cost of getting all\n   * fieldRefs unnecessarily.\n   *\n   * Additionally, blank MatchData must be created to correctly\n   * populate the results.\n   */ if (query.isNegated()) {\n            matchingFieldRefs = Object.keys(this.fieldVectors);\n            for(var i = 0; i < matchingFieldRefs.length; i++){\n                var matchingFieldRef = matchingFieldRefs[i];\n                var fieldRef = lunr.FieldRef.fromString(matchingFieldRef);\n                matchingFields[matchingFieldRef] = new lunr.MatchData;\n            }\n        }\n        for(var i = 0; i < matchingFieldRefs.length; i++){\n            /*\n     * Currently we have document fields that match the query, but we\n     * need to return documents. The matchData and scores are combined\n     * from multiple fields belonging to the same document.\n     *\n     * Scores are calculated by field, using the query vectors created\n     * above, and combined into a final document score using addition.\n     */ var fieldRef = lunr.FieldRef.fromString(matchingFieldRefs[i]), docRef = fieldRef.docRef;\n            if (!allRequiredMatches.contains(docRef)) continue;\n            if (allProhibitedMatches.contains(docRef)) continue;\n            var fieldVector = this.fieldVectors[fieldRef], score = queryVectors[fieldRef.fieldName].similarity(fieldVector), docMatch;\n            if ((docMatch = matches[docRef]) !== undefined) {\n                docMatch.score += score;\n                docMatch.matchData.combine(matchingFields[fieldRef]);\n            } else {\n                var match = {\n                    ref: docRef,\n                    score: score,\n                    matchData: matchingFields[fieldRef]\n                };\n                matches[docRef] = match;\n                results.push(match);\n            }\n        }\n        /*\n   * Sort the results objects by score, highest first.\n   */ return results.sort(function(a, b) {\n            return b.score - a.score;\n        });\n    };\n    /**\n * Prepares the index for JSON serialization.\n *\n * The schema for this JSON blob will be described in a\n * separate JSON schema file.\n *\n * @returns {Object}\n */ lunr.Index.prototype.toJSON = function() {\n        var invertedIndex = Object.keys(this.invertedIndex).sort().map(function(term) {\n            return [\n                term,\n                this.invertedIndex[term]\n            ];\n        }, this);\n        var fieldVectors = Object.keys(this.fieldVectors).map(function(ref) {\n            return [\n                ref,\n                this.fieldVectors[ref].toJSON()\n            ];\n        }, this);\n        return {\n            version: lunr.version,\n            fields: this.fields,\n            fieldVectors: fieldVectors,\n            invertedIndex: invertedIndex,\n            pipeline: this.pipeline.toJSON()\n        };\n    };\n    /**\n * Loads a previously serialized lunr.Index\n *\n * @param {Object} serializedIndex - A previously serialized lunr.Index\n * @returns {lunr.Index}\n */ lunr.Index.load = function(serializedIndex) {\n        var attrs = {}, fieldVectors = {}, serializedVectors = serializedIndex.fieldVectors, invertedIndex = Object.create(null), serializedInvertedIndex = serializedIndex.invertedIndex, tokenSetBuilder = new lunr.TokenSet.Builder, pipeline = lunr.Pipeline.load(serializedIndex.pipeline);\n        if (serializedIndex.version != lunr.version) lunr.utils.warn(\"Version mismatch when loading serialised index. Current version of lunr '\" + lunr.version + \"' does not match serialized index '\" + serializedIndex.version + \"'\");\n        for(var i = 0; i < serializedVectors.length; i++){\n            var tuple = serializedVectors[i], ref = tuple[0], elements = tuple[1];\n            fieldVectors[ref] = new lunr.Vector(elements);\n        }\n        for(var i = 0; i < serializedInvertedIndex.length; i++){\n            var tuple = serializedInvertedIndex[i], term = tuple[0], posting = tuple[1];\n            tokenSetBuilder.insert(term);\n            invertedIndex[term] = posting;\n        }\n        tokenSetBuilder.finish();\n        attrs.fields = serializedIndex.fields;\n        attrs.fieldVectors = fieldVectors;\n        attrs.invertedIndex = invertedIndex;\n        attrs.tokenSet = tokenSetBuilder.root;\n        attrs.pipeline = pipeline;\n        return new lunr.Index(attrs);\n    };\n    /*!\n * lunr.Builder\n * Copyright (C) 2020 Oliver Nightingale\n */ /**\n * lunr.Builder performs indexing on a set of documents and\n * returns instances of lunr.Index ready for querying.\n *\n * All configuration of the index is done via the builder, the\n * fields to index, the document reference, the text processing\n * pipeline and document scoring parameters are all set on the\n * builder before indexing.\n *\n * @constructor\n * @property {string} _ref - Internal reference to the document reference field.\n * @property {string[]} _fields - Internal reference to the document fields to index.\n * @property {object} invertedIndex - The inverted index maps terms to document fields.\n * @property {object} documentTermFrequencies - Keeps track of document term frequencies.\n * @property {object} documentLengths - Keeps track of the length of documents added to the index.\n * @property {lunr.tokenizer} tokenizer - Function for splitting strings into tokens for indexing.\n * @property {lunr.Pipeline} pipeline - The pipeline performs text processing on tokens before indexing.\n * @property {lunr.Pipeline} searchPipeline - A pipeline for processing search terms before querying the index.\n * @property {number} documentCount - Keeps track of the total number of documents indexed.\n * @property {number} _b - A parameter to control field length normalization, setting this to 0 disabled normalization, 1 fully normalizes field lengths, the default value is 0.75.\n * @property {number} _k1 - A parameter to control how quickly an increase in term frequency results in term frequency saturation, the default value is 1.2.\n * @property {number} termIndex - A counter incremented for each unique term, used to identify a terms position in the vector space.\n * @property {array} metadataWhitelist - A list of metadata keys that have been whitelisted for entry in the index.\n */ lunr.Builder = function() {\n        this._ref = \"id\";\n        this._fields = Object.create(null);\n        this._documents = Object.create(null);\n        this.invertedIndex = Object.create(null);\n        this.fieldTermFrequencies = {};\n        this.fieldLengths = {};\n        this.tokenizer = lunr.tokenizer;\n        this.pipeline = new lunr.Pipeline;\n        this.searchPipeline = new lunr.Pipeline;\n        this.documentCount = 0;\n        this._b = 0.75;\n        this._k1 = 1.2;\n        this.termIndex = 0;\n        this.metadataWhitelist = [];\n    };\n    /**\n * Sets the document field used as the document reference. Every document must have this field.\n * The type of this field in the document should be a string, if it is not a string it will be\n * coerced into a string by calling toString.\n *\n * The default ref is 'id'.\n *\n * The ref should _not_ be changed during indexing, it should be set before any documents are\n * added to the index. Changing it during indexing can lead to inconsistent results.\n *\n * @param {string} ref - The name of the reference field in the document.\n */ lunr.Builder.prototype.ref = function(ref) {\n        this._ref = ref;\n    };\n    /**\n * A function that is used to extract a field from a document.\n *\n * Lunr expects a field to be at the top level of a document, if however the field\n * is deeply nested within a document an extractor function can be used to extract\n * the right field for indexing.\n *\n * @callback fieldExtractor\n * @param {object} doc - The document being added to the index.\n * @returns {?(string|object|object[])} obj - The object that will be indexed for this field.\n * @example <caption>Extracting a nested field</caption>\n * function (doc) { return doc.nested.field }\n */ /**\n * Adds a field to the list of document fields that will be indexed. Every document being\n * indexed should have this field. Null values for this field in indexed documents will\n * not cause errors but will limit the chance of that document being retrieved by searches.\n *\n * All fields should be added before adding documents to the index. Adding fields after\n * a document has been indexed will have no effect on already indexed documents.\n *\n * Fields can be boosted at build time. This allows terms within that field to have more\n * importance when ranking search results. Use a field boost to specify that matches within\n * one field are more important than other fields.\n *\n * @param {string} fieldName - The name of a field to index in all documents.\n * @param {object} attributes - Optional attributes associated with this field.\n * @param {number} [attributes.boost=1] - Boost applied to all terms within this field.\n * @param {fieldExtractor} [attributes.extractor] - Function to extract a field from a document.\n * @throws {RangeError} fieldName cannot contain unsupported characters '/'\n */ lunr.Builder.prototype.field = function(fieldName, attributes) {\n        if (/\\//.test(fieldName)) throw new RangeError(\"Field '\" + fieldName + \"' contains illegal character '/'\");\n        this._fields[fieldName] = attributes || {};\n    };\n    /**\n * A parameter to tune the amount of field length normalisation that is applied when\n * calculating relevance scores. A value of 0 will completely disable any normalisation\n * and a value of 1 will fully normalise field lengths. The default is 0.75. Values of b\n * will be clamped to the range 0 - 1.\n *\n * @param {number} number - The value to set for this tuning parameter.\n */ lunr.Builder.prototype.b = function(number) {\n        if (number < 0) this._b = 0;\n        else if (number > 1) this._b = 1;\n        else this._b = number;\n    };\n    /**\n * A parameter that controls the speed at which a rise in term frequency results in term\n * frequency saturation. The default value is 1.2. Setting this to a higher value will give\n * slower saturation levels, a lower value will result in quicker saturation.\n *\n * @param {number} number - The value to set for this tuning parameter.\n */ lunr.Builder.prototype.k1 = function(number) {\n        this._k1 = number;\n    };\n    /**\n * Adds a document to the index.\n *\n * Before adding fields to the index the index should have been fully setup, with the document\n * ref and all fields to index already having been specified.\n *\n * The document must have a field name as specified by the ref (by default this is 'id') and\n * it should have all fields defined for indexing, though null or undefined values will not\n * cause errors.\n *\n * Entire documents can be boosted at build time. Applying a boost to a document indicates that\n * this document should rank higher in search results than other documents.\n *\n * @param {object} doc - The document to add to the index.\n * @param {object} attributes - Optional attributes associated with this document.\n * @param {number} [attributes.boost=1] - Boost applied to all terms within this document.\n */ lunr.Builder.prototype.add = function(doc, attributes) {\n        var docRef = doc[this._ref], fields = Object.keys(this._fields);\n        this._documents[docRef] = attributes || {};\n        this.documentCount += 1;\n        for(var i = 0; i < fields.length; i++){\n            var fieldName = fields[i], extractor = this._fields[fieldName].extractor, field = extractor ? extractor(doc) : doc[fieldName], tokens = this.tokenizer(field, {\n                fields: [\n                    fieldName\n                ]\n            }), terms = this.pipeline.run(tokens), fieldRef = new lunr.FieldRef(docRef, fieldName), fieldTerms = Object.create(null);\n            this.fieldTermFrequencies[fieldRef] = fieldTerms;\n            this.fieldLengths[fieldRef] = 0;\n            // store the length of this field for this document\n            this.fieldLengths[fieldRef] += terms.length;\n            // calculate term frequencies for this field\n            for(var j = 0; j < terms.length; j++){\n                var term = terms[j];\n                if (fieldTerms[term] == undefined) fieldTerms[term] = 0;\n                fieldTerms[term] += 1;\n                // add to inverted index\n                // create an initial posting if one doesn't exist\n                if (this.invertedIndex[term] == undefined) {\n                    var posting = Object.create(null);\n                    posting[\"_index\"] = this.termIndex;\n                    this.termIndex += 1;\n                    for(var k = 0; k < fields.length; k++)posting[fields[k]] = Object.create(null);\n                    this.invertedIndex[term] = posting;\n                }\n                // add an entry for this term/fieldName/docRef to the invertedIndex\n                if (this.invertedIndex[term][fieldName][docRef] == undefined) this.invertedIndex[term][fieldName][docRef] = Object.create(null);\n                // store all whitelisted metadata about this token in the\n                // inverted index\n                for(var l = 0; l < this.metadataWhitelist.length; l++){\n                    var metadataKey = this.metadataWhitelist[l], metadata = term.metadata[metadataKey];\n                    if (this.invertedIndex[term][fieldName][docRef][metadataKey] == undefined) this.invertedIndex[term][fieldName][docRef][metadataKey] = [];\n                    this.invertedIndex[term][fieldName][docRef][metadataKey].push(metadata);\n                }\n            }\n        }\n    };\n    /**\n * Calculates the average document length for this index\n *\n * @private\n */ lunr.Builder.prototype.calculateAverageFieldLengths = function() {\n        var fieldRefs = Object.keys(this.fieldLengths), numberOfFields = fieldRefs.length, accumulator = {}, documentsWithField = {};\n        for(var i = 0; i < numberOfFields; i++){\n            var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]), field = fieldRef.fieldName;\n            documentsWithField[field] || (documentsWithField[field] = 0);\n            documentsWithField[field] += 1;\n            accumulator[field] || (accumulator[field] = 0);\n            accumulator[field] += this.fieldLengths[fieldRef];\n        }\n        var fields = Object.keys(this._fields);\n        for(var i = 0; i < fields.length; i++){\n            var fieldName = fields[i];\n            accumulator[fieldName] = accumulator[fieldName] / documentsWithField[fieldName];\n        }\n        this.averageFieldLength = accumulator;\n    };\n    /**\n * Builds a vector space model of every document using lunr.Vector\n *\n * @private\n */ lunr.Builder.prototype.createFieldVectors = function() {\n        var fieldVectors = {}, fieldRefs = Object.keys(this.fieldTermFrequencies), fieldRefsLength = fieldRefs.length, termIdfCache = Object.create(null);\n        for(var i = 0; i < fieldRefsLength; i++){\n            var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]), fieldName = fieldRef.fieldName, fieldLength = this.fieldLengths[fieldRef], fieldVector = new lunr.Vector, termFrequencies = this.fieldTermFrequencies[fieldRef], terms = Object.keys(termFrequencies), termsLength = terms.length;\n            var fieldBoost = this._fields[fieldName].boost || 1, docBoost = this._documents[fieldRef.docRef].boost || 1;\n            for(var j = 0; j < termsLength; j++){\n                var term = terms[j], tf = termFrequencies[term], termIndex = this.invertedIndex[term]._index, idf, score, scoreWithPrecision;\n                if (termIdfCache[term] === undefined) {\n                    idf = lunr.idf(this.invertedIndex[term], this.documentCount);\n                    termIdfCache[term] = idf;\n                } else idf = termIdfCache[term];\n                score = idf * ((this._k1 + 1) * tf) / (this._k1 * (1 - this._b + this._b * (fieldLength / this.averageFieldLength[fieldName])) + tf);\n                score *= fieldBoost;\n                score *= docBoost;\n                scoreWithPrecision = Math.round(score * 1000) / 1000;\n                // Converts 1.23456789 to 1.234.\n                // Reducing the precision so that the vectors take up less\n                // space when serialised. Doing it now so that they behave\n                // the same before and after serialisation. Also, this is\n                // the fastest approach to reducing a number's precision in\n                // JavaScript.\n                fieldVector.insert(termIndex, scoreWithPrecision);\n            }\n            fieldVectors[fieldRef] = fieldVector;\n        }\n        this.fieldVectors = fieldVectors;\n    };\n    /**\n * Creates a token set of all tokens in the index using lunr.TokenSet\n *\n * @private\n */ lunr.Builder.prototype.createTokenSet = function() {\n        this.tokenSet = lunr.TokenSet.fromArray(Object.keys(this.invertedIndex).sort());\n    };\n    /**\n * Builds the index, creating an instance of lunr.Index.\n *\n * This completes the indexing process and should only be called\n * once all documents have been added to the index.\n *\n * @returns {lunr.Index}\n */ lunr.Builder.prototype.build = function() {\n        this.calculateAverageFieldLengths();\n        this.createFieldVectors();\n        this.createTokenSet();\n        return new lunr.Index({\n            invertedIndex: this.invertedIndex,\n            fieldVectors: this.fieldVectors,\n            tokenSet: this.tokenSet,\n            fields: Object.keys(this._fields),\n            pipeline: this.searchPipeline\n        });\n    };\n    /**\n * Applies a plugin to the index builder.\n *\n * A plugin is a function that is called with the index builder as its context.\n * Plugins can be used to customise or extend the behaviour of the index\n * in some way. A plugin is just a function, that encapsulated the custom\n * behaviour that should be applied when building the index.\n *\n * The plugin function will be called with the index builder as its argument, additional\n * arguments can also be passed when calling use. The function will be called\n * with the index builder as its context.\n *\n * @param {Function} plugin The plugin to apply.\n */ lunr.Builder.prototype.use = function(fn) {\n        var args = Array.prototype.slice.call(arguments, 1);\n        args.unshift(this);\n        fn.apply(this, args);\n    };\n    /**\n * Contains and collects metadata about a matching document.\n * A single instance of lunr.MatchData is returned as part of every\n * lunr.Index~Result.\n *\n * @constructor\n * @param {string} term - The term this match data is associated with\n * @param {string} field - The field in which the term was found\n * @param {object} metadata - The metadata recorded about this term in this field\n * @property {object} metadata - A cloned collection of metadata associated with this document.\n * @see {@link lunr.Index~Result}\n */ lunr.MatchData = function(term, field, metadata) {\n        var clonedMetadata = Object.create(null), metadataKeys = Object.keys(metadata || {});\n        // Cloning the metadata to prevent the original\n        // being mutated during match data combination.\n        // Metadata is kept in an array within the inverted\n        // index so cloning the data can be done with\n        // Array#slice\n        for(var i = 0; i < metadataKeys.length; i++){\n            var key = metadataKeys[i];\n            clonedMetadata[key] = metadata[key].slice();\n        }\n        this.metadata = Object.create(null);\n        if (term !== undefined) {\n            this.metadata[term] = Object.create(null);\n            this.metadata[term][field] = clonedMetadata;\n        }\n    };\n    /**\n * An instance of lunr.MatchData will be created for every term that matches a\n * document. However only one instance is required in a lunr.Index~Result. This\n * method combines metadata from another instance of lunr.MatchData with this\n * objects metadata.\n *\n * @param {lunr.MatchData} otherMatchData - Another instance of match data to merge with this one.\n * @see {@link lunr.Index~Result}\n */ lunr.MatchData.prototype.combine = function(otherMatchData) {\n        var terms = Object.keys(otherMatchData.metadata);\n        for(var i = 0; i < terms.length; i++){\n            var term = terms[i], fields = Object.keys(otherMatchData.metadata[term]);\n            if (this.metadata[term] == undefined) this.metadata[term] = Object.create(null);\n            for(var j = 0; j < fields.length; j++){\n                var field = fields[j], keys = Object.keys(otherMatchData.metadata[term][field]);\n                if (this.metadata[term][field] == undefined) this.metadata[term][field] = Object.create(null);\n                for(var k = 0; k < keys.length; k++){\n                    var key = keys[k];\n                    if (this.metadata[term][field][key] == undefined) this.metadata[term][field][key] = otherMatchData.metadata[term][field][key];\n                    else this.metadata[term][field][key] = this.metadata[term][field][key].concat(otherMatchData.metadata[term][field][key]);\n                }\n            }\n        }\n    };\n    /**\n * Add metadata for a term/field pair to this instance of match data.\n *\n * @param {string} term - The term this match data is associated with\n * @param {string} field - The field in which the term was found\n * @param {object} metadata - The metadata recorded about this term in this field\n */ lunr.MatchData.prototype.add = function(term, field, metadata) {\n        if (!(term in this.metadata)) {\n            this.metadata[term] = Object.create(null);\n            this.metadata[term][field] = metadata;\n            return;\n        }\n        if (!(field in this.metadata[term])) {\n            this.metadata[term][field] = metadata;\n            return;\n        }\n        var metadataKeys = Object.keys(metadata);\n        for(var i = 0; i < metadataKeys.length; i++){\n            var key = metadataKeys[i];\n            if (key in this.metadata[term][field]) this.metadata[term][field][key] = this.metadata[term][field][key].concat(metadata[key]);\n            else this.metadata[term][field][key] = metadata[key];\n        }\n    };\n    /**\n * A lunr.Query provides a programmatic way of defining queries to be performed\n * against a {@link lunr.Index}.\n *\n * Prefer constructing a lunr.Query using the {@link lunr.Index#query} method\n * so the query object is pre-initialized with the right index fields.\n *\n * @constructor\n * @property {lunr.Query~Clause[]} clauses - An array of query clauses.\n * @property {string[]} allFields - An array of all available fields in a lunr.Index.\n */ lunr.Query = function(allFields) {\n        this.clauses = [];\n        this.allFields = allFields;\n    };\n    /**\n * Constants for indicating what kind of automatic wildcard insertion will be used when constructing a query clause.\n *\n * This allows wildcards to be added to the beginning and end of a term without having to manually do any string\n * concatenation.\n *\n * The wildcard constants can be bitwise combined to select both leading and trailing wildcards.\n *\n * @constant\n * @default\n * @property {number} wildcard.NONE - The term will have no wildcards inserted, this is the default behaviour\n * @property {number} wildcard.LEADING - Prepend the term with a wildcard, unless a leading wildcard already exists\n * @property {number} wildcard.TRAILING - Append a wildcard to the term, unless a trailing wildcard already exists\n * @see lunr.Query~Clause\n * @see lunr.Query#clause\n * @see lunr.Query#term\n * @example <caption>query term with trailing wildcard</caption>\n * query.term('foo', { wildcard: lunr.Query.wildcard.TRAILING })\n * @example <caption>query term with leading and trailing wildcard</caption>\n * query.term('foo', {\n *   wildcard: lunr.Query.wildcard.LEADING | lunr.Query.wildcard.TRAILING\n * })\n */ lunr.Query.wildcard = new String(\"*\");\n    lunr.Query.wildcard.NONE = 0;\n    lunr.Query.wildcard.LEADING = 1;\n    lunr.Query.wildcard.TRAILING = 2;\n    /**\n * Constants for indicating what kind of presence a term must have in matching documents.\n *\n * @constant\n * @enum {number}\n * @see lunr.Query~Clause\n * @see lunr.Query#clause\n * @see lunr.Query#term\n * @example <caption>query term with required presence</caption>\n * query.term('foo', { presence: lunr.Query.presence.REQUIRED })\n */ lunr.Query.presence = {\n        /**\n   * Term's presence in a document is optional, this is the default value.\n   */ OPTIONAL: 1,\n        /**\n   * Term's presence in a document is required, documents that do not contain\n   * this term will not be returned.\n   */ REQUIRED: 2,\n        /**\n   * Term's presence in a document is prohibited, documents that do contain\n   * this term will not be returned.\n   */ PROHIBITED: 3\n    };\n    /**\n * A single clause in a {@link lunr.Query} contains a term and details on how to\n * match that term against a {@link lunr.Index}.\n *\n * @typedef {Object} lunr.Query~Clause\n * @property {string[]} fields - The fields in an index this clause should be matched against.\n * @property {number} [boost=1] - Any boost that should be applied when matching this clause.\n * @property {number} [editDistance] - Whether the term should have fuzzy matching applied, and how fuzzy the match should be.\n * @property {boolean} [usePipeline] - Whether the term should be passed through the search pipeline.\n * @property {number} [wildcard=lunr.Query.wildcard.NONE] - Whether the term should have wildcards appended or prepended.\n * @property {number} [presence=lunr.Query.presence.OPTIONAL] - The terms presence in any matching documents.\n */ /**\n * Adds a {@link lunr.Query~Clause} to this query.\n *\n * Unless the clause contains the fields to be matched all fields will be matched. In addition\n * a default boost of 1 is applied to the clause.\n *\n * @param {lunr.Query~Clause} clause - The clause to add to this query.\n * @see lunr.Query~Clause\n * @returns {lunr.Query}\n */ lunr.Query.prototype.clause = function(clause) {\n        if (!(\"fields\" in clause)) clause.fields = this.allFields;\n        if (!(\"boost\" in clause)) clause.boost = 1;\n        if (!(\"usePipeline\" in clause)) clause.usePipeline = true;\n        if (!(\"wildcard\" in clause)) clause.wildcard = lunr.Query.wildcard.NONE;\n        if (clause.wildcard & lunr.Query.wildcard.LEADING && clause.term.charAt(0) != lunr.Query.wildcard) clause.term = \"*\" + clause.term;\n        if (clause.wildcard & lunr.Query.wildcard.TRAILING && clause.term.slice(-1) != lunr.Query.wildcard) clause.term = \"\" + clause.term + \"*\";\n        if (!(\"presence\" in clause)) clause.presence = lunr.Query.presence.OPTIONAL;\n        this.clauses.push(clause);\n        return this;\n    };\n    /**\n * A negated query is one in which every clause has a presence of\n * prohibited. These queries require some special processing to return\n * the expected results.\n *\n * @returns boolean\n */ lunr.Query.prototype.isNegated = function() {\n        for(var i = 0; i < this.clauses.length; i++){\n            if (this.clauses[i].presence != lunr.Query.presence.PROHIBITED) return false;\n        }\n        return true;\n    };\n    /**\n * Adds a term to the current query, under the covers this will create a {@link lunr.Query~Clause}\n * to the list of clauses that make up this query.\n *\n * The term is used as is, i.e. no tokenization will be performed by this method. Instead conversion\n * to a token or token-like string should be done before calling this method.\n *\n * The term will be converted to a string by calling `toString`. Multiple terms can be passed as an\n * array, each term in the array will share the same options.\n *\n * @param {object|object[]} term - The term(s) to add to the query.\n * @param {object} [options] - Any additional properties to add to the query clause.\n * @returns {lunr.Query}\n * @see lunr.Query#clause\n * @see lunr.Query~Clause\n * @example <caption>adding a single term to a query</caption>\n * query.term(\"foo\")\n * @example <caption>adding a single term to a query and specifying search fields, term boost and automatic trailing wildcard</caption>\n * query.term(\"foo\", {\n *   fields: [\"title\"],\n *   boost: 10,\n *   wildcard: lunr.Query.wildcard.TRAILING\n * })\n * @example <caption>using lunr.tokenizer to convert a string to tokens before using them as terms</caption>\n * query.term(lunr.tokenizer(\"foo bar\"))\n */ lunr.Query.prototype.term = function(term, options) {\n        if (Array.isArray(term)) {\n            term.forEach(function(t) {\n                this.term(t, lunr.utils.clone(options));\n            }, this);\n            return this;\n        }\n        var clause = options || {};\n        clause.term = term.toString();\n        this.clause(clause);\n        return this;\n    };\n    lunr.QueryParseError = function(message, start, end) {\n        this.name = \"QueryParseError\";\n        this.message = message;\n        this.start = start;\n        this.end = end;\n    };\n    lunr.QueryParseError.prototype = new Error;\n    lunr.QueryLexer = function(str) {\n        this.lexemes = [];\n        this.str = str;\n        this.length = str.length;\n        this.pos = 0;\n        this.start = 0;\n        this.escapeCharPositions = [];\n    };\n    lunr.QueryLexer.prototype.run = function() {\n        var state = lunr.QueryLexer.lexText;\n        while(state)state = state(this);\n    };\n    lunr.QueryLexer.prototype.sliceString = function() {\n        var subSlices = [], sliceStart = this.start, sliceEnd = this.pos;\n        for(var i = 0; i < this.escapeCharPositions.length; i++){\n            sliceEnd = this.escapeCharPositions[i];\n            subSlices.push(this.str.slice(sliceStart, sliceEnd));\n            sliceStart = sliceEnd + 1;\n        }\n        subSlices.push(this.str.slice(sliceStart, this.pos));\n        this.escapeCharPositions.length = 0;\n        return subSlices.join(\"\");\n    };\n    lunr.QueryLexer.prototype.emit = function(type) {\n        this.lexemes.push({\n            type: type,\n            str: this.sliceString(),\n            start: this.start,\n            end: this.pos\n        });\n        this.start = this.pos;\n    };\n    lunr.QueryLexer.prototype.escapeCharacter = function() {\n        this.escapeCharPositions.push(this.pos - 1);\n        this.pos += 1;\n    };\n    lunr.QueryLexer.prototype.next = function() {\n        if (this.pos >= this.length) return lunr.QueryLexer.EOS;\n        var char = this.str.charAt(this.pos);\n        this.pos += 1;\n        return char;\n    };\n    lunr.QueryLexer.prototype.width = function() {\n        return this.pos - this.start;\n    };\n    lunr.QueryLexer.prototype.ignore = function() {\n        if (this.start == this.pos) this.pos += 1;\n        this.start = this.pos;\n    };\n    lunr.QueryLexer.prototype.backup = function() {\n        this.pos -= 1;\n    };\n    lunr.QueryLexer.prototype.acceptDigitRun = function() {\n        var char, charCode;\n        do {\n            char = this.next();\n            charCode = char.charCodeAt(0);\n        }while (charCode > 47 && charCode < 58);\n        if (char != lunr.QueryLexer.EOS) this.backup();\n    };\n    lunr.QueryLexer.prototype.more = function() {\n        return this.pos < this.length;\n    };\n    lunr.QueryLexer.EOS = \"EOS\";\n    lunr.QueryLexer.FIELD = \"FIELD\";\n    lunr.QueryLexer.TERM = \"TERM\";\n    lunr.QueryLexer.EDIT_DISTANCE = \"EDIT_DISTANCE\";\n    lunr.QueryLexer.BOOST = \"BOOST\";\n    lunr.QueryLexer.PRESENCE = \"PRESENCE\";\n    lunr.QueryLexer.lexField = function(lexer) {\n        lexer.backup();\n        lexer.emit(lunr.QueryLexer.FIELD);\n        lexer.ignore();\n        return lunr.QueryLexer.lexText;\n    };\n    lunr.QueryLexer.lexTerm = function(lexer) {\n        if (lexer.width() > 1) {\n            lexer.backup();\n            lexer.emit(lunr.QueryLexer.TERM);\n        }\n        lexer.ignore();\n        if (lexer.more()) return lunr.QueryLexer.lexText;\n    };\n    lunr.QueryLexer.lexEditDistance = function(lexer) {\n        lexer.ignore();\n        lexer.acceptDigitRun();\n        lexer.emit(lunr.QueryLexer.EDIT_DISTANCE);\n        return lunr.QueryLexer.lexText;\n    };\n    lunr.QueryLexer.lexBoost = function(lexer) {\n        lexer.ignore();\n        lexer.acceptDigitRun();\n        lexer.emit(lunr.QueryLexer.BOOST);\n        return lunr.QueryLexer.lexText;\n    };\n    lunr.QueryLexer.lexEOS = function(lexer) {\n        if (lexer.width() > 0) lexer.emit(lunr.QueryLexer.TERM);\n    };\n    // This matches the separator used when tokenising fields\n    // within a document. These should match otherwise it is\n    // not possible to search for some tokens within a document.\n    //\n    // It is possible for the user to change the separator on the\n    // tokenizer so it _might_ clash with any other of the special\n    // characters already used within the search string, e.g. :.\n    //\n    // This means that it is possible to change the separator in\n    // such a way that makes some words unsearchable using a search\n    // string.\n    lunr.QueryLexer.termSeparator = lunr.tokenizer.separator;\n    lunr.QueryLexer.lexText = function(lexer) {\n        while(true){\n            var char = lexer.next();\n            if (char == lunr.QueryLexer.EOS) return lunr.QueryLexer.lexEOS;\n            // Escape character is '\\'\n            if (char.charCodeAt(0) == 92) {\n                lexer.escapeCharacter();\n                continue;\n            }\n            if (char == \":\") return lunr.QueryLexer.lexField;\n            if (char == \"~\") {\n                lexer.backup();\n                if (lexer.width() > 0) lexer.emit(lunr.QueryLexer.TERM);\n                return lunr.QueryLexer.lexEditDistance;\n            }\n            if (char == \"^\") {\n                lexer.backup();\n                if (lexer.width() > 0) lexer.emit(lunr.QueryLexer.TERM);\n                return lunr.QueryLexer.lexBoost;\n            }\n            // \"+\" indicates term presence is required\n            // checking for length to ensure that only\n            // leading \"+\" are considered\n            if (char == \"+\" && lexer.width() === 1) {\n                lexer.emit(lunr.QueryLexer.PRESENCE);\n                return lunr.QueryLexer.lexText;\n            }\n            // \"-\" indicates term presence is prohibited\n            // checking for length to ensure that only\n            // leading \"-\" are considered\n            if (char == \"-\" && lexer.width() === 1) {\n                lexer.emit(lunr.QueryLexer.PRESENCE);\n                return lunr.QueryLexer.lexText;\n            }\n            if (char.match(lunr.QueryLexer.termSeparator)) return lunr.QueryLexer.lexTerm;\n        }\n    };\n    lunr.QueryParser = function(str, query) {\n        this.lexer = new lunr.QueryLexer(str);\n        this.query = query;\n        this.currentClause = {};\n        this.lexemeIdx = 0;\n    };\n    lunr.QueryParser.prototype.parse = function() {\n        this.lexer.run();\n        this.lexemes = this.lexer.lexemes;\n        var state = lunr.QueryParser.parseClause;\n        while(state)state = state(this);\n        return this.query;\n    };\n    lunr.QueryParser.prototype.peekLexeme = function() {\n        return this.lexemes[this.lexemeIdx];\n    };\n    lunr.QueryParser.prototype.consumeLexeme = function() {\n        var lexeme = this.peekLexeme();\n        this.lexemeIdx += 1;\n        return lexeme;\n    };\n    lunr.QueryParser.prototype.nextClause = function() {\n        var completedClause = this.currentClause;\n        this.query.clause(completedClause);\n        this.currentClause = {};\n    };\n    lunr.QueryParser.parseClause = function(parser) {\n        var lexeme = parser.peekLexeme();\n        if (lexeme == undefined) return;\n        switch(lexeme.type){\n            case lunr.QueryLexer.PRESENCE:\n                return lunr.QueryParser.parsePresence;\n            case lunr.QueryLexer.FIELD:\n                return lunr.QueryParser.parseField;\n            case lunr.QueryLexer.TERM:\n                return lunr.QueryParser.parseTerm;\n            default:\n                var errorMessage = \"expected either a field or a term, found \" + lexeme.type;\n                if (lexeme.str.length >= 1) errorMessage += \" with value '\" + lexeme.str + \"'\";\n                throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n        }\n    };\n    lunr.QueryParser.parsePresence = function(parser) {\n        var lexeme = parser.consumeLexeme();\n        if (lexeme == undefined) return;\n        switch(lexeme.str){\n            case \"-\":\n                parser.currentClause.presence = lunr.Query.presence.PROHIBITED;\n                break;\n            case \"+\":\n                parser.currentClause.presence = lunr.Query.presence.REQUIRED;\n                break;\n            default:\n                var errorMessage = \"unrecognised presence operator'\" + lexeme.str + \"'\";\n                throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n        }\n        var nextLexeme = parser.peekLexeme();\n        if (nextLexeme == undefined) {\n            var errorMessage = \"expecting term or field, found nothing\";\n            throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n        }\n        switch(nextLexeme.type){\n            case lunr.QueryLexer.FIELD:\n                return lunr.QueryParser.parseField;\n            case lunr.QueryLexer.TERM:\n                return lunr.QueryParser.parseTerm;\n            default:\n                var errorMessage = \"expecting term or field, found '\" + nextLexeme.type + \"'\";\n                throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n        }\n    };\n    lunr.QueryParser.parseField = function(parser) {\n        var lexeme = parser.consumeLexeme();\n        if (lexeme == undefined) return;\n        if (parser.query.allFields.indexOf(lexeme.str) == -1) {\n            var possibleFields = parser.query.allFields.map(function(f) {\n                return \"'\" + f + \"'\";\n            }).join(\", \"), errorMessage = \"unrecognised field '\" + lexeme.str + \"', possible fields: \" + possibleFields;\n            throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n        }\n        parser.currentClause.fields = [\n            lexeme.str\n        ];\n        var nextLexeme = parser.peekLexeme();\n        if (nextLexeme == undefined) {\n            var errorMessage = \"expecting term, found nothing\";\n            throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n        }\n        switch(nextLexeme.type){\n            case lunr.QueryLexer.TERM:\n                return lunr.QueryParser.parseTerm;\n            default:\n                var errorMessage = \"expecting term, found '\" + nextLexeme.type + \"'\";\n                throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n        }\n    };\n    lunr.QueryParser.parseTerm = function(parser) {\n        var lexeme = parser.consumeLexeme();\n        if (lexeme == undefined) return;\n        parser.currentClause.term = lexeme.str.toLowerCase();\n        if (lexeme.str.indexOf(\"*\") != -1) parser.currentClause.usePipeline = false;\n        var nextLexeme = parser.peekLexeme();\n        if (nextLexeme == undefined) {\n            parser.nextClause();\n            return;\n        }\n        switch(nextLexeme.type){\n            case lunr.QueryLexer.TERM:\n                parser.nextClause();\n                return lunr.QueryParser.parseTerm;\n            case lunr.QueryLexer.FIELD:\n                parser.nextClause();\n                return lunr.QueryParser.parseField;\n            case lunr.QueryLexer.EDIT_DISTANCE:\n                return lunr.QueryParser.parseEditDistance;\n            case lunr.QueryLexer.BOOST:\n                return lunr.QueryParser.parseBoost;\n            case lunr.QueryLexer.PRESENCE:\n                parser.nextClause();\n                return lunr.QueryParser.parsePresence;\n            default:\n                var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\";\n                throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n        }\n    };\n    lunr.QueryParser.parseEditDistance = function(parser) {\n        var lexeme = parser.consumeLexeme();\n        if (lexeme == undefined) return;\n        var editDistance = parseInt(lexeme.str, 10);\n        if (isNaN(editDistance)) {\n            var errorMessage = \"edit distance must be numeric\";\n            throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n        }\n        parser.currentClause.editDistance = editDistance;\n        var nextLexeme = parser.peekLexeme();\n        if (nextLexeme == undefined) {\n            parser.nextClause();\n            return;\n        }\n        switch(nextLexeme.type){\n            case lunr.QueryLexer.TERM:\n                parser.nextClause();\n                return lunr.QueryParser.parseTerm;\n            case lunr.QueryLexer.FIELD:\n                parser.nextClause();\n                return lunr.QueryParser.parseField;\n            case lunr.QueryLexer.EDIT_DISTANCE:\n                return lunr.QueryParser.parseEditDistance;\n            case lunr.QueryLexer.BOOST:\n                return lunr.QueryParser.parseBoost;\n            case lunr.QueryLexer.PRESENCE:\n                parser.nextClause();\n                return lunr.QueryParser.parsePresence;\n            default:\n                var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\";\n                throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n        }\n    };\n    lunr.QueryParser.parseBoost = function(parser) {\n        var lexeme = parser.consumeLexeme();\n        if (lexeme == undefined) return;\n        var boost = parseInt(lexeme.str, 10);\n        if (isNaN(boost)) {\n            var errorMessage = \"boost must be numeric\";\n            throw new lunr.QueryParseError(errorMessage, lexeme.start, lexeme.end);\n        }\n        parser.currentClause.boost = boost;\n        var nextLexeme = parser.peekLexeme();\n        if (nextLexeme == undefined) {\n            parser.nextClause();\n            return;\n        }\n        switch(nextLexeme.type){\n            case lunr.QueryLexer.TERM:\n                parser.nextClause();\n                return lunr.QueryParser.parseTerm;\n            case lunr.QueryLexer.FIELD:\n                parser.nextClause();\n                return lunr.QueryParser.parseField;\n            case lunr.QueryLexer.EDIT_DISTANCE:\n                return lunr.QueryParser.parseEditDistance;\n            case lunr.QueryLexer.BOOST:\n                return lunr.QueryParser.parseBoost;\n            case lunr.QueryLexer.PRESENCE:\n                parser.nextClause();\n                return lunr.QueryParser.parsePresence;\n            default:\n                var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\";\n                throw new lunr.QueryParseError(errorMessage, nextLexeme.start, nextLexeme.end);\n        }\n    } /**\n   * export the module via AMD, CommonJS or as a browser global\n   * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\n   */ ;\n    (function(root, factory) {\n        if (typeof define === \"function\" && define.amd) // AMD. Register as an anonymous module.\n        define(factory);\n        else /**\n       * Node. Does not work with strict CommonJS, but\n       * only CommonJS-like enviroments that support module.exports,\n       * like Node.\n       */ $9bd5008c96f03152$exports = factory();\n    })(this, function() {\n        /**\n     * Just return a value to define the module export.\n     * This example returns an object, but the module\n     * can return a function as the exported value.\n     */ return lunr;\n    });\n})();\n\n\n// set variables\nconst $6b70e849ffa4c4ec$var$htmlCollection = document.getElementsByClassName(\"excerpt\");\nconst $6b70e849ffa4c4ec$var$htmlPosts = [\n    ...$6b70e849ffa4c4ec$var$htmlCollection\n];\nconst $6b70e849ffa4c4ec$var$searchbar = document.getElementById(\"search\");\nconst $6b70e849ffa4c4ec$var$filter = document.getElementById(\"filter\");\nconst $6b70e849ffa4c4ec$var$postsContainer = document.getElementById(\"posts\");\nconst $6b70e849ffa4c4ec$var$noResults = document.getElementById(\"no-results\");\nconst $6b70e849ffa4c4ec$var$clearButton = document.getElementById(\"clear-filters\");\nconst $6b70e849ffa4c4ec$var$loadButton = document.getElementById(\"load-more\");\nlet $6b70e849ffa4c4ec$var$counter = 10;\n// create array of objects containing posts texts\nconst $6b70e849ffa4c4ec$var$posts = $6b70e849ffa4c4ec$var$htmlPosts.map((post)=>({\n        id: post.id,\n        content: post.innerText.replace(/\\n/g, \" \"),\n        feedback: post.dataset.feedback,\n        type: post.dataset.type.slice(1, -1),\n        degrees: post.dataset.degrees,\n        benefits: post.dataset.benefits,\n        location: post.dataset.location\n    }));\nvar $6b70e849ffa4c4ec$var$bigram = function(builder) {\n    // Define a pipeline function that stores two adjacent tokens together\n    var pipelineFunction = function(token, index, tokens) {\n        token.update(function(str, metadata) {\n            return str + \" \" + metadata.nextTokenStr;\n        });\n    };\n    // Register the pipeline function so the index can be serialised\n    (0, (/*@__PURE__*/$parcel$interopDefault($9bd5008c96f03152$exports))).Pipeline.registerFunction(pipelineFunction, \"bigram\");\n    // Add the pipeline function to both the indexing pipeline and the\n    // searching pipeline\n    builder.pipeline.before((0, (/*@__PURE__*/$parcel$interopDefault($9bd5008c96f03152$exports))).stemmer, pipelineFunction);\n    builder.searchPipeline.before((0, (/*@__PURE__*/$parcel$interopDefault($9bd5008c96f03152$exports))).stemmer, pipelineFunction);\n};\nvar $6b70e849ffa4c4ec$var$metadataUpdate = function(builder) {\n    // Define a pipeline function that stores two adjacent tokens together\n    var pipelineFunction = function(token, index, tokens) {\n        if (tokens[index + 1]) token.metadata[\"nextTokenStr\"] = tokens[index + 1].str;\n        else token.metadata[\"nextTokenStr\"] = \"\";\n        return token.update(function(str, metadata) {\n            return str + \" \" + metadata.nextTokenStr;\n        });\n    };\n    // Register the pipeline function so the index can be serialised\n    (0, (/*@__PURE__*/$parcel$interopDefault($9bd5008c96f03152$exports))).Pipeline.registerFunction(pipelineFunction, \"metadataUpdate\");\n    // Add the pipeline function to the indexing pipeline\n    builder.pipeline.before((0, (/*@__PURE__*/$parcel$interopDefault($9bd5008c96f03152$exports))).stemmer, pipelineFunction);\n    // Whitelist the tokenLength metadata key\n    builder.metadataWhitelist.push(\"nextTokenStr\");\n};\n// initiate lunr\nlet $6b70e849ffa4c4ec$var$idx = (0, (/*@__PURE__*/$parcel$interopDefault($9bd5008c96f03152$exports)))(function() {\n    this.ref(\"id\");\n    this.field(\"content\", {\n        boost: 10\n    });\n    this.field(\"feedback\", {\n        boost: 5\n    });\n    this.field(\"type\", {\n        boost: 5\n    });\n    this.field(\"degrees\", {\n        boost: 5\n    });\n    this.field(\"benefits\", {\n        boost: 5\n    });\n    this.field(\"location\", {\n        boost: 5\n    });\n    // remove buzz words that are causing random word eliminiation\n    this.pipeline.reset();\n    this.searchPipeline.reset();\n    // similarity tuning\n    this.k1(0.2);\n    this.b(1);\n    // this.use(metadataUpdate);\n    // this.use(bigram);\n    $6b70e849ffa4c4ec$var$posts.forEach(function(doc) {\n        this.add(doc);\n    }, this);\n});\n// automatic text search by typing in text input field\nconst $6b70e849ffa4c4ec$var$checkEnter = (e)=>{\n    e = e || event;\n    var txtArea = /textarea/i.test((e.target || e.srcElement).tagName);\n    return txtArea || (e.keyCode || e.which || e.charCode || 0) !== 13;\n};\n$6b70e849ffa4c4ec$var$searchbar.onkeypress = $6b70e849ffa4c4ec$var$checkEnter;\n$6b70e849ffa4c4ec$var$searchbar.addEventListener(\"input\", (event1)=>{\n    event1.preventDefault();\n    $6b70e849ffa4c4ec$var$loadButton.classList.add(\"hidden\");\n    $6b70e849ffa4c4ec$var$idx.query(function(q) {\n        // look for an exact match and apply a large positive boost\n        q.term(`+${event1.target.value}`, {\n            usePipeline: true,\n            boost: 100\n        });\n        // look for terms that match the beginning of this query term and apply a medium boost\n        q.term(`${event1.target.value}*`, {\n            usePipeline: false,\n            boost: 1\n        });\n        // look for terms that match with an edit distance of 2 and apply a small boost\n        q.term(event1.target.value, {\n            usePipeline: false,\n            editDistance: 2,\n            boost: 1\n        });\n    });\n    let results = $6b70e849ffa4c4ec$var$idx.search(`${event1.target.value}^100 ${event1.target.value}*^10 ${event1.target.value}~2`);\n    if (event1.target.value && results.length) {\n        $6b70e849ffa4c4ec$var$noResults.classList.add(\"hidden\");\n        $6b70e849ffa4c4ec$var$postsContainer.classList.remove(\"hidden\");\n        $6b70e849ffa4c4ec$var$htmlPosts.filter((post)=>{\n            post.classList.add(\"hidden\");\n            results.some((result)=>{\n                if (result.ref === post.id) post.classList.remove(\"hidden\");\n            });\n        });\n    } else if (event1.target.value) {\n        $6b70e849ffa4c4ec$var$noResults.classList.remove(\"hidden\");\n        $6b70e849ffa4c4ec$var$postsContainer.classList.add(\"hidden\");\n    } else {\n        $6b70e849ffa4c4ec$var$noResults.classList.add(\"hidden\");\n        $6b70e849ffa4c4ec$var$postsContainer.classList.remove(\"hidden\");\n        $6b70e849ffa4c4ec$var$htmlPosts.map((post)=>{\n            post.classList.remove(\"hidden\");\n        });\n    }\n});\n// search by submitting form of dropdown/checkboxes\n$6b70e849ffa4c4ec$var$filter.addEventListener(\"submit\", (event1)=>{\n    event1.preventDefault();\n    $6b70e849ffa4c4ec$var$loadButton.classList.add(\"hidden\");\n    let formData = new FormData($6b70e849ffa4c4ec$var$filter);\n    let options = [];\n    for (var pair of formData.entries())options = [\n        ...options,\n        ...pair\n    ];\n    options = options.filter((option)=>option !== \"on\" && option != \"location\" && option.length).map((option)=>{\n        const thisOption = `+${option}`;\n        return thisOption.replace(/\\-/g, \" +\") //.replace(\"time\", '')\n        ;\n    }).join(\" \");\n    $6b70e849ffa4c4ec$var$idx.query(function(q) {\n        // look for an exact match and apply a large positive boost\n        q.term(options, {\n            usePipeline: true,\n            boost: 100\n        });\n    });\n    let results = $6b70e849ffa4c4ec$var$idx.search(options);\n    if (options.length && results.length) {\n        $6b70e849ffa4c4ec$var$noResults.classList.add(\"hidden\");\n        $6b70e849ffa4c4ec$var$postsContainer.classList.remove(\"hidden\");\n        $6b70e849ffa4c4ec$var$htmlPosts.filter((post)=>{\n            post.classList.add(\"hidden\");\n            results.some((result)=>{\n                if (result.ref === post.id) post.classList.remove(\"hidden\");\n            });\n        });\n    } else if (options.length) {\n        $6b70e849ffa4c4ec$var$noResults.classList.remove(\"hidden\");\n        $6b70e849ffa4c4ec$var$postsContainer.classList.add(\"hidden\");\n    } else {\n        $6b70e849ffa4c4ec$var$noResults.classList.add(\"hidden\");\n        $6b70e849ffa4c4ec$var$postsContainer.classList.remove(\"hidden\");\n        $6b70e849ffa4c4ec$var$htmlPosts.map((post)=>{\n            post.classList.remove(\"hidden\");\n        });\n    }\n});\n// reset search on clear\n$6b70e849ffa4c4ec$var$clearButton.addEventListener(\"click\", (event1)=>{\n    $6b70e849ffa4c4ec$var$filter.reset();\n    $6b70e849ffa4c4ec$var$loadButton.classList.remove(\"hidden\");\n    $6b70e849ffa4c4ec$var$counter = 10;\n    $6b70e849ffa4c4ec$var$htmlPosts.map((post, index)=>{\n        if (index < $6b70e849ffa4c4ec$var$counter) post.classList.remove(\"hidden\");\n    });\n    $6b70e849ffa4c4ec$var$postsContainer.classList.remove(\"hidden\");\n});\n// load up to 10 posts on page load\nif ($6b70e849ffa4c4ec$var$htmlPosts.length) $6b70e849ffa4c4ec$var$htmlPosts.map((post, index)=>{\n    if (index >= 10) {\n        post.classList.add(\"hidden\");\n        $6b70e849ffa4c4ec$var$loadButton.classList.remove(\"hidden\");\n    } else {\n        post.classList.remove(\"hidden\");\n        $6b70e849ffa4c4ec$var$loadButton.classList.add(\"hidden\");\n    }\n});\n// load up to 10 posts more on load more click\n$6b70e849ffa4c4ec$var$loadButton.addEventListener(\"click\", (event1)=>{\n    if ($6b70e849ffa4c4ec$var$counter < $6b70e849ffa4c4ec$var$htmlPosts.length) {\n        $6b70e849ffa4c4ec$var$counter += 10;\n        $6b70e849ffa4c4ec$var$htmlPosts.map((post, index)=>{\n            if ($6b70e849ffa4c4ec$var$counter <= index <= $6b70e849ffa4c4ec$var$htmlPosts.length) post.classList.remove(\"hidden\");\n            else post.classList.add(\"hidden\");\n        });\n    } else $6b70e849ffa4c4ec$var$loadButton.classList.add(\"hidden\");\n});\n\n\n\n})();\n//# sourceMappingURL=custom.js.map\n","module.exports =\n/******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// define __esModule on exports\n/******/ \t__webpack_require__.r = function(exports) {\n/******/ \t\tObject.defineProperty(exports, '__esModule', { value: true });\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = \"./index.js\");\n/******/ })\n/************************************************************************/\n/******/ ({\n\n/***/ \"./index.js\":\n/*!******************!*\\\n  !*** ./index.js ***!\n  \\******************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\neval(\"//------------------------------------------------------------------------\\n// Disable scrolling (e.g. when modal window is open)\\n//\\n// Inspired by https://benfrain.com/preventing-body-scroll-for-modals-in-ios/\\n//\\n// Note: Once Safari and iOS Safari support the “touch-action” CSS property,\\n//       we can simply toggle a class that adds the following:\\n//\\n//       html,\\n//       body {\\n//         overflow: hidden !important;\\n//         touch-action: none !important;\\n//       }\\n//\\n//       /* Add class to elements like modal windows that still need to scroll */\\n//       .allow-scroll { touch-action: auto !important; }\\n//\\n// https://caniuse.com/#feat=css-touch-action\\n//------------------------------------------------------------------------\\n\\n\\nmodule.exports = {\\n  // Save current scroll position when scrolling is disabled so we can reset it when enabled\\n  _scrollPos: 0,\\n\\n  // Track whether or not we have injected CSS the already\\n  _hasCSS: false,\\n\\n  // Inject <style> tag with CSS rules (simpler than toggling a lot of inline styles)\\n  _injectCSS: function _injectCSS() {\\n\\n    // Don’t add styles more than once\\n    if (!this._hasCSS) {\\n      var css = '\\\\n        html.js-no-scroll { height: 100% !important; }\\\\n        .js-no-scroll body {\\\\n          height: 100%;\\\\n          overflow: hidden !important;\\\\n          position: fixed !important;\\\\n          width: 100% !important;\\\\n        }';\\n\\n      // Note: Setting “position: fixed” on the body prevents iOS from scrolling.\\n      //       However, this will cause the browser to scroll to the top, so we must\\n      //       add inline “height” and “top” styles to the body to address this.\\n\\n      // Create <style> tag and add to <head>\\n      // https://stackoverflow.com/a/524721/673457\\n      var styleEl = document.createElement('style');\\n      styleEl.type = 'text/css';\\n      styleEl.appendChild(document.createTextNode(css));\\n      document.head.appendChild(styleEl);\\n\\n      // Update var so we can avoid loading the CSS multiple times\\n      this._hasCSS = true;\\n    }\\n  },\\n\\n  _saveScrollPos: function _saveScrollPos() {\\n    this._scrollPos = window.pageYOffset || document.documentElement.scrollTop;\\n  },\\n\\n  /**\\n   * Disable scrolling\\n   */\\n  freeze: function freeze() {\\n    // Add required inline CSS (only runs first time)\\n    this._injectCSS();\\n\\n    this._saveScrollPos();\\n\\n    // Add class to prevent page scrolling (sets fixed position on body)\\n    document.documentElement.classList.add(\\\"js-no-scroll\\\");\\n\\n    // Add inline styles if not already at top of page\\n    if (this._scrollPos > 0) {\\n      document.body.style.height = \\\"calc(100% + \\\" + this._scrollPos + \\\"px)\\\";\\n      document.body.style.top = -this._scrollPos + \\\"px\\\";\\n    }\\n  },\\n\\n  /**\\n   * Enable scrolling\\n   */\\n  unfreeze: function unfreeze() {\\n    // Remove js-no-scroll class\\n    document.documentElement.classList.remove(\\\"js-no-scroll\\\");\\n\\n    if (this._scrollPos > 0) {\\n      // Remove inline styles on body, which causes the page to jump to the top.\\n      document.body.style.height = \\\"\\\";\\n      document.body.style.top = \\\"\\\";\\n\\n      // Disable native smooth scrolling before resetting the scroll position.\\n      // Otherwise, there would be an annoying jump after scrolling is enabled.\\n      if (document.documentElement.style.hasOwnProperty('scrollBehavior')) {\\n        document.documentElement.style.scrollBehavior = \\\"auto\\\";\\n      }\\n\\n      // Reset scroll position to what it was before scrolling was disabled.\\n      window.scrollTo(0, this._scrollPos);\\n\\n      // Re-enable native smooth scrolling\\n      if (document.documentElement.style.hasOwnProperty('scrollBehavior')) {\\n        document.documentElement.style.scrollBehavior = \\\"\\\";\\n      }\\n    }\\n  }\\n};\\n\\n//# sourceURL=webpack://%5Bname%5DLink/./index.js?\");\n\n/***/ })\n\n/******/ });\n//# sourceMappingURL=freeze-scroll.commonjs2.js.map"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = \"./index.js\");\n","import './modal.js';\nimport './search.js';\n","import Modal from \"./modals.js\";\n\nconst container = document.getElementById(\"info\");\n\nif (container) {\n  new Modal(container);\n}\n\n// If you have more than one modal on the page\n// const containers = document.querySelectorAll(\".Modal\");\n// containers.forEach(container => new Modal(container));\n","// by Threespot https://github.com/Threespot/modal\n// adding as a local module because Parcel is having\n// trouble with the npm installed module\n//------------------------------------------------------------------------\n// Modal windows\n//\n// - Progressively enhanced, works with pure CSS thanks to the `:target` pseudo selector\n// - Supports multiple toggles and multiple close buttons\n//\n// References:\n// - https://www.w3.org/TR/2017/NOTE-wai-aria-practices-1.1-20171214/examples/dialog-modal/dialog.html\n// - https://www.smashingmagazine.com/2014/09/making-modal-windows-better-for-everyone/\n// - https://www.smashingmagazine.com/2016/09/building-social-a-case-study-on-progressive-enhancement/\n// - https://bitsofco.de/accessible-modal-dialog/\n// - https://haltersweb.github.io/Accessibility/dialog.html\n// - https://yoast.com/dev-blog/the-a11y-monthly-making-modals-accessible/\n//\n// Note: Avoid aria-modal=\"true\" until support is beter\n//       https://labs.levelaccess.com/index.php/ARIA_Dialog_Role_with_modal_true\n//------------------------------------------------------------------------\n'use strict';\nimport scroll from '@threespot/freeze-scroll';\nimport EventEmitter from 'ev-emitter';\n\n/**\n * Accessible modal window\n * @param {HTMLElement} el - Toggle button DOM node\n * @param {Object} opts - Options\n * @param {number} [opts.transitionSpeed=\"100\"] - CSS transition speed, required to delay focus\n * @param {string} [opts.activeClasses=\"\"] - Class(es) to apply when modal is open\n * @param {string} [opts.modalContentClass=\"Modal-content\"] - Class of modal content wrapper\n * @param {function} [opts.onReady=\"\"] - Ready callback function\n */\nexport default class Modal extends EventEmitter {\n  constructor(el, opts) {\n    // Have to call super() first before referencing “this” since we’re extending EventEmitter\n    // https://stackoverflow.com/a/43591507/673457\n    super();\n\n    // Use Object.assign() to merge “opts” object with default values in this.options\n    this.options = Object.assign(\n      {},\n      {\n        transitionSpeed: 100, // CSS transition speed, required to delay focus\n        activeClasses: '', // string, accepts multiple space-separated classes\n        modalContentClass: 'Modal-content', // string, optional\n        onReady: null, // ready callback function\n      },\n      opts\n    );\n\n    if (this.options.activeClasses.length) {\n      // Check if active class string contains multiple classes\n      if (this.options.activeClasses.indexOf(' ') > -1) {\n        // Convert to array and remove any empty string values\n        // caused by having multiple spaces in a row.\n        this.options.activeClasses = this.options.activeClasses.split(' ').filter(n => n.length);\n      } else {\n        // We still need to convert a single active class to an array\n        // so we can use the spread syntax later in classList.add()\n        this.options.activeClasses = [this.options.activeClasses];\n      }\n    }\n\n    this.el = el;\n    this.el.classList.add('js-init');\n    this.isOpen = false;\n    this.hasToggles = false;\n    this.contentEl = this.el.querySelector('.Modal-content');\n    this.customContentEl = this.el.querySelector('.' + this.options.modalContentClass) || this.contentEl;\n    this.closeEls = this.el.querySelectorAll('[data-modal-close]');\n\n    // If modal has an ID, check for matching toggle elements with “data-modal” attribute\n    if (this.el.id) {\n      this.toggleEls = document.querySelectorAll(`[data-modal=\"${this.el.id}\"]`);\n      this.hasToggles = !!this.toggleEls.length;\n    } else {\n      // If modal doesn’t have an id, add a random one for “aria-controls”\n      // https://gist.github.com/gordonbrander/2230317\n      this.el.id = Math.random().toString(36).substr(2, 4);\n    }\n\n    // Store currently focused element when modal opens so we can restore focus when it closes\n    this.prevFocusedEl = null;\n\n    // Find focusable elements inside of modal window (used to prevent tabbing outside of modal)\n    this.focusableEls = this.getFocusableEls();\n\n    // Save first and last focusable elements\n    if (this.focusableEls.length) {\n      this.firstFocusableEl = this.focusableEls[0];\n      this.lastFocusableEl = this.focusableEls[this.focusableEls.length - 1];\n    }\n\n    // Check for aria-label/aria-labelledby on modal (a11y best practice)\n    if (!this.el.getAttribute('aria-label') && !this.el.getAttribute('aria-labelledby')) {\n      console.warn('A11y Issue: Modal window should have an “aria-label” or “aria-labelledby” attribute', this.el);\n    }\n\n    // Init modal window\n    this.init();\n  }\n\n  init() {\n    // Add aria attributes to modal window\n    this.el.setAttribute('aria-hidden', 'true');\n    this.el.setAttribute('role', 'dialog');\n\n    // Add aria attributes to toggle buttons\n    if (this.hasToggles) {\n      this.toggleEls.forEach(toggleEl => {\n        // Add “aria-controls” but be aware only JAWS supports it\n        // https://inclusive-components.design/menus-menu-buttons/#ariacontrols\n        toggleEl.setAttribute('aria-controls', this.el.id);\n        toggleEl.setAttribute('aria-expanded', 'false');\n        toggleEl.setAttribute('role', 'button');\n      });\n    }\n\n    // Add aria attributes to close buttons\n    if (this.closeEls.length) {\n      this.closeEls.forEach(closeEl => {\n        closeEl.setAttribute('role', 'button');\n      });\n    }\n\n    // Add event listeners\n    this.bindEvents();\n\n    // Check for ready callback\n    if (typeof this.options.onReady === 'function') {\n      this.options.onReady();\n    }\n\n    // Check URL hash to determine if modal should start open\n    // if (\n    //   this.el.id &&\n    //   window.location.hash &&\n    //   window.location.hash.substring(1) == this.el.id\n    // ) {\n    //   this.open();\n    // }\n  }\n\n  destroy() {\n    // Remove aria attributes on modal window\n    this.el.removeAttribute('aria-hidden');\n    this.el.removeAttribute('role');\n    this.el.removeAttribute('tabindex');\n\n    // Remove aria attributes on toggle buttons\n    if (this.hasToggles) {\n      this.toggleEls.forEach(toggleEl => {\n        toggleEl.removeAttribute('aria-controls');\n        toggleEl.removeAttribute('aria-expanded');\n        toggleEl.removeAttribute('role');\n      });\n    }\n\n    // Remove aria attributes on close buttons\n    if (this.closeEls.length) {\n      this.closeEls.forEach(closeEl => {\n        closeEl.removeAttribute('aria-label');\n        closeEl.removeAttribute('role');\n      });\n    }\n\n    // Remove event listeners\n    this.unbindEvents();\n\n    // Trigger destroy event\n    this.emitEvent('destroy');\n  }\n\n  // Find focusable elements inside of modal window (used to prevent tabbing outside of modal)\n  // https://bitsofco.de/accessible-modal-dialog/\n  getFocusableEls() {\n    let focusableEls = this.el.querySelectorAll(\n      'a[href], area[href], input:not([disabled]), select:not([disabled]), textarea:not([disabled]), button:not([disabled]), [tabindex=\"0\"]'\n    );\n\n    // Convert NodeList to Array\n    return [...focusableEls];\n  }\n\n  // Get currently focused element\n  // https://stackoverflow.com/a/40873560/673457\n  // Could also use document.querySelector(\":focus\") but that’s likely less performant\n  getFocusedEl() {\n    if (\n      document.hasFocus() &&\n      document.activeElement !== document.body &&\n      document.activeElement !== document.documentElement\n    ) {\n      return document.activeElement;\n    }\n\n    return null;\n  }\n\n  focusDelay(el) {\n    var self = this;\n    // Use setTimeout() to ensure element is focused\n    // https://stackoverflow.com/questions/33955650/what-is-settimeout-doing-when-set-to-0-milliseconds/33955673\n    // https://stackoverflow.com/questions/779379/why-is-settimeoutfn-0-sometimes-useful\n    // https://blog.sessionstack.com/how-javascript-works-event-loop-and-the-rise-of-async-programming-5-ways-to-better-coding-with-2f077c4438b5\n    window.setTimeout(() => el.focus(), this.options.transitionSpeed);\n  }\n\n  windowClickHandler(evt) {\n    // Ignore click on the toggle button, which already has an event handler\n    let isToggle = Array.prototype.indexOf.call(this.toggleEls, evt.target.closest('[data-modal]')) > -1;\n\n    // Don’t close if target el has been removed from the DOM by the time this callback runs\n    let targetElExists = document.body.contains(evt.target);\n\n    // Do nothing if modal is closed, a toggle was clicked,\n    // or target element no longer exists.\n    if (!this.isOpen || isToggle || !targetElExists) {\n      return;\n    }\n\n    // Don’t close if target is a child of the modal wrapper\n    let targetInsideWrapper = this.customContentEl && this.customContentEl.contains(evt.target);\n\n    // Don’t close if target is the modal wrapper itself\n    let targetIsWrapper = this.customContentEl.isSameNode(evt.target);\n\n    // For single-page apps or site using pjax (e.g. Turbolinks, Swup),\n    // we need to manually close the modal when a link is clicked,\n    // but ignore links that have been set to role=\"button\".\n    // let targetIsLink = evt.target.closest('a:not([role=\"button\"])');\n    //\n    // Then add this additional condition below:\n    // || (targetInsideWrapper && targetIsLink)\n\n    // Close when click target is outside of the modal window,\n    if (!(targetInsideWrapper || targetIsWrapper)) {\n      this.close(evt);\n    }\n  }\n\n  keydownHandler(evt) {\n    // Do nothing if modal is closed\n    if (!this.isOpen) {\n      return false;\n    }\n\n    // Close with escape key\n    if (evt.which === 27) {\n      this.close(evt);\n    }\n\n    // Prevent tabbing outside of modal\n    if (evt.which === 9) {\n      // If no focusable items, close the modal\n      if (!this.focusableEls.length) {\n        this.close(evt);\n        return false;\n      }\n\n      // Find currently focused element\n      let focusedEl = this.getFocusedEl();\n\n      // If tabbing forward and the last item is focued, focus the first item\n      if (!evt.shiftKey && focusedEl == this.lastFocusableEl) {\n        // Prevent default since we're manually focusing the first element\n        evt.preventDefault();\n        this.firstFocusableEl.focus();\n      } else if (evt.shiftKey && (focusedEl == this.firstFocusableEl || focusedEl == this.contentEl)) {\n        // If tabbing backwards and the first item is focused, focus the last item\n        evt.preventDefault();\n        this.lastFocusableEl.focus();\n      }\n    }\n  }\n\n  bindEvents() {\n    // Toggle buttons\n    if (this.hasToggles) {\n      // Note: Event callbacks need to be assigned to a var so they can be removed\n      // https://stackoverflow.com/a/22870717/673457\n      this.toggleClick = this.toggle.bind(this);\n\n      this.toggleEls.forEach(toggleEl => {\n        toggleEl.addEventListener('click', this.toggleClick);\n      });\n    }\n\n    // Close buttons\n    if (this.closeEls.length) {\n      // Event callback\n      this.closeClick = this.close.bind(this);\n\n      this.closeEls.forEach(closeEl => {\n        closeEl.addEventListener('click', this.closeClick);\n      });\n    }\n\n    // Close if click outside of modal content\n    this.windowClick = this.windowClickHandler.bind(this);\n    window.addEventListener('click', this.windowClick);\n\n    // Keyboard events\n    this.keydown = this.keydownHandler.bind(this);\n    window.addEventListener('keydown', this.keydown);\n  }\n\n  unbindEvents() {\n    // Toggle buttons\n    if (this.hasToggles) {\n      this.toggleEls.forEach(toggleEl => {\n        toggleEl.removeEventListener('click', this.toggleClick);\n      });\n    }\n\n    // Close buttons\n    if (this.closeEls.length) {\n      this.closeEls.forEach(closeEl => {\n        closeEl.removeEventListener('click', this.closeClick);\n      });\n    }\n\n    // Window events\n    window.removeEventListener('click', this.windowClick);\n    window.removeEventListener('keydown', this.keydown);\n  }\n\n  // Expand expandable\n  open(evt) {\n    evt.preventDefault();\n\n    // Save currently focused element to focus on close\n    this.prevFocusedEl = this.getFocusedEl();\n\n    // Disable scrolling\n    scroll.freeze();\n\n    // Scroll modal content to top\n    // (without this, content will be vertically centered)\n    if (this.contentEl) {\n      this.contentEl.scrollTop = 0;\n    }\n\n    // Update modal aria attributes\n    this.el.setAttribute('aria-hidden', 'false');\n\n    // Add custom classes\n    if (this.options.activeClasses.length) {\n      this.el.classList.add(...this.options.activeClasses);\n    }\n\n    // Update toggle aria attributes\n    if (this.hasToggles) {\n      this.toggleEls.forEach(toggleEl => {\n        toggleEl.setAttribute('aria-expanded', 'true');\n\n        // Add custom classes\n        if (this.options.activeClasses.length) {\n          toggleEl.classList.add(...this.options.activeClasses);\n        }\n      });\n    }\n\n    // Focus modal on open\n    if (this.contentEl) {\n      this.contentEl.setAttribute('tabindex', '-1');\n      this.focusDelay(this.contentEl);\n    } else {\n      this.el.setAttribute('tabindex', '-1');\n      this.focusDelay(this.el);\n    }\n\n    // Update URL hash so users can link directly to the modal window content\n    // Use history.replaceState() to prevent adding a new history entry\n    // Note: If replaceState isn’t supported, modal-toggles.js won’t prevent the\n    // default click event, causing the hash to update and creating a new history entry.\n    // if (history.replaceState) {\n    //   history.replaceState(null, \"\", \"#\" + this.el.id);\n    // }\n\n    // Update state\n    this.isOpen = true;\n\n    // Trigger open event\n    this.emitEvent('open');\n  }\n\n  // Collapse expandable\n  close(evt) {\n    evt.preventDefault();\n\n    // Clear hash using replaceState() to prevent adding a new history entry\n    // if (history.replaceState) {\n    //   history.replaceState(null, \"\", window.location.pathname);\n    // }\n\n    // Update modal aria attributes\n    this.el.setAttribute('aria-hidden', 'true');\n\n    // Remove custom classes\n    if (this.options.activeClasses.length) {\n      this.el.classList.remove(...this.options.activeClasses);\n    }\n\n    // Update toggle aria attributes\n    if (this.hasToggles) {\n      this.toggleEls.forEach(toggleEl => {\n        toggleEl.setAttribute('aria-expanded', 'false');\n\n        // Remove custom classes\n        if (this.options.activeClasses.length) {\n          toggleEl.classList.remove(...this.options.activeClasses);\n        }\n      });\n    }\n\n    // Enable scrolling\n    scroll.unfreeze();\n\n    // Shift focus to previously focused element\n    if (this.prevFocusedEl) {\n      this.focusDelay(this.prevFocusedEl);\n    } else if (this.hasToggles) {\n      // Focus the first toggle if nothing was previously focused\n      this.focusDelay(this.toggleEls[0]);\n    }\n\n    // Update state\n    this.isOpen = false;\n\n    // Trigger close event\n    this.emitEvent('close');\n  }\n\n  // Toggle expandable\n  toggle(evt) {\n    if (this.isOpen) {\n      this.close(evt);\n    } else {\n      this.open(evt);\n    }\n  }\n}\n","/**\n * EvEmitter v1.1.0\n * Lil' event emitter\n * MIT License\n */\n\n/* jshint unused: true, undef: true, strict: true */\n\n( function( global, factory ) {\n  // universal module definition\n  /* jshint strict: false */ /* globals define, module, window */\n  if ( typeof define == 'function' && define.amd ) {\n    // AMD - RequireJS\n    define( factory );\n  } else if ( typeof module == 'object' && module.exports ) {\n    // CommonJS - Browserify, Webpack\n    module.exports = factory();\n  } else {\n    // Browser globals\n    global.EvEmitter = factory();\n  }\n\n}( typeof window != 'undefined' ? window : this, function() {\n\n\"use strict\";\n\nfunction EvEmitter() {}\n\nvar proto = EvEmitter.prototype;\n\nproto.on = function( eventName, listener ) {\n  if ( !eventName || !listener ) {\n    return;\n  }\n  // set events hash\n  var events = this._events = this._events || {};\n  // set listeners array\n  var listeners = events[ eventName ] = events[ eventName ] || [];\n  // only add once\n  if ( listeners.indexOf( listener ) == -1 ) {\n    listeners.push( listener );\n  }\n\n  return this;\n};\n\nproto.once = function( eventName, listener ) {\n  if ( !eventName || !listener ) {\n    return;\n  }\n  // add event\n  this.on( eventName, listener );\n  // set once flag\n  // set onceEvents hash\n  var onceEvents = this._onceEvents = this._onceEvents || {};\n  // set onceListeners object\n  var onceListeners = onceEvents[ eventName ] = onceEvents[ eventName ] || {};\n  // set flag\n  onceListeners[ listener ] = true;\n\n  return this;\n};\n\nproto.off = function( eventName, listener ) {\n  var listeners = this._events && this._events[ eventName ];\n  if ( !listeners || !listeners.length ) {\n    return;\n  }\n  var index = listeners.indexOf( listener );\n  if ( index != -1 ) {\n    listeners.splice( index, 1 );\n  }\n\n  return this;\n};\n\nproto.emitEvent = function( eventName, args ) {\n  var listeners = this._events && this._events[ eventName ];\n  if ( !listeners || !listeners.length ) {\n    return;\n  }\n  // copy over to avoid interference if .off() in listener\n  listeners = listeners.slice(0);\n  args = args || [];\n  // once stuff\n  var onceListeners = this._onceEvents && this._onceEvents[ eventName ];\n\n  for ( var i=0; i < listeners.length; i++ ) {\n    var listener = listeners[i]\n    var isOnce = onceListeners && onceListeners[ listener ];\n    if ( isOnce ) {\n      // remove listener\n      // remove before trigger to prevent recursion\n      this.off( eventName, listener );\n      // unset once flag\n      delete onceListeners[ listener ];\n    }\n    // trigger listener\n    listener.apply( this, args );\n  }\n\n  return this;\n};\n\nproto.allOff = function() {\n  delete this._events;\n  delete this._onceEvents;\n};\n\nreturn EvEmitter;\n\n}));\n","import lunr from 'lunr';\n\n// set variables\nconst htmlCollection = document.getElementsByClassName('excerpt');\nconst htmlPosts = [...htmlCollection];\nconst searchbar = document.getElementById('search');\nconst filter = document.getElementById('filter');\nconst postsContainer = document.getElementById('posts');\nconst noResults = document.getElementById('no-results');\nconst clearButton = document.getElementById('clear-filters');\nconst loadButton = document.getElementById('load-more');\nlet counter = 10;\n\n\n// create array of objects containing posts texts\nconst posts = htmlPosts.map(post => (\n  {\n    id: post.id,\n    content: post.innerText.replace(/\\n/g, ' '),\n    feedback: post.dataset.feedback,\n    type: post.dataset.type.slice(1,-1),\n    degrees: post.dataset.degrees,\n    benefits: post.dataset.benefits,\n    location: post.dataset.location,\n  }\n));\n\nvar bigram = function (builder) {\n  // Define a pipeline function that stores two adjacent tokens together\n  var pipelineFunction = function (token, index, tokens) {\n    token.update(function(str, metadata) {\n      return str + \" \" + metadata.nextTokenStr;\n    })\n  }\n\n  // Register the pipeline function so the index can be serialised\n  lunr.Pipeline.registerFunction(pipelineFunction, 'bigram')\n\n  // Add the pipeline function to both the indexing pipeline and the\n  // searching pipeline\n  builder.pipeline.before(lunr.stemmer, pipelineFunction)\n  builder.searchPipeline.before(lunr.stemmer, pipelineFunction)\n}\n\n\nvar metadataUpdate = function (builder) {\n  // Define a pipeline function that stores two adjacent tokens together\n  var pipelineFunction = function (token, index, tokens) {\n    if (tokens[index + 1]) {\n      token.metadata['nextTokenStr'] = tokens[index + 1].str\n    } else {\n      token.metadata['nextTokenStr'] = \"\"\n    }\n    return token.update(function(str, metadata) {\n      return str + \" \" + metadata.nextTokenStr;\n    })\n  }\n\n  // Register the pipeline function so the index can be serialised\n  lunr.Pipeline.registerFunction(pipelineFunction, 'metadataUpdate')\n\n  // Add the pipeline function to the indexing pipeline\n  builder.pipeline.before(lunr.stemmer, pipelineFunction)\n\n  // Whitelist the tokenLength metadata key\n  builder.metadataWhitelist.push('nextTokenStr')\n}\n\n// initiate lunr\nlet idx = lunr(function () {\n  this.ref('id');\n  this.field('content', {boost: 10});\n  this.field('feedback', {boost: 5});\n  this.field('type', {boost: 5});\n  this.field('degrees', {boost: 5});\n  this.field('benefits', { boost: 5 });\n  this.field('location', { boost: 5 });\n\n  // remove buzz words that are causing random word eliminiation\n  this.pipeline.reset();\n  this.searchPipeline.reset();\n\n  // similarity tuning\n  this.k1(0.2);\n  this.b(1);\n\n  // this.use(metadataUpdate);\n  // this.use(bigram);\n\n  posts.forEach(function (doc) {\n    this.add(doc);\n  }, this);\n})\n\n// automatic text search by typing in text input field\nconst checkEnter = (e) => {\n e = e || event;\n var txtArea = /textarea/i.test((e.target || e.srcElement).tagName);\n return txtArea || (e.keyCode || e.which || e.charCode || 0) !== 13;\n}\n\nsearchbar.onkeypress = checkEnter;\n\nsearchbar.addEventListener('input', event => {\n  event.preventDefault();\n  loadButton.classList.add('hidden');\n\n  idx.query(function (q) {\n    // look for an exact match and apply a large positive boost\n    q.term(`+${event.target.value}`, { usePipeline: true, boost: 100 })\n\n    // look for terms that match the beginning of this query term and apply a medium boost\n    q.term(`${event.target.value}*`, { usePipeline: false, boost: 1 })\n\n    // look for terms that match with an edit distance of 2 and apply a small boost\n    q.term(event.target.value, { usePipeline: false, editDistance: 2, boost: 1 })\n  })\n\n  let results = idx.search(`${event.target.value}^100 ${event.target.value}*^10 ${event.target.value}~2`);\n\n  if (event.target.value && results.length) {\n    noResults.classList.add('hidden');\n    postsContainer.classList.remove('hidden');\n    htmlPosts.filter(post => {\n      post.classList.add('hidden');\n      results.some(result => {\n        if (result.ref === post.id) {\n          post.classList.remove('hidden');\n        }\n      })\n    })\n  } else if (event.target.value) {\n    noResults.classList.remove('hidden');\n    postsContainer.classList.add('hidden');\n  } else {\n    noResults.classList.add('hidden');\n    postsContainer.classList.remove('hidden');\n    htmlPosts.map(post => {\n      post.classList.remove('hidden');\n    })\n  }\n})\n\n// search by submitting form of dropdown/checkboxes\nfilter.addEventListener('submit', event => {\n  event.preventDefault();\n  loadButton.classList.add('hidden');\n  let formData = new FormData(filter);\n  let options = [];\n  for (var pair of formData.entries()) {\n    options = [...options, ...pair];\n  }\n\n  options = options\n    .filter(option => (option !== \"on\" && option != \"location\" && option.length))\n    .map(option => {\n      const thisOption = `+${option}`\n      return thisOption.replace(/\\-/g, ' +')//.replace(\"time\", '')\n    })\n    .join(\" \");\n\n\n  idx.query(function (q) {\n    // look for an exact match and apply a large positive boost\n    q.term(options, { usePipeline: true, boost: 100 })\n  })\n\n  let results = idx.search(options);\n\n  if (options.length && results.length) {\n    noResults.classList.add('hidden');\n    postsContainer.classList.remove('hidden');\n    htmlPosts.filter(post => {\n      post.classList.add('hidden');\n      results.some(result => {\n        if (result.ref === post.id) {\n          post.classList.remove('hidden');\n        }\n      })\n    })\n  } else if (options.length) {\n    noResults.classList.remove('hidden');\n    postsContainer.classList.add('hidden');\n  } else {\n    noResults.classList.add('hidden');\n    postsContainer.classList.remove('hidden');\n    htmlPosts.map(post => {\n      post.classList.remove('hidden');\n    })\n  }\n})\n\n// reset search on clear\nclearButton.addEventListener('click', event => {\n  filter.reset();\n  loadButton.classList.remove('hidden');\n  counter = 10;\n  htmlPosts.map((post, index) => {\n    if (index < counter) {\n      post.classList.remove('hidden');\n    }\n  })\n  postsContainer.classList.remove('hidden');\n});\n\n// load up to 10 posts on page load\nif (htmlPosts.length) {\n  htmlPosts.map((post, index) => {\n    if (index >= 10) {\n      post.classList.add('hidden');\n      loadButton.classList.remove('hidden');\n    } else {\n      post.classList.remove('hidden');\n      loadButton.classList.add('hidden');\n    }\n  })\n}\n\n// load up to 10 posts more on load more click\nloadButton.addEventListener('click', event => {\n  if (counter < htmlPosts.length) {\n    counter += 10;\n    htmlPosts.map((post, index) => {\n      if (counter <= index <= htmlPosts.length) {\n        post.classList.remove('hidden');\n      } else {\n        post.classList.add('hidden');\n      }\n    })\n  } else {\n    loadButton.classList.add('hidden');\n  }\n})\n","/**\n * lunr - http://lunrjs.com - A bit like Solr, but much smaller and not as bright - 2.3.9\n * Copyright (C) 2020 Oliver Nightingale\n * @license MIT\n */\n\n;(function(){\n\n/**\n * A convenience function for configuring and constructing\n * a new lunr Index.\n *\n * A lunr.Builder instance is created and the pipeline setup\n * with a trimmer, stop word filter and stemmer.\n *\n * This builder object is yielded to the configuration function\n * that is passed as a parameter, allowing the list of fields\n * and other builder parameters to be customised.\n *\n * All documents _must_ be added within the passed config function.\n *\n * @example\n * var idx = lunr(function () {\n *   this.field('title')\n *   this.field('body')\n *   this.ref('id')\n *\n *   documents.forEach(function (doc) {\n *     this.add(doc)\n *   }, this)\n * })\n *\n * @see {@link lunr.Builder}\n * @see {@link lunr.Pipeline}\n * @see {@link lunr.trimmer}\n * @see {@link lunr.stopWordFilter}\n * @see {@link lunr.stemmer}\n * @namespace {function} lunr\n */\nvar lunr = function (config) {\n  var builder = new lunr.Builder\n\n  builder.pipeline.add(\n    lunr.trimmer,\n    lunr.stopWordFilter,\n    lunr.stemmer\n  )\n\n  builder.searchPipeline.add(\n    lunr.stemmer\n  )\n\n  config.call(builder, builder)\n  return builder.build()\n}\n\nlunr.version = \"2.3.9\"\n/*!\n * lunr.utils\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * A namespace containing utils for the rest of the lunr library\n * @namespace lunr.utils\n */\nlunr.utils = {}\n\n/**\n * Print a warning message to the console.\n *\n * @param {String} message The message to be printed.\n * @memberOf lunr.utils\n * @function\n */\nlunr.utils.warn = (function (global) {\n  /* eslint-disable no-console */\n  return function (message) {\n    if (global.console && console.warn) {\n      console.warn(message)\n    }\n  }\n  /* eslint-enable no-console */\n})(this)\n\n/**\n * Convert an object to a string.\n *\n * In the case of `null` and `undefined` the function returns\n * the empty string, in all other cases the result of calling\n * `toString` on the passed object is returned.\n *\n * @param {Any} obj The object to convert to a string.\n * @return {String} string representation of the passed object.\n * @memberOf lunr.utils\n */\nlunr.utils.asString = function (obj) {\n  if (obj === void 0 || obj === null) {\n    return \"\"\n  } else {\n    return obj.toString()\n  }\n}\n\n/**\n * Clones an object.\n *\n * Will create a copy of an existing object such that any mutations\n * on the copy cannot affect the original.\n *\n * Only shallow objects are supported, passing a nested object to this\n * function will cause a TypeError.\n *\n * Objects with primitives, and arrays of primitives are supported.\n *\n * @param {Object} obj The object to clone.\n * @return {Object} a clone of the passed object.\n * @throws {TypeError} when a nested object is passed.\n * @memberOf Utils\n */\nlunr.utils.clone = function (obj) {\n  if (obj === null || obj === undefined) {\n    return obj\n  }\n\n  var clone = Object.create(null),\n      keys = Object.keys(obj)\n\n  for (var i = 0; i < keys.length; i++) {\n    var key = keys[i],\n        val = obj[key]\n\n    if (Array.isArray(val)) {\n      clone[key] = val.slice()\n      continue\n    }\n\n    if (typeof val === 'string' ||\n        typeof val === 'number' ||\n        typeof val === 'boolean') {\n      clone[key] = val\n      continue\n    }\n\n    throw new TypeError(\"clone is not deep and does not support nested objects\")\n  }\n\n  return clone\n}\nlunr.FieldRef = function (docRef, fieldName, stringValue) {\n  this.docRef = docRef\n  this.fieldName = fieldName\n  this._stringValue = stringValue\n}\n\nlunr.FieldRef.joiner = \"/\"\n\nlunr.FieldRef.fromString = function (s) {\n  var n = s.indexOf(lunr.FieldRef.joiner)\n\n  if (n === -1) {\n    throw \"malformed field ref string\"\n  }\n\n  var fieldRef = s.slice(0, n),\n      docRef = s.slice(n + 1)\n\n  return new lunr.FieldRef (docRef, fieldRef, s)\n}\n\nlunr.FieldRef.prototype.toString = function () {\n  if (this._stringValue == undefined) {\n    this._stringValue = this.fieldName + lunr.FieldRef.joiner + this.docRef\n  }\n\n  return this._stringValue\n}\n/*!\n * lunr.Set\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * A lunr set.\n *\n * @constructor\n */\nlunr.Set = function (elements) {\n  this.elements = Object.create(null)\n\n  if (elements) {\n    this.length = elements.length\n\n    for (var i = 0; i < this.length; i++) {\n      this.elements[elements[i]] = true\n    }\n  } else {\n    this.length = 0\n  }\n}\n\n/**\n * A complete set that contains all elements.\n *\n * @static\n * @readonly\n * @type {lunr.Set}\n */\nlunr.Set.complete = {\n  intersect: function (other) {\n    return other\n  },\n\n  union: function () {\n    return this\n  },\n\n  contains: function () {\n    return true\n  }\n}\n\n/**\n * An empty set that contains no elements.\n *\n * @static\n * @readonly\n * @type {lunr.Set}\n */\nlunr.Set.empty = {\n  intersect: function () {\n    return this\n  },\n\n  union: function (other) {\n    return other\n  },\n\n  contains: function () {\n    return false\n  }\n}\n\n/**\n * Returns true if this set contains the specified object.\n *\n * @param {object} object - Object whose presence in this set is to be tested.\n * @returns {boolean} - True if this set contains the specified object.\n */\nlunr.Set.prototype.contains = function (object) {\n  return !!this.elements[object]\n}\n\n/**\n * Returns a new set containing only the elements that are present in both\n * this set and the specified set.\n *\n * @param {lunr.Set} other - set to intersect with this set.\n * @returns {lunr.Set} a new set that is the intersection of this and the specified set.\n */\n\nlunr.Set.prototype.intersect = function (other) {\n  var a, b, elements, intersection = []\n\n  if (other === lunr.Set.complete) {\n    return this\n  }\n\n  if (other === lunr.Set.empty) {\n    return other\n  }\n\n  if (this.length < other.length) {\n    a = this\n    b = other\n  } else {\n    a = other\n    b = this\n  }\n\n  elements = Object.keys(a.elements)\n\n  for (var i = 0; i < elements.length; i++) {\n    var element = elements[i]\n    if (element in b.elements) {\n      intersection.push(element)\n    }\n  }\n\n  return new lunr.Set (intersection)\n}\n\n/**\n * Returns a new set combining the elements of this and the specified set.\n *\n * @param {lunr.Set} other - set to union with this set.\n * @return {lunr.Set} a new set that is the union of this and the specified set.\n */\n\nlunr.Set.prototype.union = function (other) {\n  if (other === lunr.Set.complete) {\n    return lunr.Set.complete\n  }\n\n  if (other === lunr.Set.empty) {\n    return this\n  }\n\n  return new lunr.Set(Object.keys(this.elements).concat(Object.keys(other.elements)))\n}\n/**\n * A function to calculate the inverse document frequency for\n * a posting. This is shared between the builder and the index\n *\n * @private\n * @param {object} posting - The posting for a given term\n * @param {number} documentCount - The total number of documents.\n */\nlunr.idf = function (posting, documentCount) {\n  var documentsWithTerm = 0\n\n  for (var fieldName in posting) {\n    if (fieldName == '_index') continue // Ignore the term index, its not a field\n    documentsWithTerm += Object.keys(posting[fieldName]).length\n  }\n\n  var x = (documentCount - documentsWithTerm + 0.5) / (documentsWithTerm + 0.5)\n\n  return Math.log(1 + Math.abs(x))\n}\n\n/**\n * A token wraps a string representation of a token\n * as it is passed through the text processing pipeline.\n *\n * @constructor\n * @param {string} [str=''] - The string token being wrapped.\n * @param {object} [metadata={}] - Metadata associated with this token.\n */\nlunr.Token = function (str, metadata) {\n  this.str = str || \"\"\n  this.metadata = metadata || {}\n}\n\n/**\n * Returns the token string that is being wrapped by this object.\n *\n * @returns {string}\n */\nlunr.Token.prototype.toString = function () {\n  return this.str\n}\n\n/**\n * A token update function is used when updating or optionally\n * when cloning a token.\n *\n * @callback lunr.Token~updateFunction\n * @param {string} str - The string representation of the token.\n * @param {Object} metadata - All metadata associated with this token.\n */\n\n/**\n * Applies the given function to the wrapped string token.\n *\n * @example\n * token.update(function (str, metadata) {\n *   return str.toUpperCase()\n * })\n *\n * @param {lunr.Token~updateFunction} fn - A function to apply to the token string.\n * @returns {lunr.Token}\n */\nlunr.Token.prototype.update = function (fn) {\n  this.str = fn(this.str, this.metadata)\n  return this\n}\n\n/**\n * Creates a clone of this token. Optionally a function can be\n * applied to the cloned token.\n *\n * @param {lunr.Token~updateFunction} [fn] - An optional function to apply to the cloned token.\n * @returns {lunr.Token}\n */\nlunr.Token.prototype.clone = function (fn) {\n  fn = fn || function (s) { return s }\n  return new lunr.Token (fn(this.str, this.metadata), this.metadata)\n}\n/*!\n * lunr.tokenizer\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * A function for splitting a string into tokens ready to be inserted into\n * the search index. Uses `lunr.tokenizer.separator` to split strings, change\n * the value of this property to change how strings are split into tokens.\n *\n * This tokenizer will convert its parameter to a string by calling `toString` and\n * then will split this string on the character in `lunr.tokenizer.separator`.\n * Arrays will have their elements converted to strings and wrapped in a lunr.Token.\n *\n * Optional metadata can be passed to the tokenizer, this metadata will be cloned and\n * added as metadata to every token that is created from the object to be tokenized.\n *\n * @static\n * @param {?(string|object|object[])} obj - The object to convert into tokens\n * @param {?object} metadata - Optional metadata to associate with every token\n * @returns {lunr.Token[]}\n * @see {@link lunr.Pipeline}\n */\nlunr.tokenizer = function (obj, metadata) {\n  if (obj == null || obj == undefined) {\n    return []\n  }\n\n  if (Array.isArray(obj)) {\n    return obj.map(function (t) {\n      return new lunr.Token(\n        lunr.utils.asString(t).toLowerCase(),\n        lunr.utils.clone(metadata)\n      )\n    })\n  }\n\n  var str = obj.toString().toLowerCase(),\n      len = str.length,\n      tokens = []\n\n  for (var sliceEnd = 0, sliceStart = 0; sliceEnd <= len; sliceEnd++) {\n    var char = str.charAt(sliceEnd),\n        sliceLength = sliceEnd - sliceStart\n\n    if ((char.match(lunr.tokenizer.separator) || sliceEnd == len)) {\n\n      if (sliceLength > 0) {\n        var tokenMetadata = lunr.utils.clone(metadata) || {}\n        tokenMetadata[\"position\"] = [sliceStart, sliceLength]\n        tokenMetadata[\"index\"] = tokens.length\n\n        tokens.push(\n          new lunr.Token (\n            str.slice(sliceStart, sliceEnd),\n            tokenMetadata\n          )\n        )\n      }\n\n      sliceStart = sliceEnd + 1\n    }\n\n  }\n\n  return tokens\n}\n\n/**\n * The separator used to split a string into tokens. Override this property to change the behaviour of\n * `lunr.tokenizer` behaviour when tokenizing strings. By default this splits on whitespace and hyphens.\n *\n * @static\n * @see lunr.tokenizer\n */\nlunr.tokenizer.separator = /[\\s\\-]+/\n/*!\n * lunr.Pipeline\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * lunr.Pipelines maintain an ordered list of functions to be applied to all\n * tokens in documents entering the search index and queries being ran against\n * the index.\n *\n * An instance of lunr.Index created with the lunr shortcut will contain a\n * pipeline with a stop word filter and an English language stemmer. Extra\n * functions can be added before or after either of these functions or these\n * default functions can be removed.\n *\n * When run the pipeline will call each function in turn, passing a token, the\n * index of that token in the original list of all tokens and finally a list of\n * all the original tokens.\n *\n * The output of functions in the pipeline will be passed to the next function\n * in the pipeline. To exclude a token from entering the index the function\n * should return undefined, the rest of the pipeline will not be called with\n * this token.\n *\n * For serialisation of pipelines to work, all functions used in an instance of\n * a pipeline should be registered with lunr.Pipeline. Registered functions can\n * then be loaded. If trying to load a serialised pipeline that uses functions\n * that are not registered an error will be thrown.\n *\n * If not planning on serialising the pipeline then registering pipeline functions\n * is not necessary.\n *\n * @constructor\n */\nlunr.Pipeline = function () {\n  this._stack = []\n}\n\nlunr.Pipeline.registeredFunctions = Object.create(null)\n\n/**\n * A pipeline function maps lunr.Token to lunr.Token. A lunr.Token contains the token\n * string as well as all known metadata. A pipeline function can mutate the token string\n * or mutate (or add) metadata for a given token.\n *\n * A pipeline function can indicate that the passed token should be discarded by returning\n * null, undefined or an empty string. This token will not be passed to any downstream pipeline\n * functions and will not be added to the index.\n *\n * Multiple tokens can be returned by returning an array of tokens. Each token will be passed\n * to any downstream pipeline functions and all will returned tokens will be added to the index.\n *\n * Any number of pipeline functions may be chained together using a lunr.Pipeline.\n *\n * @interface lunr.PipelineFunction\n * @param {lunr.Token} token - A token from the document being processed.\n * @param {number} i - The index of this token in the complete list of tokens for this document/field.\n * @param {lunr.Token[]} tokens - All tokens for this document/field.\n * @returns {(?lunr.Token|lunr.Token[])}\n */\n\n/**\n * Register a function with the pipeline.\n *\n * Functions that are used in the pipeline should be registered if the pipeline\n * needs to be serialised, or a serialised pipeline needs to be loaded.\n *\n * Registering a function does not add it to a pipeline, functions must still be\n * added to instances of the pipeline for them to be used when running a pipeline.\n *\n * @param {lunr.PipelineFunction} fn - The function to check for.\n * @param {String} label - The label to register this function with\n */\nlunr.Pipeline.registerFunction = function (fn, label) {\n  if (label in this.registeredFunctions) {\n    lunr.utils.warn('Overwriting existing registered function: ' + label)\n  }\n\n  fn.label = label\n  lunr.Pipeline.registeredFunctions[fn.label] = fn\n}\n\n/**\n * Warns if the function is not registered as a Pipeline function.\n *\n * @param {lunr.PipelineFunction} fn - The function to check for.\n * @private\n */\nlunr.Pipeline.warnIfFunctionNotRegistered = function (fn) {\n  var isRegistered = fn.label && (fn.label in this.registeredFunctions)\n\n  if (!isRegistered) {\n    lunr.utils.warn('Function is not registered with pipeline. This may cause problems when serialising the index.\\n', fn)\n  }\n}\n\n/**\n * Loads a previously serialised pipeline.\n *\n * All functions to be loaded must already be registered with lunr.Pipeline.\n * If any function from the serialised data has not been registered then an\n * error will be thrown.\n *\n * @param {Object} serialised - The serialised pipeline to load.\n * @returns {lunr.Pipeline}\n */\nlunr.Pipeline.load = function (serialised) {\n  var pipeline = new lunr.Pipeline\n\n  serialised.forEach(function (fnName) {\n    var fn = lunr.Pipeline.registeredFunctions[fnName]\n\n    if (fn) {\n      pipeline.add(fn)\n    } else {\n      throw new Error('Cannot load unregistered function: ' + fnName)\n    }\n  })\n\n  return pipeline\n}\n\n/**\n * Adds new functions to the end of the pipeline.\n *\n * Logs a warning if the function has not been registered.\n *\n * @param {lunr.PipelineFunction[]} functions - Any number of functions to add to the pipeline.\n */\nlunr.Pipeline.prototype.add = function () {\n  var fns = Array.prototype.slice.call(arguments)\n\n  fns.forEach(function (fn) {\n    lunr.Pipeline.warnIfFunctionNotRegistered(fn)\n    this._stack.push(fn)\n  }, this)\n}\n\n/**\n * Adds a single function after a function that already exists in the\n * pipeline.\n *\n * Logs a warning if the function has not been registered.\n *\n * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n */\nlunr.Pipeline.prototype.after = function (existingFn, newFn) {\n  lunr.Pipeline.warnIfFunctionNotRegistered(newFn)\n\n  var pos = this._stack.indexOf(existingFn)\n  if (pos == -1) {\n    throw new Error('Cannot find existingFn')\n  }\n\n  pos = pos + 1\n  this._stack.splice(pos, 0, newFn)\n}\n\n/**\n * Adds a single function before a function that already exists in the\n * pipeline.\n *\n * Logs a warning if the function has not been registered.\n *\n * @param {lunr.PipelineFunction} existingFn - A function that already exists in the pipeline.\n * @param {lunr.PipelineFunction} newFn - The new function to add to the pipeline.\n */\nlunr.Pipeline.prototype.before = function (existingFn, newFn) {\n  lunr.Pipeline.warnIfFunctionNotRegistered(newFn)\n\n  var pos = this._stack.indexOf(existingFn)\n  if (pos == -1) {\n    throw new Error('Cannot find existingFn')\n  }\n\n  this._stack.splice(pos, 0, newFn)\n}\n\n/**\n * Removes a function from the pipeline.\n *\n * @param {lunr.PipelineFunction} fn The function to remove from the pipeline.\n */\nlunr.Pipeline.prototype.remove = function (fn) {\n  var pos = this._stack.indexOf(fn)\n  if (pos == -1) {\n    return\n  }\n\n  this._stack.splice(pos, 1)\n}\n\n/**\n * Runs the current list of functions that make up the pipeline against the\n * passed tokens.\n *\n * @param {Array} tokens The tokens to run through the pipeline.\n * @returns {Array}\n */\nlunr.Pipeline.prototype.run = function (tokens) {\n  var stackLength = this._stack.length\n\n  for (var i = 0; i < stackLength; i++) {\n    var fn = this._stack[i]\n    var memo = []\n\n    for (var j = 0; j < tokens.length; j++) {\n      var result = fn(tokens[j], j, tokens)\n\n      if (result === null || result === void 0 || result === '') continue\n\n      if (Array.isArray(result)) {\n        for (var k = 0; k < result.length; k++) {\n          memo.push(result[k])\n        }\n      } else {\n        memo.push(result)\n      }\n    }\n\n    tokens = memo\n  }\n\n  return tokens\n}\n\n/**\n * Convenience method for passing a string through a pipeline and getting\n * strings out. This method takes care of wrapping the passed string in a\n * token and mapping the resulting tokens back to strings.\n *\n * @param {string} str - The string to pass through the pipeline.\n * @param {?object} metadata - Optional metadata to associate with the token\n * passed to the pipeline.\n * @returns {string[]}\n */\nlunr.Pipeline.prototype.runString = function (str, metadata) {\n  var token = new lunr.Token (str, metadata)\n\n  return this.run([token]).map(function (t) {\n    return t.toString()\n  })\n}\n\n/**\n * Resets the pipeline by removing any existing processors.\n *\n */\nlunr.Pipeline.prototype.reset = function () {\n  this._stack = []\n}\n\n/**\n * Returns a representation of the pipeline ready for serialisation.\n *\n * Logs a warning if the function has not been registered.\n *\n * @returns {Array}\n */\nlunr.Pipeline.prototype.toJSON = function () {\n  return this._stack.map(function (fn) {\n    lunr.Pipeline.warnIfFunctionNotRegistered(fn)\n\n    return fn.label\n  })\n}\n/*!\n * lunr.Vector\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * A vector is used to construct the vector space of documents and queries. These\n * vectors support operations to determine the similarity between two documents or\n * a document and a query.\n *\n * Normally no parameters are required for initializing a vector, but in the case of\n * loading a previously dumped vector the raw elements can be provided to the constructor.\n *\n * For performance reasons vectors are implemented with a flat array, where an elements\n * index is immediately followed by its value. E.g. [index, value, index, value]. This\n * allows the underlying array to be as sparse as possible and still offer decent\n * performance when being used for vector calculations.\n *\n * @constructor\n * @param {Number[]} [elements] - The flat list of element index and element value pairs.\n */\nlunr.Vector = function (elements) {\n  this._magnitude = 0\n  this.elements = elements || []\n}\n\n\n/**\n * Calculates the position within the vector to insert a given index.\n *\n * This is used internally by insert and upsert. If there are duplicate indexes then\n * the position is returned as if the value for that index were to be updated, but it\n * is the callers responsibility to check whether there is a duplicate at that index\n *\n * @param {Number} insertIdx - The index at which the element should be inserted.\n * @returns {Number}\n */\nlunr.Vector.prototype.positionForIndex = function (index) {\n  // For an empty vector the tuple can be inserted at the beginning\n  if (this.elements.length == 0) {\n    return 0\n  }\n\n  var start = 0,\n      end = this.elements.length / 2,\n      sliceLength = end - start,\n      pivotPoint = Math.floor(sliceLength / 2),\n      pivotIndex = this.elements[pivotPoint * 2]\n\n  while (sliceLength > 1) {\n    if (pivotIndex < index) {\n      start = pivotPoint\n    }\n\n    if (pivotIndex > index) {\n      end = pivotPoint\n    }\n\n    if (pivotIndex == index) {\n      break\n    }\n\n    sliceLength = end - start\n    pivotPoint = start + Math.floor(sliceLength / 2)\n    pivotIndex = this.elements[pivotPoint * 2]\n  }\n\n  if (pivotIndex == index) {\n    return pivotPoint * 2\n  }\n\n  if (pivotIndex > index) {\n    return pivotPoint * 2\n  }\n\n  if (pivotIndex < index) {\n    return (pivotPoint + 1) * 2\n  }\n}\n\n/**\n * Inserts an element at an index within the vector.\n *\n * Does not allow duplicates, will throw an error if there is already an entry\n * for this index.\n *\n * @param {Number} insertIdx - The index at which the element should be inserted.\n * @param {Number} val - The value to be inserted into the vector.\n */\nlunr.Vector.prototype.insert = function (insertIdx, val) {\n  this.upsert(insertIdx, val, function () {\n    throw \"duplicate index\"\n  })\n}\n\n/**\n * Inserts or updates an existing index within the vector.\n *\n * @param {Number} insertIdx - The index at which the element should be inserted.\n * @param {Number} val - The value to be inserted into the vector.\n * @param {function} fn - A function that is called for updates, the existing value and the\n * requested value are passed as arguments\n */\nlunr.Vector.prototype.upsert = function (insertIdx, val, fn) {\n  this._magnitude = 0\n  var position = this.positionForIndex(insertIdx)\n\n  if (this.elements[position] == insertIdx) {\n    this.elements[position + 1] = fn(this.elements[position + 1], val)\n  } else {\n    this.elements.splice(position, 0, insertIdx, val)\n  }\n}\n\n/**\n * Calculates the magnitude of this vector.\n *\n * @returns {Number}\n */\nlunr.Vector.prototype.magnitude = function () {\n  if (this._magnitude) return this._magnitude\n\n  var sumOfSquares = 0,\n      elementsLength = this.elements.length\n\n  for (var i = 1; i < elementsLength; i += 2) {\n    var val = this.elements[i]\n    sumOfSquares += val * val\n  }\n\n  return this._magnitude = Math.sqrt(sumOfSquares)\n}\n\n/**\n * Calculates the dot product of this vector and another vector.\n *\n * @param {lunr.Vector} otherVector - The vector to compute the dot product with.\n * @returns {Number}\n */\nlunr.Vector.prototype.dot = function (otherVector) {\n  var dotProduct = 0,\n      a = this.elements, b = otherVector.elements,\n      aLen = a.length, bLen = b.length,\n      aVal = 0, bVal = 0,\n      i = 0, j = 0\n\n  while (i < aLen && j < bLen) {\n    aVal = a[i], bVal = b[j]\n    if (aVal < bVal) {\n      i += 2\n    } else if (aVal > bVal) {\n      j += 2\n    } else if (aVal == bVal) {\n      dotProduct += a[i + 1] * b[j + 1]\n      i += 2\n      j += 2\n    }\n  }\n\n  return dotProduct\n}\n\n/**\n * Calculates the similarity between this vector and another vector.\n *\n * @param {lunr.Vector} otherVector - The other vector to calculate the\n * similarity with.\n * @returns {Number}\n */\nlunr.Vector.prototype.similarity = function (otherVector) {\n  return this.dot(otherVector) / this.magnitude() || 0\n}\n\n/**\n * Converts the vector to an array of the elements within the vector.\n *\n * @returns {Number[]}\n */\nlunr.Vector.prototype.toArray = function () {\n  var output = new Array (this.elements.length / 2)\n\n  for (var i = 1, j = 0; i < this.elements.length; i += 2, j++) {\n    output[j] = this.elements[i]\n  }\n\n  return output\n}\n\n/**\n * A JSON serializable representation of the vector.\n *\n * @returns {Number[]}\n */\nlunr.Vector.prototype.toJSON = function () {\n  return this.elements\n}\n/* eslint-disable */\n/*!\n * lunr.stemmer\n * Copyright (C) 2020 Oliver Nightingale\n * Includes code from - http://tartarus.org/~martin/PorterStemmer/js.txt\n */\n\n/**\n * lunr.stemmer is an english language stemmer, this is a JavaScript\n * implementation of the PorterStemmer taken from http://tartarus.org/~martin\n *\n * @static\n * @implements {lunr.PipelineFunction}\n * @param {lunr.Token} token - The string to stem\n * @returns {lunr.Token}\n * @see {@link lunr.Pipeline}\n * @function\n */\nlunr.stemmer = (function(){\n  var step2list = {\n      \"ational\" : \"ate\",\n      \"tional\" : \"tion\",\n      \"enci\" : \"ence\",\n      \"anci\" : \"ance\",\n      \"izer\" : \"ize\",\n      \"bli\" : \"ble\",\n      \"alli\" : \"al\",\n      \"entli\" : \"ent\",\n      \"eli\" : \"e\",\n      \"ousli\" : \"ous\",\n      \"ization\" : \"ize\",\n      \"ation\" : \"ate\",\n      \"ator\" : \"ate\",\n      \"alism\" : \"al\",\n      \"iveness\" : \"ive\",\n      \"fulness\" : \"ful\",\n      \"ousness\" : \"ous\",\n      \"aliti\" : \"al\",\n      \"iviti\" : \"ive\",\n      \"biliti\" : \"ble\",\n      \"logi\" : \"log\"\n    },\n\n    step3list = {\n      \"icate\" : \"ic\",\n      \"ative\" : \"\",\n      \"alize\" : \"al\",\n      \"iciti\" : \"ic\",\n      \"ical\" : \"ic\",\n      \"ful\" : \"\",\n      \"ness\" : \"\"\n    },\n\n    c = \"[^aeiou]\",          // consonant\n    v = \"[aeiouy]\",          // vowel\n    C = c + \"[^aeiouy]*\",    // consonant sequence\n    V = v + \"[aeiou]*\",      // vowel sequence\n\n    mgr0 = \"^(\" + C + \")?\" + V + C,               // [C]VC... is m>0\n    meq1 = \"^(\" + C + \")?\" + V + C + \"(\" + V + \")?$\",  // [C]VC[V] is m=1\n    mgr1 = \"^(\" + C + \")?\" + V + C + V + C,       // [C]VCVC... is m>1\n    s_v = \"^(\" + C + \")?\" + v;                   // vowel in stem\n\n  var re_mgr0 = new RegExp(mgr0);\n  var re_mgr1 = new RegExp(mgr1);\n  var re_meq1 = new RegExp(meq1);\n  var re_s_v = new RegExp(s_v);\n\n  var re_1a = /^(.+?)(ss|i)es$/;\n  var re2_1a = /^(.+?)([^s])s$/;\n  var re_1b = /^(.+?)eed$/;\n  var re2_1b = /^(.+?)(ed|ing)$/;\n  var re_1b_2 = /.$/;\n  var re2_1b_2 = /(at|bl|iz)$/;\n  var re3_1b_2 = new RegExp(\"([^aeiouylsz])\\\\1$\");\n  var re4_1b_2 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\n  var re_1c = /^(.+?[^aeiou])y$/;\n  var re_2 = /^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/;\n\n  var re_3 = /^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/;\n\n  var re_4 = /^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/;\n  var re2_4 = /^(.+?)(s|t)(ion)$/;\n\n  var re_5 = /^(.+?)e$/;\n  var re_5_1 = /ll$/;\n  var re3_5 = new RegExp(\"^\" + C + v + \"[^aeiouwxy]$\");\n\n  var porterStemmer = function porterStemmer(w) {\n    var stem,\n      suffix,\n      firstch,\n      re,\n      re2,\n      re3,\n      re4;\n\n    if (w.length < 3) { return w; }\n\n    firstch = w.substr(0,1);\n    if (firstch == \"y\") {\n      w = firstch.toUpperCase() + w.substr(1);\n    }\n\n    // Step 1a\n    re = re_1a\n    re2 = re2_1a;\n\n    if (re.test(w)) { w = w.replace(re,\"$1$2\"); }\n    else if (re2.test(w)) { w = w.replace(re2,\"$1$2\"); }\n\n    // Step 1b\n    re = re_1b;\n    re2 = re2_1b;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      re = re_mgr0;\n      if (re.test(fp[1])) {\n        re = re_1b_2;\n        w = w.replace(re,\"\");\n      }\n    } else if (re2.test(w)) {\n      var fp = re2.exec(w);\n      stem = fp[1];\n      re2 = re_s_v;\n      if (re2.test(stem)) {\n        w = stem;\n        re2 = re2_1b_2;\n        re3 = re3_1b_2;\n        re4 = re4_1b_2;\n        if (re2.test(w)) { w = w + \"e\"; }\n        else if (re3.test(w)) { re = re_1b_2; w = w.replace(re,\"\"); }\n        else if (re4.test(w)) { w = w + \"e\"; }\n      }\n    }\n\n    // Step 1c - replace suffix y or Y by i if preceded by a non-vowel which is not the first letter of the word (so cry -> cri, by -> by, say -> say)\n    re = re_1c;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      w = stem + \"i\";\n    }\n\n    // Step 2\n    re = re_2;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      suffix = fp[2];\n      re = re_mgr0;\n      if (re.test(stem)) {\n        w = stem + step2list[suffix];\n      }\n    }\n\n    // Step 3\n    re = re_3;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      suffix = fp[2];\n      re = re_mgr0;\n      if (re.test(stem)) {\n        w = stem + step3list[suffix];\n      }\n    }\n\n    // Step 4\n    re = re_4;\n    re2 = re2_4;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      re = re_mgr1;\n      if (re.test(stem)) {\n        w = stem;\n      }\n    } else if (re2.test(w)) {\n      var fp = re2.exec(w);\n      stem = fp[1] + fp[2];\n      re2 = re_mgr1;\n      if (re2.test(stem)) {\n        w = stem;\n      }\n    }\n\n    // Step 5\n    re = re_5;\n    if (re.test(w)) {\n      var fp = re.exec(w);\n      stem = fp[1];\n      re = re_mgr1;\n      re2 = re_meq1;\n      re3 = re3_5;\n      if (re.test(stem) || (re2.test(stem) && !(re3.test(stem)))) {\n        w = stem;\n      }\n    }\n\n    re = re_5_1;\n    re2 = re_mgr1;\n    if (re.test(w) && re2.test(w)) {\n      re = re_1b_2;\n      w = w.replace(re,\"\");\n    }\n\n    // and turn initial Y back to y\n\n    if (firstch == \"y\") {\n      w = firstch.toLowerCase() + w.substr(1);\n    }\n\n    return w;\n  };\n\n  return function (token) {\n    return token.update(porterStemmer);\n  }\n})();\n\nlunr.Pipeline.registerFunction(lunr.stemmer, 'stemmer')\n/*!\n * lunr.stopWordFilter\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * lunr.generateStopWordFilter builds a stopWordFilter function from the provided\n * list of stop words.\n *\n * The built in lunr.stopWordFilter is built using this generator and can be used\n * to generate custom stopWordFilters for applications or non English languages.\n *\n * @function\n * @param {Array} token The token to pass through the filter\n * @returns {lunr.PipelineFunction}\n * @see lunr.Pipeline\n * @see lunr.stopWordFilter\n */\nlunr.generateStopWordFilter = function (stopWords) {\n  var words = stopWords.reduce(function (memo, stopWord) {\n    memo[stopWord] = stopWord\n    return memo\n  }, {})\n\n  return function (token) {\n    if (token && words[token.toString()] !== token.toString()) return token\n  }\n}\n\n/**\n * lunr.stopWordFilter is an English language stop word list filter, any words\n * contained in the list will not be passed through the filter.\n *\n * This is intended to be used in the Pipeline. If the token does not pass the\n * filter then undefined will be returned.\n *\n * @function\n * @implements {lunr.PipelineFunction}\n * @params {lunr.Token} token - A token to check for being a stop word.\n * @returns {lunr.Token}\n * @see {@link lunr.Pipeline}\n */\nlunr.stopWordFilter = lunr.generateStopWordFilter([\n  'a',\n  'able',\n  'about',\n  'across',\n  'after',\n  'all',\n  'almost',\n  'also',\n  'am',\n  'among',\n  'an',\n  'and',\n  'any',\n  'are',\n  'as',\n  'at',\n  'be',\n  'because',\n  'been',\n  'but',\n  'by',\n  'can',\n  'cannot',\n  'could',\n  'dear',\n  'did',\n  'do',\n  'does',\n  'either',\n  'else',\n  'ever',\n  'every',\n  'for',\n  'from',\n  'get',\n  'got',\n  'had',\n  'has',\n  'have',\n  'he',\n  'her',\n  'hers',\n  'him',\n  'his',\n  'how',\n  'however',\n  'i',\n  'if',\n  'in',\n  'into',\n  'is',\n  'it',\n  'its',\n  'just',\n  'least',\n  'let',\n  'like',\n  'likely',\n  'may',\n  'me',\n  'might',\n  'most',\n  'must',\n  'my',\n  'neither',\n  'no',\n  'nor',\n  'not',\n  'of',\n  'off',\n  'often',\n  'on',\n  'only',\n  'or',\n  'other',\n  'our',\n  'own',\n  'rather',\n  'said',\n  'say',\n  'says',\n  'she',\n  'should',\n  'since',\n  'so',\n  'some',\n  'than',\n  'that',\n  'the',\n  'their',\n  'them',\n  'then',\n  'there',\n  'these',\n  'they',\n  'this',\n  'tis',\n  'to',\n  'too',\n  'twas',\n  'us',\n  'wants',\n  'was',\n  'we',\n  'were',\n  'what',\n  'when',\n  'where',\n  'which',\n  'while',\n  'who',\n  'whom',\n  'why',\n  'will',\n  'with',\n  'would',\n  'yet',\n  'you',\n  'your'\n])\n\nlunr.Pipeline.registerFunction(lunr.stopWordFilter, 'stopWordFilter')\n/*!\n * lunr.trimmer\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * lunr.trimmer is a pipeline function for trimming non word\n * characters from the beginning and end of tokens before they\n * enter the index.\n *\n * This implementation may not work correctly for non latin\n * characters and should either be removed or adapted for use\n * with languages with non-latin characters.\n *\n * @static\n * @implements {lunr.PipelineFunction}\n * @param {lunr.Token} token The token to pass through the filter\n * @returns {lunr.Token}\n * @see lunr.Pipeline\n */\nlunr.trimmer = function (token) {\n  return token.update(function (s) {\n    return s.replace(/^\\W+/, '').replace(/\\W+$/, '')\n  })\n}\n\nlunr.Pipeline.registerFunction(lunr.trimmer, 'trimmer')\n/*!\n * lunr.TokenSet\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * A token set is used to store the unique list of all tokens\n * within an index. Token sets are also used to represent an\n * incoming query to the index, this query token set and index\n * token set are then intersected to find which tokens to look\n * up in the inverted index.\n *\n * A token set can hold multiple tokens, as in the case of the\n * index token set, or it can hold a single token as in the\n * case of a simple query token set.\n *\n * Additionally token sets are used to perform wildcard matching.\n * Leading, contained and trailing wildcards are supported, and\n * from this edit distance matching can also be provided.\n *\n * Token sets are implemented as a minimal finite state automata,\n * where both common prefixes and suffixes are shared between tokens.\n * This helps to reduce the space used for storing the token set.\n *\n * @constructor\n */\nlunr.TokenSet = function () {\n  this.final = false\n  this.edges = {}\n  this.id = lunr.TokenSet._nextId\n  lunr.TokenSet._nextId += 1\n}\n\n/**\n * Keeps track of the next, auto increment, identifier to assign\n * to a new tokenSet.\n *\n * TokenSets require a unique identifier to be correctly minimised.\n *\n * @private\n */\nlunr.TokenSet._nextId = 1\n\n/**\n * Creates a TokenSet instance from the given sorted array of words.\n *\n * @param {String[]} arr - A sorted array of strings to create the set from.\n * @returns {lunr.TokenSet}\n * @throws Will throw an error if the input array is not sorted.\n */\nlunr.TokenSet.fromArray = function (arr) {\n  var builder = new lunr.TokenSet.Builder\n\n  for (var i = 0, len = arr.length; i < len; i++) {\n    builder.insert(arr[i])\n  }\n\n  builder.finish()\n  return builder.root\n}\n\n/**\n * Creates a token set from a query clause.\n *\n * @private\n * @param {Object} clause - A single clause from lunr.Query.\n * @param {string} clause.term - The query clause term.\n * @param {number} [clause.editDistance] - The optional edit distance for the term.\n * @returns {lunr.TokenSet}\n */\nlunr.TokenSet.fromClause = function (clause) {\n  if ('editDistance' in clause) {\n    return lunr.TokenSet.fromFuzzyString(clause.term, clause.editDistance)\n  } else {\n    return lunr.TokenSet.fromString(clause.term)\n  }\n}\n\n/**\n * Creates a token set representing a single string with a specified\n * edit distance.\n *\n * Insertions, deletions, substitutions and transpositions are each\n * treated as an edit distance of 1.\n *\n * Increasing the allowed edit distance will have a dramatic impact\n * on the performance of both creating and intersecting these TokenSets.\n * It is advised to keep the edit distance less than 3.\n *\n * @param {string} str - The string to create the token set from.\n * @param {number} editDistance - The allowed edit distance to match.\n * @returns {lunr.Vector}\n */\nlunr.TokenSet.fromFuzzyString = function (str, editDistance) {\n  var root = new lunr.TokenSet\n\n  var stack = [{\n    node: root,\n    editsRemaining: editDistance,\n    str: str\n  }]\n\n  while (stack.length) {\n    var frame = stack.pop()\n\n    // no edit\n    if (frame.str.length > 0) {\n      var char = frame.str.charAt(0),\n          noEditNode\n\n      if (char in frame.node.edges) {\n        noEditNode = frame.node.edges[char]\n      } else {\n        noEditNode = new lunr.TokenSet\n        frame.node.edges[char] = noEditNode\n      }\n\n      if (frame.str.length == 1) {\n        noEditNode.final = true\n      }\n\n      stack.push({\n        node: noEditNode,\n        editsRemaining: frame.editsRemaining,\n        str: frame.str.slice(1)\n      })\n    }\n\n    if (frame.editsRemaining == 0) {\n      continue\n    }\n\n    // insertion\n    if (\"*\" in frame.node.edges) {\n      var insertionNode = frame.node.edges[\"*\"]\n    } else {\n      var insertionNode = new lunr.TokenSet\n      frame.node.edges[\"*\"] = insertionNode\n    }\n\n    if (frame.str.length == 0) {\n      insertionNode.final = true\n    }\n\n    stack.push({\n      node: insertionNode,\n      editsRemaining: frame.editsRemaining - 1,\n      str: frame.str\n    })\n\n    // deletion\n    // can only do a deletion if we have enough edits remaining\n    // and if there are characters left to delete in the string\n    if (frame.str.length > 1) {\n      stack.push({\n        node: frame.node,\n        editsRemaining: frame.editsRemaining - 1,\n        str: frame.str.slice(1)\n      })\n    }\n\n    // deletion\n    // just removing the last character from the str\n    if (frame.str.length == 1) {\n      frame.node.final = true\n    }\n\n    // substitution\n    // can only do a substitution if we have enough edits remaining\n    // and if there are characters left to substitute\n    if (frame.str.length >= 1) {\n      if (\"*\" in frame.node.edges) {\n        var substitutionNode = frame.node.edges[\"*\"]\n      } else {\n        var substitutionNode = new lunr.TokenSet\n        frame.node.edges[\"*\"] = substitutionNode\n      }\n\n      if (frame.str.length == 1) {\n        substitutionNode.final = true\n      }\n\n      stack.push({\n        node: substitutionNode,\n        editsRemaining: frame.editsRemaining - 1,\n        str: frame.str.slice(1)\n      })\n    }\n\n    // transposition\n    // can only do a transposition if there are edits remaining\n    // and there are enough characters to transpose\n    if (frame.str.length > 1) {\n      var charA = frame.str.charAt(0),\n          charB = frame.str.charAt(1),\n          transposeNode\n\n      if (charB in frame.node.edges) {\n        transposeNode = frame.node.edges[charB]\n      } else {\n        transposeNode = new lunr.TokenSet\n        frame.node.edges[charB] = transposeNode\n      }\n\n      if (frame.str.length == 1) {\n        transposeNode.final = true\n      }\n\n      stack.push({\n        node: transposeNode,\n        editsRemaining: frame.editsRemaining - 1,\n        str: charA + frame.str.slice(2)\n      })\n    }\n  }\n\n  return root\n}\n\n/**\n * Creates a TokenSet from a string.\n *\n * The string may contain one or more wildcard characters (*)\n * that will allow wildcard matching when intersecting with\n * another TokenSet.\n *\n * @param {string} str - The string to create a TokenSet from.\n * @returns {lunr.TokenSet}\n */\nlunr.TokenSet.fromString = function (str) {\n  var node = new lunr.TokenSet,\n      root = node\n\n  /*\n   * Iterates through all characters within the passed string\n   * appending a node for each character.\n   *\n   * When a wildcard character is found then a self\n   * referencing edge is introduced to continually match\n   * any number of any characters.\n   */\n  for (var i = 0, len = str.length; i < len; i++) {\n    var char = str[i],\n        final = (i == len - 1)\n\n    if (char == \"*\") {\n      node.edges[char] = node\n      node.final = final\n\n    } else {\n      var next = new lunr.TokenSet\n      next.final = final\n\n      node.edges[char] = next\n      node = next\n    }\n  }\n\n  return root\n}\n\n/**\n * Converts this TokenSet into an array of strings\n * contained within the TokenSet.\n *\n * This is not intended to be used on a TokenSet that\n * contains wildcards, in these cases the results are\n * undefined and are likely to cause an infinite loop.\n *\n * @returns {string[]}\n */\nlunr.TokenSet.prototype.toArray = function () {\n  var words = []\n\n  var stack = [{\n    prefix: \"\",\n    node: this\n  }]\n\n  while (stack.length) {\n    var frame = stack.pop(),\n        edges = Object.keys(frame.node.edges),\n        len = edges.length\n\n    if (frame.node.final) {\n      /* In Safari, at this point the prefix is sometimes corrupted, see:\n       * https://github.com/olivernn/lunr.js/issues/279 Calling any\n       * String.prototype method forces Safari to \"cast\" this string to what\n       * it's supposed to be, fixing the bug. */\n      frame.prefix.charAt(0)\n      words.push(frame.prefix)\n    }\n\n    for (var i = 0; i < len; i++) {\n      var edge = edges[i]\n\n      stack.push({\n        prefix: frame.prefix.concat(edge),\n        node: frame.node.edges[edge]\n      })\n    }\n  }\n\n  return words\n}\n\n/**\n * Generates a string representation of a TokenSet.\n *\n * This is intended to allow TokenSets to be used as keys\n * in objects, largely to aid the construction and minimisation\n * of a TokenSet. As such it is not designed to be a human\n * friendly representation of the TokenSet.\n *\n * @returns {string}\n */\nlunr.TokenSet.prototype.toString = function () {\n  // NOTE: Using Object.keys here as this.edges is very likely\n  // to enter 'hash-mode' with many keys being added\n  //\n  // avoiding a for-in loop here as it leads to the function\n  // being de-optimised (at least in V8). From some simple\n  // benchmarks the performance is comparable, but allowing\n  // V8 to optimize may mean easy performance wins in the future.\n\n  if (this._str) {\n    return this._str\n  }\n\n  var str = this.final ? '1' : '0',\n      labels = Object.keys(this.edges).sort(),\n      len = labels.length\n\n  for (var i = 0; i < len; i++) {\n    var label = labels[i],\n        node = this.edges[label]\n\n    str = str + label + node.id\n  }\n\n  return str\n}\n\n/**\n * Returns a new TokenSet that is the intersection of\n * this TokenSet and the passed TokenSet.\n *\n * This intersection will take into account any wildcards\n * contained within the TokenSet.\n *\n * @param {lunr.TokenSet} b - An other TokenSet to intersect with.\n * @returns {lunr.TokenSet}\n */\nlunr.TokenSet.prototype.intersect = function (b) {\n  var output = new lunr.TokenSet,\n      frame = undefined\n\n  var stack = [{\n    qNode: b,\n    output: output,\n    node: this\n  }]\n\n  while (stack.length) {\n    frame = stack.pop()\n\n    // NOTE: As with the #toString method, we are using\n    // Object.keys and a for loop instead of a for-in loop\n    // as both of these objects enter 'hash' mode, causing\n    // the function to be de-optimised in V8\n    var qEdges = Object.keys(frame.qNode.edges),\n        qLen = qEdges.length,\n        nEdges = Object.keys(frame.node.edges),\n        nLen = nEdges.length\n\n    for (var q = 0; q < qLen; q++) {\n      var qEdge = qEdges[q]\n\n      for (var n = 0; n < nLen; n++) {\n        var nEdge = nEdges[n]\n\n        if (nEdge == qEdge || qEdge == '*') {\n          var node = frame.node.edges[nEdge],\n              qNode = frame.qNode.edges[qEdge],\n              final = node.final && qNode.final,\n              next = undefined\n\n          if (nEdge in frame.output.edges) {\n            // an edge already exists for this character\n            // no need to create a new node, just set the finality\n            // bit unless this node is already final\n            next = frame.output.edges[nEdge]\n            next.final = next.final || final\n\n          } else {\n            // no edge exists yet, must create one\n            // set the finality bit and insert it\n            // into the output\n            next = new lunr.TokenSet\n            next.final = final\n            frame.output.edges[nEdge] = next\n          }\n\n          stack.push({\n            qNode: qNode,\n            output: next,\n            node: node\n          })\n        }\n      }\n    }\n  }\n\n  return output\n}\nlunr.TokenSet.Builder = function () {\n  this.previousWord = \"\"\n  this.root = new lunr.TokenSet\n  this.uncheckedNodes = []\n  this.minimizedNodes = {}\n}\n\nlunr.TokenSet.Builder.prototype.insert = function (word) {\n  var node,\n      commonPrefix = 0\n\n  if (word < this.previousWord) {\n    throw new Error (\"Out of order word insertion\")\n  }\n\n  for (var i = 0; i < word.length && i < this.previousWord.length; i++) {\n    if (word[i] != this.previousWord[i]) break\n    commonPrefix++\n  }\n\n  this.minimize(commonPrefix)\n\n  if (this.uncheckedNodes.length == 0) {\n    node = this.root\n  } else {\n    node = this.uncheckedNodes[this.uncheckedNodes.length - 1].child\n  }\n\n  for (var i = commonPrefix; i < word.length; i++) {\n    var nextNode = new lunr.TokenSet,\n        char = word[i]\n\n    node.edges[char] = nextNode\n\n    this.uncheckedNodes.push({\n      parent: node,\n      char: char,\n      child: nextNode\n    })\n\n    node = nextNode\n  }\n\n  node.final = true\n  this.previousWord = word\n}\n\nlunr.TokenSet.Builder.prototype.finish = function () {\n  this.minimize(0)\n}\n\nlunr.TokenSet.Builder.prototype.minimize = function (downTo) {\n  for (var i = this.uncheckedNodes.length - 1; i >= downTo; i--) {\n    var node = this.uncheckedNodes[i],\n        childKey = node.child.toString()\n\n    if (childKey in this.minimizedNodes) {\n      node.parent.edges[node.char] = this.minimizedNodes[childKey]\n    } else {\n      // Cache the key for this node since\n      // we know it can't change anymore\n      node.child._str = childKey\n\n      this.minimizedNodes[childKey] = node.child\n    }\n\n    this.uncheckedNodes.pop()\n  }\n}\n/*!\n * lunr.Index\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * An index contains the built index of all documents and provides a query interface\n * to the index.\n *\n * Usually instances of lunr.Index will not be created using this constructor, instead\n * lunr.Builder should be used to construct new indexes, or lunr.Index.load should be\n * used to load previously built and serialized indexes.\n *\n * @constructor\n * @param {Object} attrs - The attributes of the built search index.\n * @param {Object} attrs.invertedIndex - An index of term/field to document reference.\n * @param {Object<string, lunr.Vector>} attrs.fieldVectors - Field vectors\n * @param {lunr.TokenSet} attrs.tokenSet - An set of all corpus tokens.\n * @param {string[]} attrs.fields - The names of indexed document fields.\n * @param {lunr.Pipeline} attrs.pipeline - The pipeline to use for search terms.\n */\nlunr.Index = function (attrs) {\n  this.invertedIndex = attrs.invertedIndex\n  this.fieldVectors = attrs.fieldVectors\n  this.tokenSet = attrs.tokenSet\n  this.fields = attrs.fields\n  this.pipeline = attrs.pipeline\n}\n\n/**\n * A result contains details of a document matching a search query.\n * @typedef {Object} lunr.Index~Result\n * @property {string} ref - The reference of the document this result represents.\n * @property {number} score - A number between 0 and 1 representing how similar this document is to the query.\n * @property {lunr.MatchData} matchData - Contains metadata about this match including which term(s) caused the match.\n */\n\n/**\n * Although lunr provides the ability to create queries using lunr.Query, it also provides a simple\n * query language which itself is parsed into an instance of lunr.Query.\n *\n * For programmatically building queries it is advised to directly use lunr.Query, the query language\n * is best used for human entered text rather than program generated text.\n *\n * At its simplest queries can just be a single term, e.g. `hello`, multiple terms are also supported\n * and will be combined with OR, e.g `hello world` will match documents that contain either 'hello'\n * or 'world', though those that contain both will rank higher in the results.\n *\n * Wildcards can be included in terms to match one or more unspecified characters, these wildcards can\n * be inserted anywhere within the term, and more than one wildcard can exist in a single term. Adding\n * wildcards will increase the number of documents that will be found but can also have a negative\n * impact on query performance, especially with wildcards at the beginning of a term.\n *\n * Terms can be restricted to specific fields, e.g. `title:hello`, only documents with the term\n * hello in the title field will match this query. Using a field not present in the index will lead\n * to an error being thrown.\n *\n * Modifiers can also be added to terms, lunr supports edit distance and boost modifiers on terms. A term\n * boost will make documents matching that term score higher, e.g. `foo^5`. Edit distance is also supported\n * to provide fuzzy matching, e.g. 'hello~2' will match documents with hello with an edit distance of 2.\n * Avoid large values for edit distance to improve query performance.\n *\n * Each term also supports a presence modifier. By default a term's presence in document is optional, however\n * this can be changed to either required or prohibited. For a term's presence to be required in a document the\n * term should be prefixed with a '+', e.g. `+foo bar` is a search for documents that must contain 'foo' and\n * optionally contain 'bar'. Conversely a leading '-' sets the terms presence to prohibited, i.e. it must not\n * appear in a document, e.g. `-foo bar` is a search for documents that do not contain 'foo' but may contain 'bar'.\n *\n * To escape special characters the backslash character '\\' can be used, this allows searches to include\n * characters that would normally be considered modifiers, e.g. `foo\\~2` will search for a term \"foo~2\" instead\n * of attempting to apply a boost of 2 to the search term \"foo\".\n *\n * @typedef {string} lunr.Index~QueryString\n * @example <caption>Simple single term query</caption>\n * hello\n * @example <caption>Multiple term query</caption>\n * hello world\n * @example <caption>term scoped to a field</caption>\n * title:hello\n * @example <caption>term with a boost of 10</caption>\n * hello^10\n * @example <caption>term with an edit distance of 2</caption>\n * hello~2\n * @example <caption>terms with presence modifiers</caption>\n * -foo +bar baz\n */\n\n/**\n * Performs a search against the index using lunr query syntax.\n *\n * Results will be returned sorted by their score, the most relevant results\n * will be returned first.  For details on how the score is calculated, please see\n * the {@link https://lunrjs.com/guides/searching.html#scoring|guide}.\n *\n * For more programmatic querying use lunr.Index#query.\n *\n * @param {lunr.Index~QueryString} queryString - A string containing a lunr query.\n * @throws {lunr.QueryParseError} If the passed query string cannot be parsed.\n * @returns {lunr.Index~Result[]}\n */\nlunr.Index.prototype.search = function (queryString) {\n  return this.query(function (query) {\n    var parser = new lunr.QueryParser(queryString, query)\n    parser.parse()\n  })\n}\n\n/**\n * A query builder callback provides a query object to be used to express\n * the query to perform on the index.\n *\n * @callback lunr.Index~queryBuilder\n * @param {lunr.Query} query - The query object to build up.\n * @this lunr.Query\n */\n\n/**\n * Performs a query against the index using the yielded lunr.Query object.\n *\n * If performing programmatic queries against the index, this method is preferred\n * over lunr.Index#search so as to avoid the additional query parsing overhead.\n *\n * A query object is yielded to the supplied function which should be used to\n * express the query to be run against the index.\n *\n * Note that although this function takes a callback parameter it is _not_ an\n * asynchronous operation, the callback is just yielded a query object to be\n * customized.\n *\n * @param {lunr.Index~queryBuilder} fn - A function that is used to build the query.\n * @returns {lunr.Index~Result[]}\n */\nlunr.Index.prototype.query = function (fn) {\n  // for each query clause\n  // * process terms\n  // * expand terms from token set\n  // * find matching documents and metadata\n  // * get document vectors\n  // * score documents\n\n  var query = new lunr.Query(this.fields),\n      matchingFields = Object.create(null),\n      queryVectors = Object.create(null),\n      termFieldCache = Object.create(null),\n      requiredMatches = Object.create(null),\n      prohibitedMatches = Object.create(null)\n\n  /*\n   * To support field level boosts a query vector is created per\n   * field. An empty vector is eagerly created to support negated\n   * queries.\n   */\n  for (var i = 0; i < this.fields.length; i++) {\n    queryVectors[this.fields[i]] = new lunr.Vector\n  }\n\n  fn.call(query, query)\n\n  for (var i = 0; i < query.clauses.length; i++) {\n    /*\n     * Unless the pipeline has been disabled for this term, which is\n     * the case for terms with wildcards, we need to pass the clause\n     * term through the search pipeline. A pipeline returns an array\n     * of processed terms. Pipeline functions may expand the passed\n     * term, which means we may end up performing multiple index lookups\n     * for a single query term.\n     */\n    var clause = query.clauses[i],\n        terms = null,\n        clauseMatches = lunr.Set.empty\n\n    if (clause.usePipeline) {\n      terms = this.pipeline.runString(clause.term, {\n        fields: clause.fields\n      })\n    } else {\n      terms = [clause.term]\n    }\n\n    for (var m = 0; m < terms.length; m++) {\n      var term = terms[m]\n\n      /*\n       * Each term returned from the pipeline needs to use the same query\n       * clause object, e.g. the same boost and or edit distance. The\n       * simplest way to do this is to re-use the clause object but mutate\n       * its term property.\n       */\n      clause.term = term\n\n      /*\n       * From the term in the clause we create a token set which will then\n       * be used to intersect the indexes token set to get a list of terms\n       * to lookup in the inverted index\n       */\n      var termTokenSet = lunr.TokenSet.fromClause(clause),\n          expandedTerms = this.tokenSet.intersect(termTokenSet).toArray()\n\n      /*\n       * If a term marked as required does not exist in the tokenSet it is\n       * impossible for the search to return any matches. We set all the field\n       * scoped required matches set to empty and stop examining any further\n       * clauses.\n       */\n      if (expandedTerms.length === 0 && clause.presence === lunr.Query.presence.REQUIRED) {\n        for (var k = 0; k < clause.fields.length; k++) {\n          var field = clause.fields[k]\n          requiredMatches[field] = lunr.Set.empty\n        }\n\n        break\n      }\n\n      for (var j = 0; j < expandedTerms.length; j++) {\n        /*\n         * For each term get the posting and termIndex, this is required for\n         * building the query vector.\n         */\n        var expandedTerm = expandedTerms[j],\n            posting = this.invertedIndex[expandedTerm],\n            termIndex = posting._index\n\n        for (var k = 0; k < clause.fields.length; k++) {\n          /*\n           * For each field that this query term is scoped by (by default\n           * all fields are in scope) we need to get all the document refs\n           * that have this term in that field.\n           *\n           * The posting is the entry in the invertedIndex for the matching\n           * term from above.\n           */\n          var field = clause.fields[k],\n              fieldPosting = posting[field],\n              matchingDocumentRefs = Object.keys(fieldPosting),\n              termField = expandedTerm + \"/\" + field,\n              matchingDocumentsSet = new lunr.Set(matchingDocumentRefs)\n\n          /*\n           * if the presence of this term is required ensure that the matching\n           * documents are added to the set of required matches for this clause.\n           *\n           */\n          if (clause.presence == lunr.Query.presence.REQUIRED) {\n            clauseMatches = clauseMatches.union(matchingDocumentsSet)\n\n            if (requiredMatches[field] === undefined) {\n              requiredMatches[field] = lunr.Set.complete\n            }\n          }\n\n          /*\n           * if the presence of this term is prohibited ensure that the matching\n           * documents are added to the set of prohibited matches for this field,\n           * creating that set if it does not yet exist.\n           */\n          if (clause.presence == lunr.Query.presence.PROHIBITED) {\n            if (prohibitedMatches[field] === undefined) {\n              prohibitedMatches[field] = lunr.Set.empty\n            }\n\n            prohibitedMatches[field] = prohibitedMatches[field].union(matchingDocumentsSet)\n\n            /*\n             * Prohibited matches should not be part of the query vector used for\n             * similarity scoring and no metadata should be extracted so we continue\n             * to the next field\n             */\n            continue\n          }\n\n          /*\n           * The query field vector is populated using the termIndex found for\n           * the term and a unit value with the appropriate boost applied.\n           * Using upsert because there could already be an entry in the vector\n           * for the term we are working with. In that case we just add the scores\n           * together.\n           */\n          queryVectors[field].upsert(termIndex, clause.boost, function (a, b) { return a + b })\n\n          /**\n           * If we've already seen this term, field combo then we've already collected\n           * the matching documents and metadata, no need to go through all that again\n           */\n          if (termFieldCache[termField]) {\n            continue\n          }\n\n          for (var l = 0; l < matchingDocumentRefs.length; l++) {\n            /*\n             * All metadata for this term/field/document triple\n             * are then extracted and collected into an instance\n             * of lunr.MatchData ready to be returned in the query\n             * results\n             */\n            var matchingDocumentRef = matchingDocumentRefs[l],\n                matchingFieldRef = new lunr.FieldRef (matchingDocumentRef, field),\n                metadata = fieldPosting[matchingDocumentRef],\n                fieldMatch\n\n            if ((fieldMatch = matchingFields[matchingFieldRef]) === undefined) {\n              matchingFields[matchingFieldRef] = new lunr.MatchData (expandedTerm, field, metadata)\n            } else {\n              fieldMatch.add(expandedTerm, field, metadata)\n            }\n\n          }\n\n          termFieldCache[termField] = true\n        }\n      }\n    }\n\n    /**\n     * If the presence was required we need to update the requiredMatches field sets.\n     * We do this after all fields for the term have collected their matches because\n     * the clause terms presence is required in _any_ of the fields not _all_ of the\n     * fields.\n     */\n    if (clause.presence === lunr.Query.presence.REQUIRED) {\n      for (var k = 0; k < clause.fields.length; k++) {\n        var field = clause.fields[k]\n        requiredMatches[field] = requiredMatches[field].intersect(clauseMatches)\n      }\n    }\n  }\n\n  /**\n   * Need to combine the field scoped required and prohibited\n   * matching documents into a global set of required and prohibited\n   * matches\n   */\n  var allRequiredMatches = lunr.Set.complete,\n      allProhibitedMatches = lunr.Set.empty\n\n  for (var i = 0; i < this.fields.length; i++) {\n    var field = this.fields[i]\n\n    if (requiredMatches[field]) {\n      allRequiredMatches = allRequiredMatches.intersect(requiredMatches[field])\n    }\n\n    if (prohibitedMatches[field]) {\n      allProhibitedMatches = allProhibitedMatches.union(prohibitedMatches[field])\n    }\n  }\n\n  var matchingFieldRefs = Object.keys(matchingFields),\n      results = [],\n      matches = Object.create(null)\n\n  /*\n   * If the query is negated (contains only prohibited terms)\n   * we need to get _all_ fieldRefs currently existing in the\n   * index. This is only done when we know that the query is\n   * entirely prohibited terms to avoid any cost of getting all\n   * fieldRefs unnecessarily.\n   *\n   * Additionally, blank MatchData must be created to correctly\n   * populate the results.\n   */\n  if (query.isNegated()) {\n    matchingFieldRefs = Object.keys(this.fieldVectors)\n\n    for (var i = 0; i < matchingFieldRefs.length; i++) {\n      var matchingFieldRef = matchingFieldRefs[i]\n      var fieldRef = lunr.FieldRef.fromString(matchingFieldRef)\n      matchingFields[matchingFieldRef] = new lunr.MatchData\n    }\n  }\n\n  for (var i = 0; i < matchingFieldRefs.length; i++) {\n    /*\n     * Currently we have document fields that match the query, but we\n     * need to return documents. The matchData and scores are combined\n     * from multiple fields belonging to the same document.\n     *\n     * Scores are calculated by field, using the query vectors created\n     * above, and combined into a final document score using addition.\n     */\n    var fieldRef = lunr.FieldRef.fromString(matchingFieldRefs[i]),\n        docRef = fieldRef.docRef\n\n    if (!allRequiredMatches.contains(docRef)) {\n      continue\n    }\n\n    if (allProhibitedMatches.contains(docRef)) {\n      continue\n    }\n\n    var fieldVector = this.fieldVectors[fieldRef],\n        score = queryVectors[fieldRef.fieldName].similarity(fieldVector),\n        docMatch\n\n    if ((docMatch = matches[docRef]) !== undefined) {\n      docMatch.score += score\n      docMatch.matchData.combine(matchingFields[fieldRef])\n    } else {\n      var match = {\n        ref: docRef,\n        score: score,\n        matchData: matchingFields[fieldRef]\n      }\n      matches[docRef] = match\n      results.push(match)\n    }\n  }\n\n  /*\n   * Sort the results objects by score, highest first.\n   */\n  return results.sort(function (a, b) {\n    return b.score - a.score\n  })\n}\n\n/**\n * Prepares the index for JSON serialization.\n *\n * The schema for this JSON blob will be described in a\n * separate JSON schema file.\n *\n * @returns {Object}\n */\nlunr.Index.prototype.toJSON = function () {\n  var invertedIndex = Object.keys(this.invertedIndex)\n    .sort()\n    .map(function (term) {\n      return [term, this.invertedIndex[term]]\n    }, this)\n\n  var fieldVectors = Object.keys(this.fieldVectors)\n    .map(function (ref) {\n      return [ref, this.fieldVectors[ref].toJSON()]\n    }, this)\n\n  return {\n    version: lunr.version,\n    fields: this.fields,\n    fieldVectors: fieldVectors,\n    invertedIndex: invertedIndex,\n    pipeline: this.pipeline.toJSON()\n  }\n}\n\n/**\n * Loads a previously serialized lunr.Index\n *\n * @param {Object} serializedIndex - A previously serialized lunr.Index\n * @returns {lunr.Index}\n */\nlunr.Index.load = function (serializedIndex) {\n  var attrs = {},\n      fieldVectors = {},\n      serializedVectors = serializedIndex.fieldVectors,\n      invertedIndex = Object.create(null),\n      serializedInvertedIndex = serializedIndex.invertedIndex,\n      tokenSetBuilder = new lunr.TokenSet.Builder,\n      pipeline = lunr.Pipeline.load(serializedIndex.pipeline)\n\n  if (serializedIndex.version != lunr.version) {\n    lunr.utils.warn(\"Version mismatch when loading serialised index. Current version of lunr '\" + lunr.version + \"' does not match serialized index '\" + serializedIndex.version + \"'\")\n  }\n\n  for (var i = 0; i < serializedVectors.length; i++) {\n    var tuple = serializedVectors[i],\n        ref = tuple[0],\n        elements = tuple[1]\n\n    fieldVectors[ref] = new lunr.Vector(elements)\n  }\n\n  for (var i = 0; i < serializedInvertedIndex.length; i++) {\n    var tuple = serializedInvertedIndex[i],\n        term = tuple[0],\n        posting = tuple[1]\n\n    tokenSetBuilder.insert(term)\n    invertedIndex[term] = posting\n  }\n\n  tokenSetBuilder.finish()\n\n  attrs.fields = serializedIndex.fields\n\n  attrs.fieldVectors = fieldVectors\n  attrs.invertedIndex = invertedIndex\n  attrs.tokenSet = tokenSetBuilder.root\n  attrs.pipeline = pipeline\n\n  return new lunr.Index(attrs)\n}\n/*!\n * lunr.Builder\n * Copyright (C) 2020 Oliver Nightingale\n */\n\n/**\n * lunr.Builder performs indexing on a set of documents and\n * returns instances of lunr.Index ready for querying.\n *\n * All configuration of the index is done via the builder, the\n * fields to index, the document reference, the text processing\n * pipeline and document scoring parameters are all set on the\n * builder before indexing.\n *\n * @constructor\n * @property {string} _ref - Internal reference to the document reference field.\n * @property {string[]} _fields - Internal reference to the document fields to index.\n * @property {object} invertedIndex - The inverted index maps terms to document fields.\n * @property {object} documentTermFrequencies - Keeps track of document term frequencies.\n * @property {object} documentLengths - Keeps track of the length of documents added to the index.\n * @property {lunr.tokenizer} tokenizer - Function for splitting strings into tokens for indexing.\n * @property {lunr.Pipeline} pipeline - The pipeline performs text processing on tokens before indexing.\n * @property {lunr.Pipeline} searchPipeline - A pipeline for processing search terms before querying the index.\n * @property {number} documentCount - Keeps track of the total number of documents indexed.\n * @property {number} _b - A parameter to control field length normalization, setting this to 0 disabled normalization, 1 fully normalizes field lengths, the default value is 0.75.\n * @property {number} _k1 - A parameter to control how quickly an increase in term frequency results in term frequency saturation, the default value is 1.2.\n * @property {number} termIndex - A counter incremented for each unique term, used to identify a terms position in the vector space.\n * @property {array} metadataWhitelist - A list of metadata keys that have been whitelisted for entry in the index.\n */\nlunr.Builder = function () {\n  this._ref = \"id\"\n  this._fields = Object.create(null)\n  this._documents = Object.create(null)\n  this.invertedIndex = Object.create(null)\n  this.fieldTermFrequencies = {}\n  this.fieldLengths = {}\n  this.tokenizer = lunr.tokenizer\n  this.pipeline = new lunr.Pipeline\n  this.searchPipeline = new lunr.Pipeline\n  this.documentCount = 0\n  this._b = 0.75\n  this._k1 = 1.2\n  this.termIndex = 0\n  this.metadataWhitelist = []\n}\n\n/**\n * Sets the document field used as the document reference. Every document must have this field.\n * The type of this field in the document should be a string, if it is not a string it will be\n * coerced into a string by calling toString.\n *\n * The default ref is 'id'.\n *\n * The ref should _not_ be changed during indexing, it should be set before any documents are\n * added to the index. Changing it during indexing can lead to inconsistent results.\n *\n * @param {string} ref - The name of the reference field in the document.\n */\nlunr.Builder.prototype.ref = function (ref) {\n  this._ref = ref\n}\n\n/**\n * A function that is used to extract a field from a document.\n *\n * Lunr expects a field to be at the top level of a document, if however the field\n * is deeply nested within a document an extractor function can be used to extract\n * the right field for indexing.\n *\n * @callback fieldExtractor\n * @param {object} doc - The document being added to the index.\n * @returns {?(string|object|object[])} obj - The object that will be indexed for this field.\n * @example <caption>Extracting a nested field</caption>\n * function (doc) { return doc.nested.field }\n */\n\n/**\n * Adds a field to the list of document fields that will be indexed. Every document being\n * indexed should have this field. Null values for this field in indexed documents will\n * not cause errors but will limit the chance of that document being retrieved by searches.\n *\n * All fields should be added before adding documents to the index. Adding fields after\n * a document has been indexed will have no effect on already indexed documents.\n *\n * Fields can be boosted at build time. This allows terms within that field to have more\n * importance when ranking search results. Use a field boost to specify that matches within\n * one field are more important than other fields.\n *\n * @param {string} fieldName - The name of a field to index in all documents.\n * @param {object} attributes - Optional attributes associated with this field.\n * @param {number} [attributes.boost=1] - Boost applied to all terms within this field.\n * @param {fieldExtractor} [attributes.extractor] - Function to extract a field from a document.\n * @throws {RangeError} fieldName cannot contain unsupported characters '/'\n */\nlunr.Builder.prototype.field = function (fieldName, attributes) {\n  if (/\\//.test(fieldName)) {\n    throw new RangeError (\"Field '\" + fieldName + \"' contains illegal character '/'\")\n  }\n\n  this._fields[fieldName] = attributes || {}\n}\n\n/**\n * A parameter to tune the amount of field length normalisation that is applied when\n * calculating relevance scores. A value of 0 will completely disable any normalisation\n * and a value of 1 will fully normalise field lengths. The default is 0.75. Values of b\n * will be clamped to the range 0 - 1.\n *\n * @param {number} number - The value to set for this tuning parameter.\n */\nlunr.Builder.prototype.b = function (number) {\n  if (number < 0) {\n    this._b = 0\n  } else if (number > 1) {\n    this._b = 1\n  } else {\n    this._b = number\n  }\n}\n\n/**\n * A parameter that controls the speed at which a rise in term frequency results in term\n * frequency saturation. The default value is 1.2. Setting this to a higher value will give\n * slower saturation levels, a lower value will result in quicker saturation.\n *\n * @param {number} number - The value to set for this tuning parameter.\n */\nlunr.Builder.prototype.k1 = function (number) {\n  this._k1 = number\n}\n\n/**\n * Adds a document to the index.\n *\n * Before adding fields to the index the index should have been fully setup, with the document\n * ref and all fields to index already having been specified.\n *\n * The document must have a field name as specified by the ref (by default this is 'id') and\n * it should have all fields defined for indexing, though null or undefined values will not\n * cause errors.\n *\n * Entire documents can be boosted at build time. Applying a boost to a document indicates that\n * this document should rank higher in search results than other documents.\n *\n * @param {object} doc - The document to add to the index.\n * @param {object} attributes - Optional attributes associated with this document.\n * @param {number} [attributes.boost=1] - Boost applied to all terms within this document.\n */\nlunr.Builder.prototype.add = function (doc, attributes) {\n  var docRef = doc[this._ref],\n      fields = Object.keys(this._fields)\n\n  this._documents[docRef] = attributes || {}\n  this.documentCount += 1\n\n  for (var i = 0; i < fields.length; i++) {\n    var fieldName = fields[i],\n        extractor = this._fields[fieldName].extractor,\n        field = extractor ? extractor(doc) : doc[fieldName],\n        tokens = this.tokenizer(field, {\n          fields: [fieldName]\n        }),\n        terms = this.pipeline.run(tokens),\n        fieldRef = new lunr.FieldRef (docRef, fieldName),\n        fieldTerms = Object.create(null)\n\n    this.fieldTermFrequencies[fieldRef] = fieldTerms\n    this.fieldLengths[fieldRef] = 0\n\n    // store the length of this field for this document\n    this.fieldLengths[fieldRef] += terms.length\n\n    // calculate term frequencies for this field\n    for (var j = 0; j < terms.length; j++) {\n      var term = terms[j]\n\n      if (fieldTerms[term] == undefined) {\n        fieldTerms[term] = 0\n      }\n\n      fieldTerms[term] += 1\n\n      // add to inverted index\n      // create an initial posting if one doesn't exist\n      if (this.invertedIndex[term] == undefined) {\n        var posting = Object.create(null)\n        posting[\"_index\"] = this.termIndex\n        this.termIndex += 1\n\n        for (var k = 0; k < fields.length; k++) {\n          posting[fields[k]] = Object.create(null)\n        }\n\n        this.invertedIndex[term] = posting\n      }\n\n      // add an entry for this term/fieldName/docRef to the invertedIndex\n      if (this.invertedIndex[term][fieldName][docRef] == undefined) {\n        this.invertedIndex[term][fieldName][docRef] = Object.create(null)\n      }\n\n      // store all whitelisted metadata about this token in the\n      // inverted index\n      for (var l = 0; l < this.metadataWhitelist.length; l++) {\n        var metadataKey = this.metadataWhitelist[l],\n            metadata = term.metadata[metadataKey]\n\n        if (this.invertedIndex[term][fieldName][docRef][metadataKey] == undefined) {\n          this.invertedIndex[term][fieldName][docRef][metadataKey] = []\n        }\n\n        this.invertedIndex[term][fieldName][docRef][metadataKey].push(metadata)\n      }\n    }\n\n  }\n}\n\n/**\n * Calculates the average document length for this index\n *\n * @private\n */\nlunr.Builder.prototype.calculateAverageFieldLengths = function () {\n\n  var fieldRefs = Object.keys(this.fieldLengths),\n      numberOfFields = fieldRefs.length,\n      accumulator = {},\n      documentsWithField = {}\n\n  for (var i = 0; i < numberOfFields; i++) {\n    var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\n        field = fieldRef.fieldName\n\n    documentsWithField[field] || (documentsWithField[field] = 0)\n    documentsWithField[field] += 1\n\n    accumulator[field] || (accumulator[field] = 0)\n    accumulator[field] += this.fieldLengths[fieldRef]\n  }\n\n  var fields = Object.keys(this._fields)\n\n  for (var i = 0; i < fields.length; i++) {\n    var fieldName = fields[i]\n    accumulator[fieldName] = accumulator[fieldName] / documentsWithField[fieldName]\n  }\n\n  this.averageFieldLength = accumulator\n}\n\n/**\n * Builds a vector space model of every document using lunr.Vector\n *\n * @private\n */\nlunr.Builder.prototype.createFieldVectors = function () {\n  var fieldVectors = {},\n      fieldRefs = Object.keys(this.fieldTermFrequencies),\n      fieldRefsLength = fieldRefs.length,\n      termIdfCache = Object.create(null)\n\n  for (var i = 0; i < fieldRefsLength; i++) {\n    var fieldRef = lunr.FieldRef.fromString(fieldRefs[i]),\n        fieldName = fieldRef.fieldName,\n        fieldLength = this.fieldLengths[fieldRef],\n        fieldVector = new lunr.Vector,\n        termFrequencies = this.fieldTermFrequencies[fieldRef],\n        terms = Object.keys(termFrequencies),\n        termsLength = terms.length\n\n\n    var fieldBoost = this._fields[fieldName].boost || 1,\n        docBoost = this._documents[fieldRef.docRef].boost || 1\n\n    for (var j = 0; j < termsLength; j++) {\n      var term = terms[j],\n          tf = termFrequencies[term],\n          termIndex = this.invertedIndex[term]._index,\n          idf, score, scoreWithPrecision\n\n      if (termIdfCache[term] === undefined) {\n        idf = lunr.idf(this.invertedIndex[term], this.documentCount)\n        termIdfCache[term] = idf\n      } else {\n        idf = termIdfCache[term]\n      }\n\n      score = idf * ((this._k1 + 1) * tf) / (this._k1 * (1 - this._b + this._b * (fieldLength / this.averageFieldLength[fieldName])) + tf)\n      score *= fieldBoost\n      score *= docBoost\n      scoreWithPrecision = Math.round(score * 1000) / 1000\n      // Converts 1.23456789 to 1.234.\n      // Reducing the precision so that the vectors take up less\n      // space when serialised. Doing it now so that they behave\n      // the same before and after serialisation. Also, this is\n      // the fastest approach to reducing a number's precision in\n      // JavaScript.\n\n      fieldVector.insert(termIndex, scoreWithPrecision)\n    }\n\n    fieldVectors[fieldRef] = fieldVector\n  }\n\n  this.fieldVectors = fieldVectors\n}\n\n/**\n * Creates a token set of all tokens in the index using lunr.TokenSet\n *\n * @private\n */\nlunr.Builder.prototype.createTokenSet = function () {\n  this.tokenSet = lunr.TokenSet.fromArray(\n    Object.keys(this.invertedIndex).sort()\n  )\n}\n\n/**\n * Builds the index, creating an instance of lunr.Index.\n *\n * This completes the indexing process and should only be called\n * once all documents have been added to the index.\n *\n * @returns {lunr.Index}\n */\nlunr.Builder.prototype.build = function () {\n  this.calculateAverageFieldLengths()\n  this.createFieldVectors()\n  this.createTokenSet()\n\n  return new lunr.Index({\n    invertedIndex: this.invertedIndex,\n    fieldVectors: this.fieldVectors,\n    tokenSet: this.tokenSet,\n    fields: Object.keys(this._fields),\n    pipeline: this.searchPipeline\n  })\n}\n\n/**\n * Applies a plugin to the index builder.\n *\n * A plugin is a function that is called with the index builder as its context.\n * Plugins can be used to customise or extend the behaviour of the index\n * in some way. A plugin is just a function, that encapsulated the custom\n * behaviour that should be applied when building the index.\n *\n * The plugin function will be called with the index builder as its argument, additional\n * arguments can also be passed when calling use. The function will be called\n * with the index builder as its context.\n *\n * @param {Function} plugin The plugin to apply.\n */\nlunr.Builder.prototype.use = function (fn) {\n  var args = Array.prototype.slice.call(arguments, 1)\n  args.unshift(this)\n  fn.apply(this, args)\n}\n/**\n * Contains and collects metadata about a matching document.\n * A single instance of lunr.MatchData is returned as part of every\n * lunr.Index~Result.\n *\n * @constructor\n * @param {string} term - The term this match data is associated with\n * @param {string} field - The field in which the term was found\n * @param {object} metadata - The metadata recorded about this term in this field\n * @property {object} metadata - A cloned collection of metadata associated with this document.\n * @see {@link lunr.Index~Result}\n */\nlunr.MatchData = function (term, field, metadata) {\n  var clonedMetadata = Object.create(null),\n      metadataKeys = Object.keys(metadata || {})\n\n  // Cloning the metadata to prevent the original\n  // being mutated during match data combination.\n  // Metadata is kept in an array within the inverted\n  // index so cloning the data can be done with\n  // Array#slice\n  for (var i = 0; i < metadataKeys.length; i++) {\n    var key = metadataKeys[i]\n    clonedMetadata[key] = metadata[key].slice()\n  }\n\n  this.metadata = Object.create(null)\n\n  if (term !== undefined) {\n    this.metadata[term] = Object.create(null)\n    this.metadata[term][field] = clonedMetadata\n  }\n}\n\n/**\n * An instance of lunr.MatchData will be created for every term that matches a\n * document. However only one instance is required in a lunr.Index~Result. This\n * method combines metadata from another instance of lunr.MatchData with this\n * objects metadata.\n *\n * @param {lunr.MatchData} otherMatchData - Another instance of match data to merge with this one.\n * @see {@link lunr.Index~Result}\n */\nlunr.MatchData.prototype.combine = function (otherMatchData) {\n  var terms = Object.keys(otherMatchData.metadata)\n\n  for (var i = 0; i < terms.length; i++) {\n    var term = terms[i],\n        fields = Object.keys(otherMatchData.metadata[term])\n\n    if (this.metadata[term] == undefined) {\n      this.metadata[term] = Object.create(null)\n    }\n\n    for (var j = 0; j < fields.length; j++) {\n      var field = fields[j],\n          keys = Object.keys(otherMatchData.metadata[term][field])\n\n      if (this.metadata[term][field] == undefined) {\n        this.metadata[term][field] = Object.create(null)\n      }\n\n      for (var k = 0; k < keys.length; k++) {\n        var key = keys[k]\n\n        if (this.metadata[term][field][key] == undefined) {\n          this.metadata[term][field][key] = otherMatchData.metadata[term][field][key]\n        } else {\n          this.metadata[term][field][key] = this.metadata[term][field][key].concat(otherMatchData.metadata[term][field][key])\n        }\n\n      }\n    }\n  }\n}\n\n/**\n * Add metadata for a term/field pair to this instance of match data.\n *\n * @param {string} term - The term this match data is associated with\n * @param {string} field - The field in which the term was found\n * @param {object} metadata - The metadata recorded about this term in this field\n */\nlunr.MatchData.prototype.add = function (term, field, metadata) {\n  if (!(term in this.metadata)) {\n    this.metadata[term] = Object.create(null)\n    this.metadata[term][field] = metadata\n    return\n  }\n\n  if (!(field in this.metadata[term])) {\n    this.metadata[term][field] = metadata\n    return\n  }\n\n  var metadataKeys = Object.keys(metadata)\n\n  for (var i = 0; i < metadataKeys.length; i++) {\n    var key = metadataKeys[i]\n\n    if (key in this.metadata[term][field]) {\n      this.metadata[term][field][key] = this.metadata[term][field][key].concat(metadata[key])\n    } else {\n      this.metadata[term][field][key] = metadata[key]\n    }\n  }\n}\n/**\n * A lunr.Query provides a programmatic way of defining queries to be performed\n * against a {@link lunr.Index}.\n *\n * Prefer constructing a lunr.Query using the {@link lunr.Index#query} method\n * so the query object is pre-initialized with the right index fields.\n *\n * @constructor\n * @property {lunr.Query~Clause[]} clauses - An array of query clauses.\n * @property {string[]} allFields - An array of all available fields in a lunr.Index.\n */\nlunr.Query = function (allFields) {\n  this.clauses = []\n  this.allFields = allFields\n}\n\n/**\n * Constants for indicating what kind of automatic wildcard insertion will be used when constructing a query clause.\n *\n * This allows wildcards to be added to the beginning and end of a term without having to manually do any string\n * concatenation.\n *\n * The wildcard constants can be bitwise combined to select both leading and trailing wildcards.\n *\n * @constant\n * @default\n * @property {number} wildcard.NONE - The term will have no wildcards inserted, this is the default behaviour\n * @property {number} wildcard.LEADING - Prepend the term with a wildcard, unless a leading wildcard already exists\n * @property {number} wildcard.TRAILING - Append a wildcard to the term, unless a trailing wildcard already exists\n * @see lunr.Query~Clause\n * @see lunr.Query#clause\n * @see lunr.Query#term\n * @example <caption>query term with trailing wildcard</caption>\n * query.term('foo', { wildcard: lunr.Query.wildcard.TRAILING })\n * @example <caption>query term with leading and trailing wildcard</caption>\n * query.term('foo', {\n *   wildcard: lunr.Query.wildcard.LEADING | lunr.Query.wildcard.TRAILING\n * })\n */\n\nlunr.Query.wildcard = new String (\"*\")\nlunr.Query.wildcard.NONE = 0\nlunr.Query.wildcard.LEADING = 1\nlunr.Query.wildcard.TRAILING = 2\n\n/**\n * Constants for indicating what kind of presence a term must have in matching documents.\n *\n * @constant\n * @enum {number}\n * @see lunr.Query~Clause\n * @see lunr.Query#clause\n * @see lunr.Query#term\n * @example <caption>query term with required presence</caption>\n * query.term('foo', { presence: lunr.Query.presence.REQUIRED })\n */\nlunr.Query.presence = {\n  /**\n   * Term's presence in a document is optional, this is the default value.\n   */\n  OPTIONAL: 1,\n\n  /**\n   * Term's presence in a document is required, documents that do not contain\n   * this term will not be returned.\n   */\n  REQUIRED: 2,\n\n  /**\n   * Term's presence in a document is prohibited, documents that do contain\n   * this term will not be returned.\n   */\n  PROHIBITED: 3\n}\n\n/**\n * A single clause in a {@link lunr.Query} contains a term and details on how to\n * match that term against a {@link lunr.Index}.\n *\n * @typedef {Object} lunr.Query~Clause\n * @property {string[]} fields - The fields in an index this clause should be matched against.\n * @property {number} [boost=1] - Any boost that should be applied when matching this clause.\n * @property {number} [editDistance] - Whether the term should have fuzzy matching applied, and how fuzzy the match should be.\n * @property {boolean} [usePipeline] - Whether the term should be passed through the search pipeline.\n * @property {number} [wildcard=lunr.Query.wildcard.NONE] - Whether the term should have wildcards appended or prepended.\n * @property {number} [presence=lunr.Query.presence.OPTIONAL] - The terms presence in any matching documents.\n */\n\n/**\n * Adds a {@link lunr.Query~Clause} to this query.\n *\n * Unless the clause contains the fields to be matched all fields will be matched. In addition\n * a default boost of 1 is applied to the clause.\n *\n * @param {lunr.Query~Clause} clause - The clause to add to this query.\n * @see lunr.Query~Clause\n * @returns {lunr.Query}\n */\nlunr.Query.prototype.clause = function (clause) {\n  if (!('fields' in clause)) {\n    clause.fields = this.allFields\n  }\n\n  if (!('boost' in clause)) {\n    clause.boost = 1\n  }\n\n  if (!('usePipeline' in clause)) {\n    clause.usePipeline = true\n  }\n\n  if (!('wildcard' in clause)) {\n    clause.wildcard = lunr.Query.wildcard.NONE\n  }\n\n  if ((clause.wildcard & lunr.Query.wildcard.LEADING) && (clause.term.charAt(0) != lunr.Query.wildcard)) {\n    clause.term = \"*\" + clause.term\n  }\n\n  if ((clause.wildcard & lunr.Query.wildcard.TRAILING) && (clause.term.slice(-1) != lunr.Query.wildcard)) {\n    clause.term = \"\" + clause.term + \"*\"\n  }\n\n  if (!('presence' in clause)) {\n    clause.presence = lunr.Query.presence.OPTIONAL\n  }\n\n  this.clauses.push(clause)\n\n  return this\n}\n\n/**\n * A negated query is one in which every clause has a presence of\n * prohibited. These queries require some special processing to return\n * the expected results.\n *\n * @returns boolean\n */\nlunr.Query.prototype.isNegated = function () {\n  for (var i = 0; i < this.clauses.length; i++) {\n    if (this.clauses[i].presence != lunr.Query.presence.PROHIBITED) {\n      return false\n    }\n  }\n\n  return true\n}\n\n/**\n * Adds a term to the current query, under the covers this will create a {@link lunr.Query~Clause}\n * to the list of clauses that make up this query.\n *\n * The term is used as is, i.e. no tokenization will be performed by this method. Instead conversion\n * to a token or token-like string should be done before calling this method.\n *\n * The term will be converted to a string by calling `toString`. Multiple terms can be passed as an\n * array, each term in the array will share the same options.\n *\n * @param {object|object[]} term - The term(s) to add to the query.\n * @param {object} [options] - Any additional properties to add to the query clause.\n * @returns {lunr.Query}\n * @see lunr.Query#clause\n * @see lunr.Query~Clause\n * @example <caption>adding a single term to a query</caption>\n * query.term(\"foo\")\n * @example <caption>adding a single term to a query and specifying search fields, term boost and automatic trailing wildcard</caption>\n * query.term(\"foo\", {\n *   fields: [\"title\"],\n *   boost: 10,\n *   wildcard: lunr.Query.wildcard.TRAILING\n * })\n * @example <caption>using lunr.tokenizer to convert a string to tokens before using them as terms</caption>\n * query.term(lunr.tokenizer(\"foo bar\"))\n */\nlunr.Query.prototype.term = function (term, options) {\n  if (Array.isArray(term)) {\n    term.forEach(function (t) { this.term(t, lunr.utils.clone(options)) }, this)\n    return this\n  }\n\n  var clause = options || {}\n  clause.term = term.toString()\n\n  this.clause(clause)\n\n  return this\n}\nlunr.QueryParseError = function (message, start, end) {\n  this.name = \"QueryParseError\"\n  this.message = message\n  this.start = start\n  this.end = end\n}\n\nlunr.QueryParseError.prototype = new Error\nlunr.QueryLexer = function (str) {\n  this.lexemes = []\n  this.str = str\n  this.length = str.length\n  this.pos = 0\n  this.start = 0\n  this.escapeCharPositions = []\n}\n\nlunr.QueryLexer.prototype.run = function () {\n  var state = lunr.QueryLexer.lexText\n\n  while (state) {\n    state = state(this)\n  }\n}\n\nlunr.QueryLexer.prototype.sliceString = function () {\n  var subSlices = [],\n      sliceStart = this.start,\n      sliceEnd = this.pos\n\n  for (var i = 0; i < this.escapeCharPositions.length; i++) {\n    sliceEnd = this.escapeCharPositions[i]\n    subSlices.push(this.str.slice(sliceStart, sliceEnd))\n    sliceStart = sliceEnd + 1\n  }\n\n  subSlices.push(this.str.slice(sliceStart, this.pos))\n  this.escapeCharPositions.length = 0\n\n  return subSlices.join('')\n}\n\nlunr.QueryLexer.prototype.emit = function (type) {\n  this.lexemes.push({\n    type: type,\n    str: this.sliceString(),\n    start: this.start,\n    end: this.pos\n  })\n\n  this.start = this.pos\n}\n\nlunr.QueryLexer.prototype.escapeCharacter = function () {\n  this.escapeCharPositions.push(this.pos - 1)\n  this.pos += 1\n}\n\nlunr.QueryLexer.prototype.next = function () {\n  if (this.pos >= this.length) {\n    return lunr.QueryLexer.EOS\n  }\n\n  var char = this.str.charAt(this.pos)\n  this.pos += 1\n  return char\n}\n\nlunr.QueryLexer.prototype.width = function () {\n  return this.pos - this.start\n}\n\nlunr.QueryLexer.prototype.ignore = function () {\n  if (this.start == this.pos) {\n    this.pos += 1\n  }\n\n  this.start = this.pos\n}\n\nlunr.QueryLexer.prototype.backup = function () {\n  this.pos -= 1\n}\n\nlunr.QueryLexer.prototype.acceptDigitRun = function () {\n  var char, charCode\n\n  do {\n    char = this.next()\n    charCode = char.charCodeAt(0)\n  } while (charCode > 47 && charCode < 58)\n\n  if (char != lunr.QueryLexer.EOS) {\n    this.backup()\n  }\n}\n\nlunr.QueryLexer.prototype.more = function () {\n  return this.pos < this.length\n}\n\nlunr.QueryLexer.EOS = 'EOS'\nlunr.QueryLexer.FIELD = 'FIELD'\nlunr.QueryLexer.TERM = 'TERM'\nlunr.QueryLexer.EDIT_DISTANCE = 'EDIT_DISTANCE'\nlunr.QueryLexer.BOOST = 'BOOST'\nlunr.QueryLexer.PRESENCE = 'PRESENCE'\n\nlunr.QueryLexer.lexField = function (lexer) {\n  lexer.backup()\n  lexer.emit(lunr.QueryLexer.FIELD)\n  lexer.ignore()\n  return lunr.QueryLexer.lexText\n}\n\nlunr.QueryLexer.lexTerm = function (lexer) {\n  if (lexer.width() > 1) {\n    lexer.backup()\n    lexer.emit(lunr.QueryLexer.TERM)\n  }\n\n  lexer.ignore()\n\n  if (lexer.more()) {\n    return lunr.QueryLexer.lexText\n  }\n}\n\nlunr.QueryLexer.lexEditDistance = function (lexer) {\n  lexer.ignore()\n  lexer.acceptDigitRun()\n  lexer.emit(lunr.QueryLexer.EDIT_DISTANCE)\n  return lunr.QueryLexer.lexText\n}\n\nlunr.QueryLexer.lexBoost = function (lexer) {\n  lexer.ignore()\n  lexer.acceptDigitRun()\n  lexer.emit(lunr.QueryLexer.BOOST)\n  return lunr.QueryLexer.lexText\n}\n\nlunr.QueryLexer.lexEOS = function (lexer) {\n  if (lexer.width() > 0) {\n    lexer.emit(lunr.QueryLexer.TERM)\n  }\n}\n\n// This matches the separator used when tokenising fields\n// within a document. These should match otherwise it is\n// not possible to search for some tokens within a document.\n//\n// It is possible for the user to change the separator on the\n// tokenizer so it _might_ clash with any other of the special\n// characters already used within the search string, e.g. :.\n//\n// This means that it is possible to change the separator in\n// such a way that makes some words unsearchable using a search\n// string.\nlunr.QueryLexer.termSeparator = lunr.tokenizer.separator\n\nlunr.QueryLexer.lexText = function (lexer) {\n  while (true) {\n    var char = lexer.next()\n\n    if (char == lunr.QueryLexer.EOS) {\n      return lunr.QueryLexer.lexEOS\n    }\n\n    // Escape character is '\\'\n    if (char.charCodeAt(0) == 92) {\n      lexer.escapeCharacter()\n      continue\n    }\n\n    if (char == \":\") {\n      return lunr.QueryLexer.lexField\n    }\n\n    if (char == \"~\") {\n      lexer.backup()\n      if (lexer.width() > 0) {\n        lexer.emit(lunr.QueryLexer.TERM)\n      }\n      return lunr.QueryLexer.lexEditDistance\n    }\n\n    if (char == \"^\") {\n      lexer.backup()\n      if (lexer.width() > 0) {\n        lexer.emit(lunr.QueryLexer.TERM)\n      }\n      return lunr.QueryLexer.lexBoost\n    }\n\n    // \"+\" indicates term presence is required\n    // checking for length to ensure that only\n    // leading \"+\" are considered\n    if (char == \"+\" && lexer.width() === 1) {\n      lexer.emit(lunr.QueryLexer.PRESENCE)\n      return lunr.QueryLexer.lexText\n    }\n\n    // \"-\" indicates term presence is prohibited\n    // checking for length to ensure that only\n    // leading \"-\" are considered\n    if (char == \"-\" && lexer.width() === 1) {\n      lexer.emit(lunr.QueryLexer.PRESENCE)\n      return lunr.QueryLexer.lexText\n    }\n\n    if (char.match(lunr.QueryLexer.termSeparator)) {\n      return lunr.QueryLexer.lexTerm\n    }\n  }\n}\n\nlunr.QueryParser = function (str, query) {\n  this.lexer = new lunr.QueryLexer (str)\n  this.query = query\n  this.currentClause = {}\n  this.lexemeIdx = 0\n}\n\nlunr.QueryParser.prototype.parse = function () {\n  this.lexer.run()\n  this.lexemes = this.lexer.lexemes\n\n  var state = lunr.QueryParser.parseClause\n\n  while (state) {\n    state = state(this)\n  }\n\n  return this.query\n}\n\nlunr.QueryParser.prototype.peekLexeme = function () {\n  return this.lexemes[this.lexemeIdx]\n}\n\nlunr.QueryParser.prototype.consumeLexeme = function () {\n  var lexeme = this.peekLexeme()\n  this.lexemeIdx += 1\n  return lexeme\n}\n\nlunr.QueryParser.prototype.nextClause = function () {\n  var completedClause = this.currentClause\n  this.query.clause(completedClause)\n  this.currentClause = {}\n}\n\nlunr.QueryParser.parseClause = function (parser) {\n  var lexeme = parser.peekLexeme()\n\n  if (lexeme == undefined) {\n    return\n  }\n\n  switch (lexeme.type) {\n    case lunr.QueryLexer.PRESENCE:\n      return lunr.QueryParser.parsePresence\n    case lunr.QueryLexer.FIELD:\n      return lunr.QueryParser.parseField\n    case lunr.QueryLexer.TERM:\n      return lunr.QueryParser.parseTerm\n    default:\n      var errorMessage = \"expected either a field or a term, found \" + lexeme.type\n\n      if (lexeme.str.length >= 1) {\n        errorMessage += \" with value '\" + lexeme.str + \"'\"\n      }\n\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n  }\n}\n\nlunr.QueryParser.parsePresence = function (parser) {\n  var lexeme = parser.consumeLexeme()\n\n  if (lexeme == undefined) {\n    return\n  }\n\n  switch (lexeme.str) {\n    case \"-\":\n      parser.currentClause.presence = lunr.Query.presence.PROHIBITED\n      break\n    case \"+\":\n      parser.currentClause.presence = lunr.Query.presence.REQUIRED\n      break\n    default:\n      var errorMessage = \"unrecognised presence operator'\" + lexeme.str + \"'\"\n      throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n  }\n\n  var nextLexeme = parser.peekLexeme()\n\n  if (nextLexeme == undefined) {\n    var errorMessage = \"expecting term or field, found nothing\"\n    throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n  }\n\n  switch (nextLexeme.type) {\n    case lunr.QueryLexer.FIELD:\n      return lunr.QueryParser.parseField\n    case lunr.QueryLexer.TERM:\n      return lunr.QueryParser.parseTerm\n    default:\n      var errorMessage = \"expecting term or field, found '\" + nextLexeme.type + \"'\"\n      throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n  }\n}\n\nlunr.QueryParser.parseField = function (parser) {\n  var lexeme = parser.consumeLexeme()\n\n  if (lexeme == undefined) {\n    return\n  }\n\n  if (parser.query.allFields.indexOf(lexeme.str) == -1) {\n    var possibleFields = parser.query.allFields.map(function (f) { return \"'\" + f + \"'\" }).join(', '),\n        errorMessage = \"unrecognised field '\" + lexeme.str + \"', possible fields: \" + possibleFields\n\n    throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n  }\n\n  parser.currentClause.fields = [lexeme.str]\n\n  var nextLexeme = parser.peekLexeme()\n\n  if (nextLexeme == undefined) {\n    var errorMessage = \"expecting term, found nothing\"\n    throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n  }\n\n  switch (nextLexeme.type) {\n    case lunr.QueryLexer.TERM:\n      return lunr.QueryParser.parseTerm\n    default:\n      var errorMessage = \"expecting term, found '\" + nextLexeme.type + \"'\"\n      throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n  }\n}\n\nlunr.QueryParser.parseTerm = function (parser) {\n  var lexeme = parser.consumeLexeme()\n\n  if (lexeme == undefined) {\n    return\n  }\n\n  parser.currentClause.term = lexeme.str.toLowerCase()\n\n  if (lexeme.str.indexOf(\"*\") != -1) {\n    parser.currentClause.usePipeline = false\n  }\n\n  var nextLexeme = parser.peekLexeme()\n\n  if (nextLexeme == undefined) {\n    parser.nextClause()\n    return\n  }\n\n  switch (nextLexeme.type) {\n    case lunr.QueryLexer.TERM:\n      parser.nextClause()\n      return lunr.QueryParser.parseTerm\n    case lunr.QueryLexer.FIELD:\n      parser.nextClause()\n      return lunr.QueryParser.parseField\n    case lunr.QueryLexer.EDIT_DISTANCE:\n      return lunr.QueryParser.parseEditDistance\n    case lunr.QueryLexer.BOOST:\n      return lunr.QueryParser.parseBoost\n    case lunr.QueryLexer.PRESENCE:\n      parser.nextClause()\n      return lunr.QueryParser.parsePresence\n    default:\n      var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n      throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n  }\n}\n\nlunr.QueryParser.parseEditDistance = function (parser) {\n  var lexeme = parser.consumeLexeme()\n\n  if (lexeme == undefined) {\n    return\n  }\n\n  var editDistance = parseInt(lexeme.str, 10)\n\n  if (isNaN(editDistance)) {\n    var errorMessage = \"edit distance must be numeric\"\n    throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n  }\n\n  parser.currentClause.editDistance = editDistance\n\n  var nextLexeme = parser.peekLexeme()\n\n  if (nextLexeme == undefined) {\n    parser.nextClause()\n    return\n  }\n\n  switch (nextLexeme.type) {\n    case lunr.QueryLexer.TERM:\n      parser.nextClause()\n      return lunr.QueryParser.parseTerm\n    case lunr.QueryLexer.FIELD:\n      parser.nextClause()\n      return lunr.QueryParser.parseField\n    case lunr.QueryLexer.EDIT_DISTANCE:\n      return lunr.QueryParser.parseEditDistance\n    case lunr.QueryLexer.BOOST:\n      return lunr.QueryParser.parseBoost\n    case lunr.QueryLexer.PRESENCE:\n      parser.nextClause()\n      return lunr.QueryParser.parsePresence\n    default:\n      var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n      throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n  }\n}\n\nlunr.QueryParser.parseBoost = function (parser) {\n  var lexeme = parser.consumeLexeme()\n\n  if (lexeme == undefined) {\n    return\n  }\n\n  var boost = parseInt(lexeme.str, 10)\n\n  if (isNaN(boost)) {\n    var errorMessage = \"boost must be numeric\"\n    throw new lunr.QueryParseError (errorMessage, lexeme.start, lexeme.end)\n  }\n\n  parser.currentClause.boost = boost\n\n  var nextLexeme = parser.peekLexeme()\n\n  if (nextLexeme == undefined) {\n    parser.nextClause()\n    return\n  }\n\n  switch (nextLexeme.type) {\n    case lunr.QueryLexer.TERM:\n      parser.nextClause()\n      return lunr.QueryParser.parseTerm\n    case lunr.QueryLexer.FIELD:\n      parser.nextClause()\n      return lunr.QueryParser.parseField\n    case lunr.QueryLexer.EDIT_DISTANCE:\n      return lunr.QueryParser.parseEditDistance\n    case lunr.QueryLexer.BOOST:\n      return lunr.QueryParser.parseBoost\n    case lunr.QueryLexer.PRESENCE:\n      parser.nextClause()\n      return lunr.QueryParser.parsePresence\n    default:\n      var errorMessage = \"Unexpected lexeme type '\" + nextLexeme.type + \"'\"\n      throw new lunr.QueryParseError (errorMessage, nextLexeme.start, nextLexeme.end)\n  }\n}\n\n  /**\n   * export the module via AMD, CommonJS or as a browser global\n   * Export code from https://github.com/umdjs/umd/blob/master/returnExports.js\n   */\n  ;(function (root, factory) {\n    if (typeof define === 'function' && define.amd) {\n      // AMD. Register as an anonymous module.\n      define(factory)\n    } else if (typeof exports === 'object') {\n      /**\n       * Node. Does not work with strict CommonJS, but\n       * only CommonJS-like enviroments that support module.exports,\n       * like Node.\n       */\n      module.exports = factory()\n    } else {\n      // Browser globals (root is window)\n      root.lunr = factory()\n    }\n  }(this, function () {\n    /**\n     * Just return a value to define the module export.\n     * This example returns an object, but the module\n     * can return a function as the exported value.\n     */\n    return lunr\n  }))\n})();\n"],"names":["$parcel$interopDefault","a","__esModule","default","$parcel$global","globalThis","self","window","global","$parcel$modules","$parcel$inits","parcelRequire","id","exports","init","module","call","err","Error","code","register","modules1","installedModules1","__webpack_require__1","moduleId1","module1","i","l","m","c","d","exports1","name1","getter1","o","Object","defineProperty","configurable","enumerable","get","r","value","n","object1","property1","prototype","hasOwnProperty","p","s","__webpack_require__","eval","$ee2Qt","$ba1d3eb1170b398e$exports","factory","define","amd","EvEmitter","proto","on","eventName","listener","events","_events","listeners","indexOf","push","once","onceEvents","_onceEvents","onceListeners","off","length","index","splice","emitEvent","args","slice","apply","allOff","$c83f175452bd0a3c$export$2e2bcd8739ae039","constructor","el","opts","options","assign","transitionSpeed","activeClasses","modalContentClass","onReady","split","filter","classList","add","isOpen","hasToggles","contentEl","querySelector","customContentEl","closeEls","querySelectorAll","toggleEls","document","Math","random","toString","substr","prevFocusedEl","focusableEls","getFocusableEls","firstFocusableEl","lastFocusableEl","getAttribute","console","warn","setAttribute","forEach","toggleEl","closeEl","bindEvents","destroy","removeAttribute","unbindEvents","getFocusedEl","hasFocus","activeElement","body","documentElement","focusDelay","setTimeout","focus","windowClickHandler","evt","isToggle","Array","target","closest","targetElExists","contains","targetInsideWrapper","targetIsWrapper","isSameNode","close","keydownHandler","which","focusedEl","shiftKey","preventDefault","toggleClick","toggle","bind","addEventListener","closeClick","windowClick","keydown","removeEventListener","open","freeze","scrollTop","remove","unfreeze","$7baa24001ba46d98$var$container","getElementById","$9bd5008c96f03152$exports","lunr","config","builder","Builder","pipeline","trimmer","stopWordFilter","stemmer","searchPipeline","build","version","utils","message","asString","obj","clone","create","keys","key","val","isArray","TypeError","FieldRef","docRef","fieldName","stringValue","_stringValue","joiner","fromString","fieldRef","undefined","Set","elements","complete","intersect","other","union","empty","object","b","intersection","element","concat","idf","posting","documentCount","documentsWithTerm","log","abs","Token","str","metadata","update","fn","tokenizer","map","t","toLowerCase","len","tokens","sliceEnd","sliceStart","char","charAt","sliceLength","match","separator","tokenMetadata","Pipeline","_stack","registeredFunctions","registerFunction","label","warnIfFunctionNotRegistered","load","serialised","fnName","fns","arguments","after","existingFn","newFn","pos","before","run","stackLength","memo","j","result","k","runString","token","reset","toJSON","Vector","_magnitude","positionForIndex","start","end","pivotPoint","floor","pivotIndex","insert","insertIdx","upsert","position","magnitude","sumOfSquares","elementsLength","sqrt","dot","otherVector","dotProduct","aLen","bLen","aVal","bVal","similarity","toArray","output","step2list","step3list","v","C","V","mgr0","meq1","mgr1","s_v","re_mgr0","RegExp","re_mgr1","re_meq1","re_s_v","re_1a","re2_1a","re_1b","re2_1b","re_1b_2","re2_1b_2","re3_1b_2","re4_1b_2","re_1c","re_2","re_3","re_4","re2_4","re_5","re_5_1","re3_5","porterStemmer","w","stem","suffix","firstch","re","re2","re3","re4","toUpperCase","test","replace","fp","exec","generateStopWordFilter","stopWords","words","reduce","stopWord","TokenSet","final","edges","_nextId","fromArray","arr","finish","root","fromClause","clause","fromFuzzyString","term","editDistance","stack","node","editsRemaining","frame","pop","noEditNode","insertionNode","substitutionNode","transposeNode","charA","charB","next","prefix","edge","_str","labels","sort","qNode","qEdges","qLen","nEdges","nLen","q","qEdge","nEdge","previousWord","uncheckedNodes","minimizedNodes","word","commonPrefix","minimize","child","nextNode","parent","downTo","childKey","Index","attrs","invertedIndex","fieldVectors","tokenSet","fields","search","queryString","query","parser","QueryParser","parse","Query","matchingFields","queryVectors","termFieldCache","requiredMatches","prohibitedMatches","clauses","terms","clauseMatches","usePipeline","termTokenSet","expandedTerms","presence","REQUIRED","field","expandedTerm","termIndex","_index","fieldPosting","matchingDocumentRefs","termField","matchingDocumentsSet","PROHIBITED","boost","fieldMatch","matchingDocumentRef","matchingFieldRef","MatchData","allRequiredMatches","allProhibitedMatches","matchingFieldRefs","results","matches","isNegated","docMatch","fieldVector","score","matchData","combine","ref","serializedIndex","serializedVectors","serializedInvertedIndex","tokenSetBuilder","tuple","_ref","_fields","_documents","fieldTermFrequencies","fieldLengths","_b","_k1","metadataWhitelist","attributes","RangeError","number","k1","doc","extractor","fieldTerms","metadataKey","calculateAverageFieldLengths","fieldRefs","numberOfFields","accumulator","documentsWithField","averageFieldLength","createFieldVectors","fieldRefsLength","termIdfCache","fieldLength","termFrequencies","termsLength","fieldBoost","docBoost","scoreWithPrecision","tf","round","createTokenSet","use","unshift","clonedMetadata","metadataKeys","otherMatchData","allFields","wildcard","String","NONE","LEADING","TRAILING","OPTIONAL","QueryParseError","name","QueryLexer","lexemes","escapeCharPositions","state","lexText","sliceString","subSlices","join","emit","type","escapeCharacter","EOS","width","ignore","backup","acceptDigitRun","charCode","charCodeAt","more","FIELD","TERM","EDIT_DISTANCE","BOOST","PRESENCE","lexField","lexer","lexTerm","lexEditDistance","lexBoost","lexEOS","termSeparator","currentClause","lexemeIdx","parseClause","peekLexeme","consumeLexeme","lexeme","nextClause","completedClause","parsePresence","parseField","parseTerm","errorMessage","nextLexeme","possibleFields","f","parseEditDistance","parseBoost","parseInt","isNaN","$6b70e849ffa4c4ec$var$htmlCollection","getElementsByClassName","$6b70e849ffa4c4ec$var$htmlPosts","$6b70e849ffa4c4ec$var$searchbar","$6b70e849ffa4c4ec$var$filter","$6b70e849ffa4c4ec$var$postsContainer","$6b70e849ffa4c4ec$var$noResults","$6b70e849ffa4c4ec$var$clearButton","$6b70e849ffa4c4ec$var$loadButton","$6b70e849ffa4c4ec$var$counter","$6b70e849ffa4c4ec$var$posts","post","content","innerText","feedback","dataset","degrees","benefits","location","$6b70e849ffa4c4ec$var$bigram","pipelineFunction","nextTokenStr","$6b70e849ffa4c4ec$var$metadataUpdate","$6b70e849ffa4c4ec$var$idx","$6b70e849ffa4c4ec$var$checkEnter","e","event","txtArea","srcElement","tagName","keyCode","onkeypress","event1","some","formData","FormData","pair","entries","option","thisOption"],"version":3,"file":"custom.js.map"}